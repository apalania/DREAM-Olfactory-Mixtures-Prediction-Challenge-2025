{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1cLWOpwM9ylFpyChS9G0Jyc5XFSclHrg_","timestamp":1754717066224},{"file_id":"16uRrQ8WMhyYVzyGQRLsvp6EwVAzbjQ4s","timestamp":1754638155755},{"file_id":"1fs34Kt_qmjsBJzqia_GDxsZu1d6d5bAW","timestamp":1754637118958},{"file_id":"1TvwoXmPrfc-sz5Ovn9pFfxbANH0wGGTD","timestamp":1754634143244}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KECSKhWS4K6Z","executionInfo":{"status":"ok","timestamp":1754643411306,"user_tz":-330,"elapsed":393,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"75449c57-f98f-4437-94b3-a5d64369a6b5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data files...\n","CID data shape: (209, 3)\n","molecular_features shape: (209, 3714)\n","Training data shape: (237, 52)\n","Stimulus definition shape: (302, 5)\n","Leaderboard form shape: (34, 52)\n","Test form shape: (31, 52)\n","OpenPOM data not found\n","Data loaded successfully!\n"]}],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","\n","# Initialize scalers and encoders\n","molecular_scaler = StandardScaler()\n","target_scaler = StandardScaler()\n","solvent_encoder = LabelEncoder()\n","\n","print(\"Loading data files...\")\n","\n","# Load CID data\n","cid_data = pd.read_csv('CID.csv', encoding='latin1')\n","print(f\"CID data shape: {cid_data.shape}\")\n","\n","# Load Mordred descriptors with encoding fallback\n","try:\n","    mordred_descriptors = pd.read_csv('concatenated_fingerprints.csv', encoding='utf-8')\n","except UnicodeDecodeError:\n","    try:\n","        mordred_descriptors = pd.read_csv('concatenated_fingerprints.csv', encoding='latin1')\n","    except:\n","        mordred_descriptors = pd.read_csv('Concatenated_Fingerprints.csv', encoding='cp1252')\n","print(f\"molecular_features shape: {mordred_descriptors.shape}\")\n","\n","\n","\n","# Load training data\n","training_data = pd.read_csv('TASK1_training.csv', encoding='latin1')\n","print(f\"Training data shape: {training_data.shape}\")\n","\n","# Load stimulus definitions\n","stimulus_def = pd.read_csv('TASK1_Stimulus_definition.csv', encoding='latin1')\n","print(f\"Stimulus definition shape: {stimulus_def.shape}\")\n","\n","# Load submission forms\n","leaderboard_form = pd.read_csv('TASK1_leaderboard_set_Submission_form.csv', encoding='latin1')\n","test_form = pd.read_csv('TASK1_test_set_Submission_form.csv', encoding='latin1')\n","\n","print(f\"Leaderboard form shape: {leaderboard_form.shape}\")\n","print(f\"Test form shape: {test_form.shape}\")\n","\n","# Load OpenPOM (optional)\n","try:\n","    openpom_data = pd.read_csv('OpenPOM_Dream_RATA.csv', encoding='latin1')\n","    print(f\"OpenPOM data shape: {openpom_data.shape}\")\n","except:\n","    openpom_data = None\n","    print(\"OpenPOM data not found\")\n","\n","print(\"Data loaded successfully!\")\n"]},{"cell_type":"code","source":["\n","# Prepare Mordred features with cleaned data\n","# Regenerate list of valid feature columns from cleaned Mordred\n","mordred_feature_cols_clean = [col for col in mordred_descriptors.columns if col not in ['molecule', 'SMILES']]\n","\n","molecular_features = mordred_descriptors[['molecule'] + mordred_feature_cols_clean].copy()\n","\n","\n","#morgan_features.columns = ['molecule'] + [f'morgan_{col}' for col in morgan_feature_cols]\n","\n","# Merge molecular features\n","#molecular_features = pd.merge(mordred_features, morgan_features, on='molecule', how='inner')\n","\n","\n","print(f\"\\n=== FINAL MOLECULAR FEATURES ===\")\n","print(f\"Combined molecular features shape: {molecular_features.shape}\")\n","print(f\"Molecules with complete features: {len(molecular_features['molecule'].unique())}\")\n","\n","# Verify no NaN values remain\n","remaining_nans = molecular_features.isnull().sum().sum()\n","print(f\"Remaining NaN values in final dataset: {remaining_nans}\")\n","\n","if remaining_nans == 0:\n","    print(\"✅ All NaN values successfully handled!\")\n","else:\n","    print(\"⚠️  Warning: Some NaN values still remain\")\n","\n","print(\"\\n=== PREPARING TRAINING DATA ===\")\n","\n","# Reuse molecular_features if already created in previous cell\n","# If not, rerun the \"Prepare Molecular Features\" cell above\n","\n","# Merge training data with stimulus definitions\n","train_with_stimulus = pd.merge(\n","    training_data,\n","    stimulus_def,\n","    on='stimulus',\n","    how='left'\n",")\n","\n","print(f\"Training data with stimulus info shape: {train_with_stimulus.shape}\")\n","print(f\"Missing stimulus definitions: {train_with_stimulus['molecule'].isna().sum()}\")\n","\n","# Merge with molecular features\n","train_complete = pd.merge(\n","    train_with_stimulus,\n","    molecular_features,\n","    on='molecule', how='left'\n",")\n","\n","print(f\"Complete training data shape: {train_complete.shape}\")\n","\n","print(f\"Missing molecular features: {train_complete.isnull().any(axis=1).sum()}\")\n","\n","# Remove rows with missing data\n","print(f\"Training data after removing missing: {train_complete.shape}\")\n","\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","# Drop rows with missing molecule\n","train_data = train_complete\n","# Target columns\n","target_cols = ['Green', 'Cucumber', 'Herbal', 'Mint', 'Woody', 'Pine', 'Floral',\n","               'Powdery', 'Fruity', 'Citrus', 'Tropical', 'Berry', 'Peach', 'Sweet',\n","               'Caramellic', 'Vanilla', 'BrownSpice', 'Smoky', 'Burnt', 'Roasted',\n","               'Grainy', 'Meaty', 'Nutty', 'Fatty', 'Coconut', 'Waxy', 'Dairy',\n","               'Buttery', 'Cheesy', 'Sour', 'Fermented', 'Sulfurous', 'Garlic.Onion',\n","               'Earthy', 'Mushroom', 'Musty', 'Ammonia', 'Fishy', 'Fecal',\n","               'Rotten.Decay', 'Rubber', 'Phenolic', 'Animal', 'Medicinal',\n","               'Cooling', 'Sharp', 'Chlorine', 'Alcoholic', 'Plastic', 'Ozone', 'Metallic']\n","\n","# Feature columns = all except IDs + targets\n","non_feature_cols = ['molecule', 'SMILES', 'stimulus', 'Intensity_label', 'solvent', 'dilution'] + target_cols\n","feature_cols = [col for col in train_data.columns if col not in non_feature_cols]\n","# Prepare input features\n","X_molecular = train_data[feature_cols].fillna(0).values\n","X_concentration = np.log10(train_data['dilution'].fillna(0.001)).values.reshape(-1, 1)\n","\n","solvent_encoder = LabelEncoder()\n","X_solvent = solvent_encoder.fit_transform(train_data['solvent'].fillna('PG')).reshape(-1, 1)\n","\n","intensity_encoder = LabelEncoder()\n","X_intensity = intensity_encoder.fit_transform(train_data['Intensity_label'].fillna('L')).reshape(-1, 1)\n","\n","# Concatenate all feature blocks into a DataFrame\n","X_df = pd.concat([\n","    pd.DataFrame(X_molecular, columns=[str(c) for c in feature_cols]),\n","    pd.DataFrame(X_concentration, columns=['log_dilution']),\n","    pd.DataFrame(X_solvent, columns=['solvent_encoded']),\n","    pd.DataFrame(X_intensity, columns=['intensity_encoded'])\n","], axis=1)\n","\n","# Convert to NumPy array for PyTorch\n","X_np = X_df.values.astype(np.float32)\n","\n","# y: shape (num_samples, num_targets)\n","y_np = train_data[target_cols].fillna(0).values.astype(np.float32)\n","y_df = pd.DataFrame(y_np, columns=target_cols)\n","\n","def prepare_test_data(form_df, stimulus_def, molecular_features, feature_cols,\n","                      solvent_encoder, intensity_encoder, molecular_scaler, set_name=\"test\"):\n","    \"\"\"Prepare test data for prediction (returns Pandas DataFrame)\"\"\"\n","    print(f\"\\n=== PREPARING {set_name.upper()} DATA ===\")\n","\n","    # Merge with stimulus definitions\n","    test_with_stimulus = pd.merge(\n","        form_df,\n","        stimulus_def,\n","        on='stimulus',\n","        how='left'\n","    )\n","\n","    print(f\"{set_name} data with stimulus info shape: {test_with_stimulus.shape}\")\n","    print(f\"Missing stimulus definitions: {test_with_stimulus['molecule'].isna().sum()}\")\n","\n","    # Merge with molecular features\n","    test_complete = pd.merge(\n","        test_with_stimulus,\n","        molecular_features,\n","        on='molecule',\n","        how='left'\n","    )\n","\n","    print(f\"Complete {set_name} data shape: {test_complete.shape}\")\n","    print(test_complete.columns)\n","    # Molecular features (as DataFrame)\n","    X_molecular = test_complete[feature_cols].copy()\n","\n","    # Concentration (log-scaled)\n","    X_concentration = np.log10(test_complete['dilution'].fillna(0.001) + 1e-10)\n","    X_concentration = pd.DataFrame(X_concentration, columns=['log_dilution'])\n","\n","    # Solvent encoding\n","    solvent_filled = test_complete['solvent'].fillna('PG')\n","    X_solvent = pd.DataFrame(solvent_encoder.transform(solvent_filled), columns=['solvent_encoded'])\n","\n","    # Intensity encoding\n","    intensity_filled = test_complete['Intensity_label'].fillna('L')\n","    X_intensity = pd.DataFrame(intensity_encoder.transform(intensity_filled), columns=['intensity_encoded'])\n","\n","    # Combine all into a single DataFrame\n","    X_all = pd.concat([X_molecular, X_concentration, X_solvent, X_intensity], axis=1)\n","\n","    # Handle missing values and enforce numeric type\n","    X_all = X_all.fillna(0.0).astype(np.float32)\n","\n","    # Optional: apply scaler if needed\n","    # X_scaled = molecular_scaler.transform(X_all)  # Uncomment if you want scaling\n","    # X_all = pd.DataFrame(X_scaled, columns=X_all.columns)  # Maintain column names\n","\n","    return X_all, test_complete\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","X_test, test_data = prepare_test_data(\n","    form_df=test_form,\n","    stimulus_def=stimulus_def,\n","    molecular_features=molecular_features,\n","    feature_cols=feature_cols,\n","    solvent_encoder=solvent_encoder,\n","    intensity_encoder=intensity_encoder,\n","    molecular_scaler=molecular_scaler\n",")\n","# Load the selected feature names from Lasso\n","\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P42CaMFc73TU","executionInfo":{"status":"ok","timestamp":1754643415177,"user_tz":-330,"elapsed":428,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"05b85dac-489c-481d-ad04-e892c9be5035"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== FINAL MOLECULAR FEATURES ===\n","Combined molecular features shape: (209, 3713)\n","Molecules with complete features: 209\n","Remaining NaN values in final dataset: 0\n","✅ All NaN values successfully handled!\n","\n","=== PREPARING TRAINING DATA ===\n","Training data with stimulus info shape: (237, 56)\n","Missing stimulus definitions: 0\n","Complete training data shape: (237, 3768)\n","Missing molecular features: 0\n","Training data after removing missing: (237, 3768)\n","\n","=== PREPARING TEST DATA ===\n","test data with stimulus info shape: (31, 56)\n","Missing stimulus definitions: 0\n","Complete test data shape: (31, 3768)\n","Index(['stimulus', 'Green', 'Cucumber', 'Herbal', 'Mint', 'Woody', 'Pine',\n","       'Floral', 'Powdery', 'Fruity',\n","       ...\n","       'SRW10', 'TSRW10', 'MW', 'AMW', 'WPath', 'WPol', 'Zagreb1', 'Zagreb2',\n","       'mZagreb1', 'mZagreb2'],\n","      dtype='object', length=3768)\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-3501361578.py:147: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  X_all = X_all.fillna(0.0).astype(np.float32)\n"]}]},{"cell_type":"code","source":["print(y_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"X-k9Wn1auv-t","executionInfo":{"status":"ok","timestamp":1754640624040,"user_tz":-330,"elapsed":1044,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"9f561850-dc73-4566-a2cc-929f6976d331"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(237, 51)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.decomposition import PCA\n","from sklearn.linear_model import MultiTaskLassoCV  # Note the change here\n","\n","def pca_lasso_feature_selection(x_df, y_df, X_test):\n","    # Step 1: Apply PCA on all features\n","    pca = PCA(n_components=None)\n","    X_pca = pca.fit_transform(x_df)\n","\n","    # Step 2: Use MultiTaskLassoCV for multi-output feature selection\n","    lasso = MultiTaskLassoCV(cv=5, random_state=42).fit(X_pca, y_df)\n","\n","    # Step 3: Compute norm of coefficients across multiple targets\n","    coef_norm = np.linalg.norm(lasso.coef_, axis=0)\n","\n","    # Select PCA components with non-zero coefficients\n","    selected_components = np.where(coef_norm > 1e-5)[0]\n","\n","    # Filter PCA components for train and test data accordingly\n","    X_pca_selected = X_pca[:, selected_components]\n","    X_test_pca = pca.transform(X_test)\n","    X_test_pca_selected = X_test_pca[:, selected_components]\n","\n","    # Convert to DataFrames with meaningful column names\n","    X_selected_df = pd.DataFrame(X_pca_selected, columns=[f'PCA_{i}' for i in selected_components])\n","    X_test_selected_df = pd.DataFrame(X_test_pca_selected, columns=[f'PCA_{i}' for i in selected_components])\n","\n","    return X_selected_df, X_test_selected_df\n","x_df_lasso, X_test = pca_lasso_feature_selection(X_df, y_df, X_test)\n","print(x_df_lasso.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FqX3tzOAxByv","executionInfo":{"status":"ok","timestamp":1754643447707,"user_tz":-330,"elapsed":5815,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"9d967a89-a331-4f76-9d64-94b4626994bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["          PCA_0        PCA_1        PCA_2       PCA_3        PCA_4  \\\n","0  -7143.429999    36.284304  1590.189940  -17.311156  -115.099405   \n","1  14769.869433    91.496008  -387.708494 -664.656971   432.214182   \n","2 -14669.718557  3058.902633  1243.392292 -110.632223  1029.834272   \n","3   8889.329035   591.561590  1007.006925 -700.324643 -1020.453764   \n","4  -7143.430071    36.284422  1590.189888  -17.311156  -115.099515   \n","\n","        PCA_5       PCA_6       PCA_7       PCA_8      PCA_10      PCA_11  \n","0 -115.760148 -148.895493 -244.836755 -453.519181 -332.495868   28.781464  \n","1 -670.818548  528.162203 -664.486099  140.127384  354.260786  103.588238  \n","2  608.212219  309.202570 -644.652555   54.575466 -393.524628 -398.927474  \n","3 -639.971997 -800.951785 -103.238916 -454.590844  507.274776  558.105250  \n","4 -115.760324 -148.895505 -244.836299 -453.520145 -332.495816   28.781010  \n"]}]},{"cell_type":"markdown","source":["# **Hyperbolic Model**"],"metadata":{"id":"dkuRAgL-z76S"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class PearsonCosineLoss(nn.Module):\n","    def __init__(self, alpha=0.5, eps=1e-8):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.eps = eps\n","        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=eps)\n","\n","    def forward(self, y_pred, y_true):\n","        # Pearson Correlation (1 - correlation for minimization)\n","        y_pred_centered = y_pred - y_pred.mean(dim=1, keepdim=True)\n","        y_true_centered = y_true - y_true.mean(dim=1, keepdim=True)\n","        numerator = (y_pred_centered * y_true_centered).sum(dim=1)\n","        denominator = (y_pred_centered.pow(2).sum(dim=1) * y_true_centered.pow(2).sum(dim=1)).sqrt() + self.eps\n","        pearson_corr = numerator / denominator\n","        pearson_loss = 1 - pearson_corr\n","\n","        # Cosine Similarity (1 - similarity for minimization)\n","        cosine_loss = 1 - self.cosine_similarity(y_pred, y_true)\n","        loss = self.alpha * pearson_loss + (1 - self.alpha) * cosine_loss\n","        return loss.mean()\n","class HyperbolicModel(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, output_dim)\n","        self.tanh = nn.Tanh()\n","    def forward(self, x):\n","        x = self.tanh(self.fc1(x))\n","        x = self.tanh(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    corrs = [np.corrcoef(y_true[:,i], y_pred[:,i])[0,1] if np.std(y_true[:,i])>0 and np.std(y_pred[:,i])>0 else 0 for i in range(y_true.shape[1])]\n","    avg_pearson = np.mean(corrs)\n","    norms_true = np.linalg.norm(y_true, axis=1)\n","    norms_pred = np.linalg.norm(y_pred, axis=1)\n","    cos = np.sum(y_true * y_pred, axis=1) / (norms_true * norms_pred + 1e-8)\n","    avg_cosine = np.mean(cos)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine\n","    }\n","\n","# Training routine\n","def train_and_evaluate(X, y, test_ratio=0.2, epochs=100, lr=1e-3, batch_size=32, alpha=0.5):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # Split\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_ratio, random_state=42)\n","    X_train_t = torch.FloatTensor(X_train).to(device)\n","    y_train_t = torch.FloatTensor(y_train).to(device)\n","    X_val_t = torch.FloatTensor(X_val).to(device)\n","    y_val_t = torch.FloatTensor(y_val).to(device)\n","\n","    # Model\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    loss_fn = PearsonCosineLoss(alpha=alpha)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    n = X_train.shape[0]\n","    steps_per_epoch = int(np.ceil(n / batch_size))\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        idx = np.random.permutation(n)\n","        for i in range(steps_per_epoch):\n","            batch_idx = idx[i*batch_size:(i+1)*batch_size]\n","            xb = X_train_t[batch_idx]\n","            yb = y_train_t[batch_idx]\n","            optimizer.zero_grad()\n","            y_pred = model(xb)\n","            loss = loss_fn(y_pred, yb)\n","            loss.backward()\n","            optimizer.step()\n","        if (epoch+1) % 20 == 0:\n","            print(f\"Epoch {epoch+1}/{epochs}: Train Loss = {loss.item():.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        y_train_pred = model(X_train_t).cpu().numpy()\n","        y_val_pred = model(X_val_t).cpu().numpy()\n","\n","    # Print metrics on split data\n","    train_metrics = calculate_metrics(y_train, y_train_pred)\n","    val_metrics = calculate_metrics(y_val, y_val_pred)\n","    print(\"\\\\nTrain Metrics:\", train_metrics)\n","    print(\"Validation Metrics:\", val_metrics)\n","\n","    # Retrain on full data\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    X_full_t = torch.FloatTensor(X).to(device)\n","    y_full_t = torch.FloatTensor(y).to(device)\n","    for epoch in range(epochs):\n","        optimizer.zero_grad()\n","        y_pred = model(X_full_t)\n","        loss = loss_fn(y_pred, y_full_t)\n","        loss.backward()\n","        optimizer.step()\n","    model.eval()\n","    with torch.no_grad():\n","        y_full_pred = model(X_full_t).cpu().numpy()\n","    full_metrics = calculate_metrics(y, y_full_pred)\n","    print(\"\\\\nMetrics on Full Data:\", full_metrics)\n","    return model, device\n","# Run training and print metrics\n","model, device = train_and_evaluate(x_df_lasso.to_numpy(), y_df.to_numpy(), test_ratio=0.2, epochs=100, lr=1e-3, batch_size=32, alpha=0.5)\n","\n","# Convert all columns to numeric (with NaNs where conversion failed)\n","X_test_numeric = X_test.apply(pd.to_numeric, errors='coerce')\n","\n","# Fill NaN values (e.g., with 0 or other imputation strategy)\n","X_test_filled = X_test_numeric.fillna(0)\n","\n","# Convert to numpy array of floats\n","X_test_arr = X_test_filled.to_numpy(dtype=np.float32)\n","with torch.no_grad():\n","    X_test_tensor = torch.FloatTensor(X_test_arr).to(device)\n","    test_preds = model(X_test_tensor).cpu().numpy()\n","\n","# Save submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","\n","test_submission.to_csv('hyperbolic_task1_pcalasso.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKn1rTrhN47u","executionInfo":{"status":"ok","timestamp":1754642500715,"user_tz":-330,"elapsed":2483,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"787266de-c3b7-41d0-a86c-58a94a211e0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 20/100: Train Loss = 0.2938\n","Epoch 40/100: Train Loss = 0.2221\n","Epoch 60/100: Train Loss = 0.2184\n","Epoch 80/100: Train Loss = 0.1901\n","Epoch 100/100: Train Loss = 0.1750\n","\\nTrain Metrics: {'MSE': 0.05216173082590103, 'MAE': 0.11851051449775696, 'R2': 0.34603363275527954, 'Avg Pearson Correlation': np.float64(0.6462116261112222), 'Avg Cosine Similarity': np.float32(0.8636175)}\n","Validation Metrics: {'MSE': 0.08286306262016296, 'MAE': 0.1701226532459259, 'R2': -0.2854960858821869, 'Avg Pearson Correlation': np.float64(0.17885212287664348), 'Avg Cosine Similarity': np.float32(0.57487434)}\n","\\nMetrics on Full Data: {'MSE': 0.05258292704820633, 'MAE': 0.13506537675857544, 'R2': 0.2849707305431366, 'Avg Pearson Correlation': np.float64(0.5572993004158857), 'Avg Cosine Similarity': np.float32(0.81675804)}\n","Test predictions saved.\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Correlation Regressor**"],"metadata":{"id":"d6XCJgfl0g16"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","\n","\n","# Pearson correlation loss (maximize correlation by minimizing negative correlation)\n","def pearson_correlation_loss(y_true, y_pred):\n","    y_true_centered = y_true - tf.reduce_mean(y_true, axis=1, keepdims=True)\n","    y_pred_centered = y_pred - tf.reduce_mean(y_pred, axis=1, keepdims=True)\n","    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n","    denominator = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered), axis=1)) * tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered), axis=1))\n","    correlation = numerator / (denominator + 1e-8)\n","    return -tf.reduce_mean(correlation)\n","\n","\n","def create_olfactory_model(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(128, activation='relu', input_shape=(input_dim,)),\n","        Dense(64, activation='relu'),\n","        Dense(output_dim, activation='linear')\n","    ])\n","    model.compile(optimizer='adam', loss=pearson_correlation_loss, metrics=['mse'])\n","    return model\n","\n","\n","class CorrelationRegressor(BaseEstimator, RegressorMixin):\n","    def __init__(self, input_dim=None, output_dim=None, epochs=100, batch_size=32, verbose=0):\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.verbose = verbose\n","        self.model_ = None\n","\n","    def fit(self, X, y):\n","        if self.input_dim is None:\n","            self.input_dim = X.shape[1]\n","        if self.output_dim is None:\n","            self.output_dim = y.shape[1] if len(y.shape) > 1 else 1\n","        self.model_ = create_olfactory_model(self.input_dim, self.output_dim)\n","        self.model_.fit(\n","            X, y,\n","            epochs=self.epochs,\n","            batch_size=self.batch_size,\n","            verbose=self.verbose\n","        )\n","        return self\n","\n","    def predict(self, X):\n","        if self.model_ is None:\n","            raise ValueError(\"Model not fitted yet\")\n","        return self.model_.predict(X)\n","\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","\n","# Convert DataFrames to numpy arrays\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","\n","# 1. Split data 80% train, 20% validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","\n","# 2. Initialize regressor\n","regressor = CorrelationRegressor(\n","    input_dim=X_train_split.shape[1],\n","    output_dim=y_train_split.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","\n","# 3. Train on 80% split\n","regressor.fit(X_train_split, y_train_split)\n","\n","# 4. Evaluate on train split and validation split\n","y_train_pred = regressor.predict(X_train_split)\n","y_val_pred = regressor.predict(X_val)\n","\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","\n","# 5. Train on full dataset (train + val)\n","regressor_full = CorrelationRegressor(\n","    input_dim=X.shape[1],\n","    output_dim=y.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","regressor_full.fit(X, y)\n","\n","# 6. Evaluate on entire training dataset\n","y_full_pred = regressor_full.predict(X)\n","print(\"\\nFull training dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","\n","# 7. Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = regressor_full.predict(X_test_arr)\n","\n","# 8. Save submission file\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('corr_test_pcalasso.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2EGVulygyAxt","executionInfo":{"status":"ok","timestamp":1754642540651,"user_tz":-330,"elapsed":29828,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"6bb4c65d-9bdd-4d03-cc29-a8f917210a0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 8ms/step - loss: -0.0991 - mse: 618423.8125\n","Epoch 2/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.2315 - mse: 783803.9375  \n","Epoch 3/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3228 - mse: 1190184.7500 \n","Epoch 4/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3636 - mse: 1130654.6250 \n","Epoch 5/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4046 - mse: 1129829.0000 \n","Epoch 6/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4406 - mse: 1083323.8750\n","Epoch 7/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4607 - mse: 1170359.2500 \n","Epoch 8/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4596 - mse: 1266021.3750 \n","Epoch 9/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4770 - mse: 1137536.0000\n","Epoch 10/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4911 - mse: 1094303.0000 \n","Epoch 11/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4930 - mse: 1061922.6250 \n","Epoch 12/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5162 - mse: 975315.5000  \n","Epoch 13/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5354 - mse: 825378.9375 \n","Epoch 14/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5203 - mse: 704061.5000 \n","Epoch 15/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5392 - mse: 645212.8125 \n","Epoch 16/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5485 - mse: 615487.8125 \n","Epoch 17/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5722 - mse: 514597.7500 \n","Epoch 18/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5883 - mse: 448896.3750 \n","Epoch 19/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5769 - mse: 411761.4688 \n","Epoch 20/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5879 - mse: 374419.3750 \n","Epoch 21/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5972 - mse: 360262.2500  \n","Epoch 22/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5982 - mse: 294343.9375  \n","Epoch 23/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6146 - mse: 285839.9062 \n","Epoch 24/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6098 - mse: 329845.1250  \n","Epoch 25/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.6097 - mse: 291726.2812 \n","Epoch 26/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6175 - mse: 213872.2031 \n","Epoch 27/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.6306 - mse: 204963.1875\n","Epoch 28/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6359 - mse: 197937.3125 \n","Epoch 29/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6449 - mse: 212256.2344 \n","Epoch 30/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6538 - mse: 170645.6562 \n","Epoch 31/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6702 - mse: 155271.3125  \n","Epoch 32/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6715 - mse: 160898.1562 \n","Epoch 33/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6636 - mse: 155564.6562 \n","Epoch 34/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6722 - mse: 141077.3281 \n","Epoch 35/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6739 - mse: 138488.6562  \n","Epoch 36/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6947 - mse: 133557.5000  \n","Epoch 37/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6772 - mse: 145264.8438 \n","Epoch 38/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7000 - mse: 132949.6250  \n","Epoch 39/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6909 - mse: 103880.4922 \n","Epoch 40/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7031 - mse: 111455.5391 \n","Epoch 41/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6979 - mse: 113057.0469 \n","Epoch 42/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7123 - mse: 106505.4609\n","Epoch 43/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7081 - mse: 118429.0156  \n","Epoch 44/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7155 - mse: 108041.4688 \n","Epoch 45/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7166 - mse: 109997.5469  \n","Epoch 46/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7106 - mse: 117853.0859  \n","Epoch 47/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7167 - mse: 108628.6094 \n","Epoch 48/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7345 - mse: 86077.1016 \n","Epoch 49/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7247 - mse: 96388.6406   \n","Epoch 50/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7294 - mse: 101214.3594 \n","Epoch 51/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7172 - mse: 100886.1875  \n","Epoch 52/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7270 - mse: 88313.1016 \n","Epoch 53/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7422 - mse: 76885.8047 \n","Epoch 54/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7375 - mse: 82005.5234 \n","Epoch 55/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7502 - mse: 89218.4844 \n","Epoch 56/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7480 - mse: 89674.3438 \n","Epoch 57/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7429 - mse: 84500.3594   \n","Epoch 58/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7452 - mse: 77699.2422 \n","Epoch 59/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7430 - mse: 77782.2891  \n","Epoch 60/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7538 - mse: 71835.7578  \n","Epoch 61/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7519 - mse: 72751.3281 \n","Epoch 62/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7491 - mse: 77437.3906 \n","Epoch 63/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7573 - mse: 75083.1406 \n","Epoch 64/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7625 - mse: 73599.5781\n","Epoch 65/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7595 - mse: 72645.6484 \n","Epoch 66/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: -0.7676 - mse: 71384.8984\n","Epoch 67/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7694 - mse: 71101.0469\n","Epoch 68/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7699 - mse: 68400.7812\n","Epoch 69/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7723 - mse: 67690.5312\n","Epoch 70/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7584 - mse: 63174.9219\n","Epoch 71/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7650 - mse: 70924.1328\n","Epoch 72/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7779 - mse: 65885.9688\n","Epoch 73/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.7554 - mse: 65224.0625\n","Epoch 74/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7849 - mse: 67823.3672\n","Epoch 75/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7875 - mse: 66636.6484\n","Epoch 76/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7754 - mse: 63129.2734\n","Epoch 77/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7775 - mse: 66191.1016\n","Epoch 78/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.7775 - mse: 60719.7344\n","Epoch 79/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.7889 - mse: 66155.0391\n","Epoch 80/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7760 - mse: 62766.3125\n","Epoch 81/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7926 - mse: 57685.9844\n","Epoch 82/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7848 - mse: 64221.7188\n","Epoch 83/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7839 - mse: 58693.0117\n","Epoch 84/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.7944 - mse: 59165.1602\n","Epoch 85/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7768 - mse: 51982.0039\n","Epoch 86/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7910 - mse: 53385.5039 \n","Epoch 87/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7859 - mse: 68797.9609 \n","Epoch 88/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7982 - mse: 67496.0391 \n","Epoch 89/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7960 - mse: 57893.0703 \n","Epoch 90/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7950 - mse: 66402.5000 \n","Epoch 91/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7965 - mse: 48903.9766  \n","Epoch 92/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8072 - mse: 67063.6250  \n","Epoch 93/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7952 - mse: 49000.2930 \n","Epoch 94/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.8039 - mse: 52559.6016 \n","Epoch 95/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7914 - mse: 63096.6406 \n","Epoch 96/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8080 - mse: 56987.1719 \n","Epoch 97/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8041 - mse: 49344.0820 \n","Epoch 98/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8100 - mse: 49163.9883 \n","Epoch 99/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7984 - mse: 49666.7734 \n","Epoch 100/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8054 - mse: 51691.8516 \n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","Training set metrics:\n","{'MSE': 54421.45703125, 'MAE': 145.21994018554688, 'R2': -945799.5, 'Avg Pearson Correlation': np.float64(0.5324233834826698), 'Avg Cosine Similarity': np.float32(0.35096192)}\n","\n","Validation set metrics:\n","{'MSE': 42425.140625, 'MAE': 128.7954864501953, 'R2': -946559.9375, 'Avg Pearson Correlation': np.float64(0.24940930936597977), 'Avg Cosine Similarity': np.float32(0.110189974)}\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: -0.0206 - mse: 717416.3125\n","Epoch 2/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.1735 - mse: 943384.1250  \n","Epoch 3/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2706 - mse: 1100782.3750\n","Epoch 4/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.3427 - mse: 1308791.6250 \n","Epoch 5/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4131 - mse: 1436095.6250  \n","Epoch 6/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4347 - mse: 1533359.0000 \n","Epoch 7/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4489 - mse: 1582842.3750 \n","Epoch 8/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4735 - mse: 1515899.0000 \n","Epoch 9/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4959 - mse: 1367325.6250 \n","Epoch 10/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4954 - mse: 1315185.3750 \n","Epoch 11/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5137 - mse: 1101917.2500 \n","Epoch 12/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5232 - mse: 853912.5625 \n","Epoch 13/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5375 - mse: 784787.5000 \n","Epoch 14/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5598 - mse: 763393.1875 \n","Epoch 15/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5594 - mse: 550917.5000 \n","Epoch 16/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5647 - mse: 499691.7188 \n","Epoch 17/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5760 - mse: 433574.5938 \n","Epoch 18/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5717 - mse: 396491.9688 \n","Epoch 19/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6037 - mse: 342035.7500 \n","Epoch 20/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6094 - mse: 323339.2812 \n","Epoch 21/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6134 - mse: 292470.5938 \n","Epoch 22/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6225 - mse: 271300.6562 \n","Epoch 23/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6375 - mse: 252705.4062 \n","Epoch 24/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.6482 - mse: 243951.4219  \n","Epoch 25/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6494 - mse: 228805.5625 \n","Epoch 26/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6561 - mse: 203363.3125 \n","Epoch 27/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6565 - mse: 199695.6094 \n","Epoch 28/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6676 - mse: 181871.0625 \n","Epoch 29/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6721 - mse: 195137.6719 \n","Epoch 30/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6722 - mse: 174746.3594  \n","Epoch 31/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6857 - mse: 187028.5938 \n","Epoch 32/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6692 - mse: 172322.0781 \n","Epoch 33/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6819 - mse: 174449.1406  \n","Epoch 34/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6841 - mse: 163137.2812 \n","Epoch 35/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6811 - mse: 157515.8438 \n","Epoch 36/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6998 - mse: 168365.2500 \n","Epoch 37/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7037 - mse: 160648.5625 \n","Epoch 38/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7020 - mse: 149341.8906 \n","Epoch 39/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6918 - mse: 169317.8125 \n","Epoch 40/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7078 - mse: 148612.0938 \n","Epoch 41/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7101 - mse: 148927.0000 \n","Epoch 42/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7161 - mse: 144198.4219 \n","Epoch 43/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7073 - mse: 130663.8672 \n","Epoch 44/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7092 - mse: 126134.7422 \n","Epoch 45/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7060 - mse: 133064.6875 \n","Epoch 46/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7214 - mse: 114515.5391\n","Epoch 47/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7014 - mse: 138720.8906 \n","Epoch 48/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7219 - mse: 127345.6328 \n","Epoch 49/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7249 - mse: 137434.6406 \n","Epoch 50/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7274 - mse: 105431.6484\n","Epoch 51/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7166 - mse: 111596.7891\n","Epoch 52/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7227 - mse: 119700.4297 \n","Epoch 53/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7292 - mse: 114869.5859 \n","Epoch 54/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7333 - mse: 107257.1953 \n","Epoch 55/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7306 - mse: 118510.5547 \n","Epoch 56/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7308 - mse: 103434.6406\n","Epoch 57/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7362 - mse: 104584.3281\n","Epoch 58/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7412 - mse: 112846.8438 \n","Epoch 59/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7399 - mse: 106136.8906\n","Epoch 60/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7438 - mse: 104070.9219 \n","Epoch 61/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7314 - mse: 96943.1797 \n","Epoch 62/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7509 - mse: 97548.7344  \n","Epoch 63/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7415 - mse: 93776.7188 \n","Epoch 64/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7524 - mse: 94472.5703 \n","Epoch 65/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7495 - mse: 96090.3594 \n","Epoch 66/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7492 - mse: 86571.1328 \n","Epoch 67/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7452 - mse: 92675.9922 \n","Epoch 68/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7635 - mse: 102144.6328 \n","Epoch 69/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7625 - mse: 95042.5078  \n","Epoch 70/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7583 - mse: 82828.7344\n","Epoch 71/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7652 - mse: 81247.6953 \n","Epoch 72/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7640 - mse: 85991.5547 \n","Epoch 73/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7631 - mse: 94674.2031  \n","Epoch 74/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7727 - mse: 91128.3750 \n","Epoch 75/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7773 - mse: 80249.4766 \n","Epoch 76/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7681 - mse: 82726.9375 \n","Epoch 77/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7774 - mse: 78989.8516 \n","Epoch 78/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7892 - mse: 78428.8047 \n","Epoch 79/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7664 - mse: 82552.4141 \n","Epoch 80/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7727 - mse: 77599.4219 \n","Epoch 81/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7720 - mse: 83956.1250\n","Epoch 82/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7695 - mse: 79025.5859 \n","Epoch 83/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7702 - mse: 71176.6797 \n","Epoch 84/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7777 - mse: 77948.7109\n","Epoch 85/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7667 - mse: 78018.1406 \n","Epoch 86/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: -0.7754 - mse: 78554.6016\n","Epoch 87/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7688 - mse: 76369.5547  \n","Epoch 88/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7884 - mse: 72804.6016 \n","Epoch 89/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7888 - mse: 68075.9609 \n","Epoch 90/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7889 - mse: 76562.6484 \n","Epoch 91/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7962 - mse: 77515.7109 \n","Epoch 92/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7857 - mse: 71920.2969 \n","Epoch 93/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7930 - mse: 69550.3984 \n","Epoch 94/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7906 - mse: 68530.5938 \n","Epoch 95/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7987 - mse: 61351.6953 \n","Epoch 96/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7854 - mse: 70952.3906  \n","Epoch 97/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7917 - mse: 77428.9531  \n","Epoch 98/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7966 - mse: 60489.8477 \n","Epoch 99/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7932 - mse: 72501.4219 \n","Epoch 100/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7957 - mse: 67788.1875  \n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n","\n","Full training dataset metrics:\n","{'MSE': 66830.8515625, 'MAE': 176.11476135253906, 'R2': -1329739.0, 'Avg Pearson Correlation': np.float64(0.5484743020570001), 'Avg Cosine Similarity': np.float32(0.2474872)}\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n","Test predictions saved.\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Random Forest Regressor**"],"metadata":{"id":"Ami_LtwT2Z2D"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","import pandas as pd\n","\n","# Custom Pearson correlation scorer\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","# Evaluation metrics\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","# Prepare data\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","# Train-validation split\n","X_train_split, X_val, y_train_split, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train model\n","base_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","model = MultiOutputRegressor(base_model)\n","model.fit(X_train_split, y_train_split)\n","\n","# Predictions\n","y_train_pred = model.predict(X_train_split)\n","y_val_pred = model.predict(X_val)\n","\n","# Evaluation\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# Train on full data\n","final_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n","final_model.fit(X, y)\n","y_pred=final_model.predict(X)\n","print(calculate_metrics(y, y_pred))\n","# Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = final_model.predict(X_test_arr)\n","\n","# Prepare submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('rf_test_pcalasso.csv', index=False)\n","print(\"Test predictions saved to rf_test_lasso.csv\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OMa9sFH7jzy","executionInfo":{"status":"ok","timestamp":1754642575548,"user_tz":-330,"elapsed":34900,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"936ad06f-17b8-4d94-c829-2dafe72276d9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","{'MSE': 0.00934896730862367, 'MAE': 0.05626918009350374, 'R2': 0.876410300528905, 'Avg Pearson Correlation': np.float64(0.9567009461033736), 'Avg Cosine Similarity': np.float64(0.9613587065569211)}\n","\n","Validation set metrics:\n","{'MSE': 0.06151586923210145, 'MAE': 0.14693716983373778, 'R2': 0.08960474620970418, 'Avg Pearson Correlation': np.float64(0.4194121582141943), 'Avg Cosine Similarity': np.float64(0.6485590860429554)}\n","{'MSE': 0.00873138695229087, 'MAE': 0.054592924932387, 'R2': 0.8819453732462094, 'Avg Pearson Correlation': np.float64(0.9560153387411587), 'Avg Cosine Similarity': np.float64(0.9626820188065544)}\n","Test predictions saved to rf_test_lasso.csv\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Randomforest 2**"],"metadata":{"id":"6CgPuqOv5UWE"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# --- Custom metrics ---\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr): corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    similarities = []\n","    for i in range(y_true.shape[0]):\n","        y_true_norm = y_true[i] / (np.linalg.norm(y_true[i]) + 1e-8)\n","        y_pred_norm = y_pred[i] / (np.linalg.norm(y_pred[i]) + 1e-8)\n","        similarity = np.dot(y_true_norm, y_pred_norm)\n","        similarities.append(similarity)\n","    return np.mean(similarities)\n","\n","def calculate_metrics(y_true, y_pred):\n","    return {\n","        \"MSE\": mean_squared_error(y_true, y_pred),\n","        \"MAE\": mean_absolute_error(y_true, y_pred),\n","        \"R2\": r2_score(y_true, y_pred),\n","        \"Avg Pearson Correlation\": pearson_correlation_score(y_true, y_pred),\n","        \"Avg Cosine Similarity\": cosine_similarity_score(y_true, y_pred),\n","    }\n","\n","# --------- Example workflow ---------\n","# These need to be set before running:\n","# X_df: DataFrame of features, y_df: DataFrame of targets (n_samples, n_targets)\n","# X_test_df: DataFrame of test features\n","# test_form: DataFrame with 'stimulus' column, matches rows of X_test_df\n","# target_cols: list of 51 string column names\n","\n","# 1. Convert to numpy if needed\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","X_test = X_test.to_numpy(dtype=np.float32)\n","\n","# 2. 80/20 split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 3. Train MultiOutput RandomForest\n","rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf.fit(X_train, y_train)\n","\n","# 4. Print metrics on splits\n","y_train_pred = rf.predict(X_train)\n","y_val_pred = rf.predict(X_val)\n","print(\"Training metrics:\")\n","print(calculate_metrics(y_train, y_train_pred))\n","print(\"\\nValidation metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# 5. Retrain on entire dataset, print metrics\n","rf_full = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf_full.fit(X, y)\n","y_full_pred = rf_full.predict(X)\n","print(\"\\nFull dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","# 6. Predict on test set, save file\n","test_preds = rf_full.predict(X_test)\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","test_submission.to_csv('rf_corr_cosine_metrics_test_pcalasso.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPwlXa2e5Otw","executionInfo":{"status":"ok","timestamp":1754642610515,"user_tz":-330,"elapsed":34973,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"efd10c40-f29c-4547-ea30-90e79065cac1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training metrics:\n","{'MSE': 0.00934896730862367, 'MAE': 0.05626918009350374, 'R2': 0.876410300528905, 'Avg Pearson Correlation': np.float64(0.9567009461033736), 'Avg Cosine Similarity': np.float64(0.962224419466831)}\n","\n","Validation metrics:\n","{'MSE': 0.06151586923210145, 'MAE': 0.14693716983373778, 'R2': 0.08960474620970418, 'Avg Pearson Correlation': np.float64(0.4194121582141943), 'Avg Cosine Similarity': np.float64(0.7126143602636336)}\n","\n","Full dataset metrics:\n","{'MSE': 0.00873138695229087, 'MAE': 0.054592924932387, 'R2': 0.8819453732462094, 'Avg Pearson Correlation': np.float64(0.9560153387411587), 'Avg Cosine Similarity': np.float64(0.9631158559207271)}\n","Test predictions saved.\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Xgboost**"],"metadata":{"id":"-hanjYk-62sN"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics import make_scorer\n","from sklearn.multioutput import MultiOutputRegressor\n","import xgboost as xgb\n","\n","# --------------- Metrics ---------------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    avg_pearson = pearson_correlation_score(y_true, y_pred)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson\n","    }\n","\n","# --------------- Custom Objectives for XGBoost ---------------\n","# They receive (preds, dtrain) and must return (grad, hess)\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative Pearson correlation loss.\n","    This is a rough approximation for demonstration only.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_mean = np.mean(preds)\n","    label_mean = np.mean(labels)\n","    pred_centered = preds - pred_mean\n","    label_centered = labels - label_mean\n","\n","    cov = np.sum(pred_centered * label_centered)\n","    pred_var = np.sum(pred_centered ** 2) + 1e-8\n","    label_var = np.sum(label_centered ** 2) + 1e-8\n","\n","    # Gradient (negative derivative of correlation)\n","    grad = - (label_centered / (np.sqrt(pred_var) * np.sqrt(label_var))) + \\\n","           (cov * pred_centered) / (pred_var ** 1.5 * np.sqrt(label_var))\n","\n","    # Hessian approximation with small constant\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative cosine similarity loss.\n","    Rough approximation for demonstration.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","\n","    cos_sim = np.dot(preds, labels) / (pred_norm * label_norm)\n","    grad = - (labels / (pred_norm * label_norm)) + \\\n","           (cos_sim * preds) / (pred_norm ** 2)\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","# --------------- Model Wrappers ---------------\n","\n","class XGBoostCorrelationRegressor:\n","    \"\"\"XGBoost regressor for single output with Pearson correlation loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=pearson_correlation_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        # y must be 1D for single output\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class XGBoostCosineSimilarityRegressor:\n","    \"\"\"XGBoost regressor for single output with Cosine similarity loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=cosine_similarity_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class MultiOutputXGBoostRegressor:\n","    \"\"\"Multi-output regressor as sklearn wrapper over XGBRegressor.\"\"\"\n","    def __init__(self, **kwargs):\n","        base_est = xgb.XGBRegressor(objective='reg:squarederror', **kwargs)\n","        self.model = MultiOutputRegressor(base_est)\n","\n","    def fit(self, X, y):\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","# --------------- Training & evaluation function ---------------\n","\n","def train_evaluate_save(model, X, y, X_test, test_form, target_cols, model_name=\"model\"):\n","    \"\"\"\n","    Train with 80/20 split, print evaluation, retrain on full data, print evaluation, predict on test, save CSV.\n","    \"\"\"\n","    print(f\"--- Training and evaluating {model_name} ---\")\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Train on split\n","    model.fit(X_train, y_train)\n","\n","    # Predict & evaluate on train and validation split\n","    y_train_pred = model.predict(X_train)\n","    y_val_pred = model.predict(X_val)\n","    print(\"Train Metrics:\", calculate_metrics(y_train, y_train_pred))\n","    print(\"Validation Metrics:\", calculate_metrics(y_val, y_val_pred))\n","\n","    # Retrain on full dataset\n","    model.fit(X, y)\n","    y_full_pred = model.predict(X)\n","    print(\"Full Data Metrics:\", calculate_metrics(y, y_full_pred))\n","\n","    # Predict on test data\n","    test_preds = model.predict(X_test)\n","\n","    # Save predictions file\n","    test_submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        test_submission[col] = test_preds[:, i] if test_preds.shape[1] > 1 else test_preds[:, 0]\n","\n","    output_file = f'{model_name}_test_pcalasso.csv'\n","    test_submission.to_csv(output_file, index=False)\n","    print(f\"Test predictions saved to {output_file}\")\n","    print(f\"Test submission shape: {test_submission.shape}\\n\")\n","\n","# --------------- Usage Notes ---------------\n","# Variables you must have prepared before calling:\n","\n","# X: numpy array of shape (n_samples, n_features)\n","# y: numpy array of shape (n_samples, 51) - targets\n","# X_test: numpy array for test features, shape (n_test_samples, n_features)\n","# test_form: pandas DataFrame with 'stimulus' column for test samples\n","# target_cols: list of 51 odor descriptor column names, matching y columns\n","\n","# Example calls (uncomment and set your datasets appropriately):\n","#\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","model_pearson = MultiOutputXGBoostRegressor()  # Multitarget with standard MSE\n","train_evaluate_save(model_pearson, X, y, X_test, test_form, target_cols, model_name=\"MultiOutputXGBoost_MSE\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1yk7lN9vDvT2","executionInfo":{"status":"ok","timestamp":1754642629027,"user_tz":-330,"elapsed":18514,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"272b1495-24e2-4e1e-ba99-7d862c669f28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Training and evaluating MultiOutputXGBoost_MSE ---\n","Train Metrics: {'MSE': 0.0002666337531991303, 'MAE': 0.0016083167865872383, 'R2': 0.9982136487960815, 'Avg Pearson Correlation': np.float64(0.9991032089355377)}\n","Validation Metrics: {'MSE': 0.07507400214672089, 'MAE': 0.15649820864200592, 'R2': -0.18404369056224823, 'Avg Pearson Correlation': np.float64(0.3587408054550242)}\n","Full Data Metrics: {'MSE': 0.00021741546515841037, 'MAE': 0.0021510650403797626, 'R2': 0.9985148906707764, 'Avg Pearson Correlation': np.float64(0.9992607779185715)}\n","Test predictions saved to MultiOutputXGBoost_MSE_test_pcalasso.csv\n","Test submission shape: (31, 52)\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# ------- Custom metrics -------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        corrs.append(0 if np.isnan(corr) else corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        if np.linalg.norm(y_true[:, i]) > 0 and np.linalg.norm(y_pred[:, i]) > 0:\n","            cs = cosine_similarity(y_true[:, i].reshape(1, -1), y_pred[:, i].reshape(1, -1))[0, 0]\n","        else:\n","            cs = 0\n","        cos_sims.append(cs)\n","    return np.mean(cos_sims)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    pearson = pearson_correlation_score(y_true, y_pred)\n","    cosine = cosine_similarity_score(y_true, y_pred)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': pearson,\n","        'Avg Cosine Similarity': cosine\n","    }\n","\n","# ------- Custom objectives for XGBoost -------\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    y_true_mean = np.mean(labels)\n","    y_pred_mean = np.mean(preds)\n","    y_true_centered = labels - y_true_mean\n","    y_pred_centered = preds - y_pred_mean\n","    numerator = np.sum(y_true_centered * y_pred_centered)\n","    y_true_std = np.sqrt(np.sum(y_true_centered**2)) + 1e-8\n","    y_pred_std = np.sqrt(np.sum(y_pred_centered**2)) + 1e-8\n","    denominator = y_true_std * y_pred_std\n","\n","    d_numerator = y_true_centered\n","    d_y_pred_std = y_pred_centered / y_pred_std\n","    d_denominator = y_true_std * d_y_pred_std\n","\n","    gradient = -(d_numerator * denominator - numerator * d_denominator) / (denominator ** 2)\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","    y_true_normalized = labels / label_norm\n","    y_pred_normalized = preds / pred_norm\n","\n","    gradient = - y_true_normalized / pred_norm\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","# ------- Training function per model -------\n","\n","def train_custom_xgb_model(X, y, X_val, y_val, X_test, test_form, target_cols, custom_obj, model_name):\n","    print(f\"Training {model_name} ...\")\n","\n","    val_preds = []\n","    val_trues = []\n","\n","    test_preds = np.zeros((X_test.shape[0], y.shape[1]))\n","\n","    for i, col in enumerate(target_cols):\n","        print(f\"Training target: {col}\")\n","        # create DMatrix for training\n","        dtrain = xgb.DMatrix(X, label=y[:, i])\n","        dval = xgb.DMatrix(X_val, label=y_val[:, i])\n","        params = {\n","            'objective': 'reg:squarederror',  # ignored because of custom obj\n","            'max_depth': 6,\n","            'learning_rate': 0.1,\n","            'verbosity': 0,\n","            'seed': 42,\n","        }\n","        # Train model with early stopping evaluated on val split\n","        model = xgb.train(\n","            params,\n","            dtrain,\n","            num_boost_round=100,\n","            obj=custom_obj,\n","            evals=[(dval, 'validation')],\n","            early_stopping_rounds=10,\n","            verbose_eval=False\n","        )\n","\n","        # Predict validation\n","        val_pred = model.predict(dval)\n","        val_preds.append(val_pred)\n","        val_trues.append(y_val[:, i])\n","\n","        # Refit on full data for test prediction\n","        dfull = xgb.DMatrix(X, label=y[:, i])\n","        model_full = xgb.train(params, dfull, num_boost_round=model.best_iteration or 100, obj=custom_obj, verbose_eval=False)\n","\n","        dtest = xgb.DMatrix(X_test)\n","        test_preds[:, i] = model_full.predict(dtest)\n","\n","    # Aggregate validation results\n","    val_preds_arr = np.column_stack(val_preds)\n","    val_trues_arr = np.column_stack(val_trues)\n","\n","    print(f\"{model_name} - Validation metrics (aggregated):\")\n","    print(calculate_metrics(val_trues_arr, val_preds_arr))\n","\n","    # Save test predictions\n","    submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        submission[col] = test_preds[:, i]\n","    submission_file = f\"{model_name}_test_pcalasso.csv\"\n","    submission.to_csv(submission_file, index=False)\n","    print(f\"Saved test predictions to {submission_file}\")\n","\n","# ------- Prepare data -------\n","\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","target_cols = target_cols  # list of 51 target column names\n","test_form_df = test_form  # contains 'stimulus'\n","\n","\n","# Split train data for validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# ------- Run models -------\n","\n","# 1. Pearson correlation objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    pearson_correlation_obj, \"XGBoost_PearsonCorrelation\"\n",")\n","\n","# 2. Cosine similarity objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    cosine_similarity_obj, \"XGBoost_CosineSimilarity\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vccgUip_XjH_","executionInfo":{"status":"ok","timestamp":1754642638588,"user_tz":-330,"elapsed":9563,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"65700b95-eb77-4130-b817-3538c283be61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training XGBoost_PearsonCorrelation ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_PearsonCorrelation - Validation metrics (aggregated):\n","{'MSE': 8264572469248.0, 'MAE': 2232969.0, 'R2': -293723619459072.0, 'Avg Pearson Correlation': np.float64(0.3368046144957702), 'Avg Cosine Similarity': np.float32(0.21379586)}\n","Saved test predictions to XGBoost_PearsonCorrelation_test_pcalasso.csv\n","Training XGBoost_CosineSimilarity ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_CosineSimilarity - Validation metrics (aggregated):\n","{'MSE': 0.22139431536197662, 'MAE': 0.43590500950813293, 'R2': -8.23885440826416, 'Avg Pearson Correlation': np.float64(0.3273298783161023), 'Avg Cosine Similarity': np.float32(0.5672276)}\n","Saved test predictions to XGBoost_CosineSimilarity_test_pcalasso.csv\n"]}]}]}
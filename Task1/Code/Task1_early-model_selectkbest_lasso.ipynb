{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1xzRnW9nGcNNKYKa250R3OPRfsH31cpgS","timestamp":1754717100982},{"file_id":"1cLWOpwM9ylFpyChS9G0Jyc5XFSclHrg_","timestamp":1754639968591},{"file_id":"16uRrQ8WMhyYVzyGQRLsvp6EwVAzbjQ4s","timestamp":1754638155755},{"file_id":"1fs34Kt_qmjsBJzqia_GDxsZu1d6d5bAW","timestamp":1754637118958},{"file_id":"1TvwoXmPrfc-sz5Ovn9pFfxbANH0wGGTD","timestamp":1754634143244}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KECSKhWS4K6Z","executionInfo":{"status":"ok","timestamp":1754645725994,"user_tz":-330,"elapsed":1740,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"0ed8af9a-9563-4687-9226-4110f9ca3df0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading data files...\n","CID data shape: (209, 3)\n","molecular_features shape: (209, 3714)\n","Training data shape: (237, 52)\n","Stimulus definition shape: (302, 5)\n","Leaderboard form shape: (34, 52)\n","Test form shape: (31, 52)\n","OpenPOM data not found\n","Data loaded successfully!\n"]}],"source":["import pandas as pd\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","\n","# Initialize scalers and encoders\n","molecular_scaler = StandardScaler()\n","target_scaler = StandardScaler()\n","solvent_encoder = LabelEncoder()\n","\n","print(\"Loading data files...\")\n","\n","# Load CID data\n","cid_data = pd.read_csv('CID.csv', encoding='latin1')\n","print(f\"CID data shape: {cid_data.shape}\")\n","\n","# Load Mordred descriptors with encoding fallback\n","try:\n","    mordred_descriptors = pd.read_csv('concatenated_fingerprints.csv', encoding='utf-8')\n","except UnicodeDecodeError:\n","    try:\n","        mordred_descriptors = pd.read_csv('concatenated_fingerprints.csv', encoding='latin1')\n","    except:\n","        mordred_descriptors = pd.read_csv('Concatenated_Fingerprints.csv', encoding='cp1252')\n","print(f\"molecular_features shape: {mordred_descriptors.shape}\")\n","\n","\n","\n","# Load training data\n","training_data = pd.read_csv('TASK1_training.csv', encoding='latin1')\n","print(f\"Training data shape: {training_data.shape}\")\n","\n","# Load stimulus definitions\n","stimulus_def = pd.read_csv('TASK1_Stimulus_definition.csv', encoding='latin1')\n","print(f\"Stimulus definition shape: {stimulus_def.shape}\")\n","\n","# Load submission forms\n","leaderboard_form = pd.read_csv('TASK1_leaderboard_set_Submission_form.csv', encoding='latin1')\n","test_form = pd.read_csv('TASK1_test_set_Submission_form.csv', encoding='latin1')\n","\n","print(f\"Leaderboard form shape: {leaderboard_form.shape}\")\n","print(f\"Test form shape: {test_form.shape}\")\n","\n","# Load OpenPOM (optional)\n","try:\n","    openpom_data = pd.read_csv('OpenPOM_Dream_RATA.csv', encoding='latin1')\n","    print(f\"OpenPOM data shape: {openpom_data.shape}\")\n","except:\n","    openpom_data = None\n","    print(\"OpenPOM data not found\")\n","\n","print(\"Data loaded successfully!\")\n"]},{"cell_type":"code","source":["\n","# Prepare Mordred features with cleaned data\n","# Regenerate list of valid feature columns from cleaned Mordred\n","mordred_feature_cols_clean = [col for col in mordred_descriptors.columns if col not in ['molecule', 'SMILES']]\n","\n","molecular_features = mordred_descriptors[['molecule'] + mordred_feature_cols_clean].copy()\n","\n","\n","#morgan_features.columns = ['molecule'] + [f'morgan_{col}' for col in morgan_feature_cols]\n","\n","# Merge molecular features\n","#molecular_features = pd.merge(mordred_features, morgan_features, on='molecule', how='inner')\n","\n","\n","print(f\"\\n=== FINAL MOLECULAR FEATURES ===\")\n","print(f\"Combined molecular features shape: {molecular_features.shape}\")\n","print(f\"Molecules with complete features: {len(molecular_features['molecule'].unique())}\")\n","\n","# Verify no NaN values remain\n","remaining_nans = molecular_features.isnull().sum().sum()\n","print(f\"Remaining NaN values in final dataset: {remaining_nans}\")\n","\n","if remaining_nans == 0:\n","    print(\"✅ All NaN values successfully handled!\")\n","else:\n","    print(\"⚠️  Warning: Some NaN values still remain\")\n","\n","print(\"\\n=== PREPARING TRAINING DATA ===\")\n","\n","# Reuse molecular_features if already created in previous cell\n","# If not, rerun the \"Prepare Molecular Features\" cell above\n","\n","# Merge training data with stimulus definitions\n","train_with_stimulus = pd.merge(\n","    training_data,\n","    stimulus_def,\n","    on='stimulus',\n","    how='left'\n",")\n","\n","print(f\"Training data with stimulus info shape: {train_with_stimulus.shape}\")\n","print(f\"Missing stimulus definitions: {train_with_stimulus['molecule'].isna().sum()}\")\n","\n","# Merge with molecular features\n","train_complete = pd.merge(\n","    train_with_stimulus,\n","    molecular_features,\n","    on='molecule', how='left'\n",")\n","\n","print(f\"Complete training data shape: {train_complete.shape}\")\n","\n","print(f\"Missing molecular features: {train_complete.isnull().any(axis=1).sum()}\")\n","\n","# Remove rows with missing data\n","print(f\"Training data after removing missing: {train_complete.shape}\")\n","\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","# Drop rows with missing molecule\n","train_data = train_complete\n","# Target columns\n","target_cols = ['Green', 'Cucumber', 'Herbal', 'Mint', 'Woody', 'Pine', 'Floral',\n","               'Powdery', 'Fruity', 'Citrus', 'Tropical', 'Berry', 'Peach', 'Sweet',\n","               'Caramellic', 'Vanilla', 'BrownSpice', 'Smoky', 'Burnt', 'Roasted',\n","               'Grainy', 'Meaty', 'Nutty', 'Fatty', 'Coconut', 'Waxy', 'Dairy',\n","               'Buttery', 'Cheesy', 'Sour', 'Fermented', 'Sulfurous', 'Garlic.Onion',\n","               'Earthy', 'Mushroom', 'Musty', 'Ammonia', 'Fishy', 'Fecal',\n","               'Rotten.Decay', 'Rubber', 'Phenolic', 'Animal', 'Medicinal',\n","               'Cooling', 'Sharp', 'Chlorine', 'Alcoholic', 'Plastic', 'Ozone', 'Metallic']\n","\n","# Feature columns = all except IDs + targets\n","non_feature_cols = ['molecule', 'SMILES', 'stimulus', 'Intensity_label', 'solvent', 'dilution'] + target_cols\n","feature_cols = [col for col in train_data.columns if col not in non_feature_cols]\n","# Prepare input features\n","X_molecular = train_data[feature_cols].fillna(0).values\n","X_concentration = np.log10(train_data['dilution'].fillna(0.001)).values.reshape(-1, 1)\n","\n","solvent_encoder = LabelEncoder()\n","X_solvent = solvent_encoder.fit_transform(train_data['solvent'].fillna('PG')).reshape(-1, 1)\n","\n","intensity_encoder = LabelEncoder()\n","X_intensity = intensity_encoder.fit_transform(train_data['Intensity_label'].fillna('L')).reshape(-1, 1)\n","\n","# Concatenate all feature blocks into a DataFrame\n","X_df = pd.concat([\n","    pd.DataFrame(X_molecular, columns=[str(c) for c in feature_cols]),\n","    pd.DataFrame(X_concentration, columns=['log_dilution']),\n","    pd.DataFrame(X_solvent, columns=['solvent_encoded']),\n","    pd.DataFrame(X_intensity, columns=['intensity_encoded'])\n","], axis=1)\n","\n","# Convert to NumPy array for PyTorch\n","X_np = X_df.values.astype(np.float32)\n","\n","# y: shape (num_samples, num_targets)\n","y_np = train_data[target_cols].fillna(0).values.astype(np.float32)\n","y_df = pd.DataFrame(y_np, columns=target_cols)\n","\n","def prepare_test_data(form_df, stimulus_def, molecular_features, feature_cols,\n","                      solvent_encoder, intensity_encoder, molecular_scaler, set_name=\"test\"):\n","    \"\"\"Prepare test data for prediction (returns Pandas DataFrame)\"\"\"\n","    print(f\"\\n=== PREPARING {set_name.upper()} DATA ===\")\n","\n","    # Merge with stimulus definitions\n","    test_with_stimulus = pd.merge(\n","        form_df,\n","        stimulus_def,\n","        on='stimulus',\n","        how='left'\n","    )\n","\n","    print(f\"{set_name} data with stimulus info shape: {test_with_stimulus.shape}\")\n","    print(f\"Missing stimulus definitions: {test_with_stimulus['molecule'].isna().sum()}\")\n","\n","    # Merge with molecular features\n","    test_complete = pd.merge(\n","        test_with_stimulus,\n","        molecular_features,\n","        on='molecule',\n","        how='left'\n","    )\n","\n","    print(f\"Complete {set_name} data shape: {test_complete.shape}\")\n","    print(test_complete.columns)\n","    # Molecular features (as DataFrame)\n","    X_molecular = test_complete[feature_cols].copy()\n","\n","    # Concentration (log-scaled)\n","    X_concentration = np.log10(test_complete['dilution'].fillna(0.001) + 1e-10)\n","    X_concentration = pd.DataFrame(X_concentration, columns=['log_dilution'])\n","\n","    # Solvent encoding\n","    solvent_filled = test_complete['solvent'].fillna('PG')\n","    X_solvent = pd.DataFrame(solvent_encoder.transform(solvent_filled), columns=['solvent_encoded'])\n","\n","    # Intensity encoding\n","    intensity_filled = test_complete['Intensity_label'].fillna('L')\n","    X_intensity = pd.DataFrame(intensity_encoder.transform(intensity_filled), columns=['intensity_encoded'])\n","\n","    # Combine all into a single DataFrame\n","    X_all = pd.concat([X_molecular, X_concentration, X_solvent, X_intensity], axis=1)\n","\n","    # Handle missing values and enforce numeric type\n","    X_all = X_all.fillna(0.0).astype(np.float32)\n","\n","    # Optional: apply scaler if needed\n","    # X_scaled = molecular_scaler.transform(X_all)  # Uncomment if you want scaling\n","    # X_all = pd.DataFrame(X_scaled, columns=X_all.columns)  # Maintain column names\n","\n","    return X_all, test_complete\n","\n","import pandas as pd\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler, LabelEncoder\n","from sklearn.model_selection import train_test_split\n","\n","X_test, test_data = prepare_test_data(\n","    form_df=test_form,\n","    stimulus_def=stimulus_def,\n","    molecular_features=molecular_features,\n","    feature_cols=feature_cols,\n","    solvent_encoder=solvent_encoder,\n","    intensity_encoder=intensity_encoder,\n","    molecular_scaler=molecular_scaler\n",")\n","# Load the selected feature names from Lasso\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P42CaMFc73TU","executionInfo":{"status":"ok","timestamp":1754645726708,"user_tz":-330,"elapsed":724,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"14cb2c87-6f4b-47ba-8926-b9fe3d47833f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","=== FINAL MOLECULAR FEATURES ===\n","Combined molecular features shape: (209, 3713)\n","Molecules with complete features: 209\n","Remaining NaN values in final dataset: 0\n","✅ All NaN values successfully handled!\n","\n","=== PREPARING TRAINING DATA ===\n","Training data with stimulus info shape: (237, 56)\n","Missing stimulus definitions: 0\n","Complete training data shape: (237, 3768)\n","Missing molecular features: 0\n","Training data after removing missing: (237, 3768)\n","\n","=== PREPARING TEST DATA ===\n","test data with stimulus info shape: (31, 56)\n","Missing stimulus definitions: 0\n","Complete test data shape: (31, 3768)\n","Index(['stimulus', 'Green', 'Cucumber', 'Herbal', 'Mint', 'Woody', 'Pine',\n","       'Floral', 'Powdery', 'Fruity',\n","       ...\n","       'SRW10', 'TSRW10', 'MW', 'AMW', 'WPath', 'WPol', 'Zagreb1', 'Zagreb2',\n","       'mZagreb1', 'mZagreb2'],\n","      dtype='object', length=3768)\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-1376930417.py:147: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n","  X_all = X_all.fillna(0.0).astype(np.float32)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.feature_selection import SelectKBest, f_regression\n","\n","def select_k_best_features(x_df, y_df, k=50):\n","    \"\"\"\n","    Select top k features with SelectKBest for multi-output regression by\n","    averaging F-scores across all target columns.\n","\n","    Parameters:\n","        x_df (pd.DataFrame): Feature dataframe\n","        y_df (pd.DataFrame): Multi-output target dataframe\n","        k (int): Number of top features to select\n","\n","    Returns:\n","        X_selected_df (pd.DataFrame): DataFrame with top k features selected (train data)\n","    \"\"\"\n","\n","    # Convert to numpy\n","    X = x_df.values\n","    y = y_df.values\n","\n","    # We'll collect scores for each target\n","    all_scores = []\n","    for i in range(y.shape[1]):\n","        # Compute f_regression univariate scores for this target\n","        scores, _ = f_regression(X, y[:, i])\n","        all_scores.append(scores)\n","\n","    # Average scores across all targets\n","    avg_scores = np.mean(np.array(all_scores), axis=0)\n","\n","    # Select indices of top k scores\n","    top_k_indices = np.argsort(avg_scores)[::-1][:k]\n","\n","    # Subset dataframe to these columns\n","    selected_columns = x_df.columns[top_k_indices]\n","    X_selected_df = x_df.loc[:, selected_columns]\n","\n","    return X_selected_df\n","\n","# Example usage:\n","x_df_lasso = select_k_best_features(X_df, y_df, k=50)\n","selected_features_lasso = x_df_lasso.columns.tolist()\n","\n","# Filter X_df to contain only the selected features\n","X_test = X_test[selected_features_lasso]"],"metadata":{"id":"pKE40RMdw-TH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_df_lasso.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Em07xkjL5m2h","executionInfo":{"status":"ok","timestamp":1754645731038,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"fc2c5876-a0f0-472a-c373-78ddc8fec727"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  map4_r2_bit_827 MACCS_88 nS   BCUTv-1h   BCUTi-1l  BCUTp-1h    AMID_C  \\\n","0               0        0  0  20.758641  11.082845  1.854676  1.329362   \n","1               0        0  0  20.870875  10.981705  1.964262  1.798521   \n","2               0        0  0  20.730448  11.107868  1.831248  1.303998   \n","3               1        0  0  20.776633  11.069523  1.872181  1.611501   \n","4               0        0  0  20.758641  11.082845  1.854676  1.329362   \n","\n","        MIC0 TopoPSA   AATSC0p  ... map4_r2_bit_715 BCUTse-1l    AATS0p  \\\n","0   12.50226    37.3  0.201457  ...               0  2.564947  1.157473   \n","1   9.437219   17.07  0.230987  ...               0  2.466161  1.310805   \n","2  12.019278   17.07  0.204856  ...               0  2.586632  1.167758   \n","3   11.24654    26.3  0.218205  ...               0  2.554329  1.240752   \n","4   12.50226    37.3  0.201457  ...               0  2.564947  1.157473   \n","\n","   SpDiam_A     AATS1m SlogP_VSA5 MINssS MAXssS      ATS4s         ATS4i  \n","0  3.863703  67.904703  26.186202    0.0    0.0  74.166667   4618.210326  \n","1  4.469763  66.566563  52.372404    0.0    0.0      149.0  11145.749014  \n","2  3.236068   61.48164  13.344559    0.0    0.0       24.0   1110.305786  \n","3  4.261308   71.27105  45.448667    0.0    0.0     111.75   9303.464215  \n","4  3.863703  67.904703  26.186202    0.0    0.0  74.166667   4618.210326  \n","\n","[5 rows x 50 columns]\n"]}]},{"cell_type":"markdown","source":["# **Hyperbolic Model**"],"metadata":{"id":"dkuRAgL-z76S"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class PearsonCosineLoss(nn.Module):\n","    def __init__(self, alpha=0.5, eps=1e-8):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.eps = eps\n","        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=eps)\n","\n","    def forward(self, y_pred, y_true):\n","        # Pearson Correlation (1 - correlation for minimization)\n","        y_pred_centered = y_pred - y_pred.mean(dim=1, keepdim=True)\n","        y_true_centered = y_true - y_true.mean(dim=1, keepdim=True)\n","        numerator = (y_pred_centered * y_true_centered).sum(dim=1)\n","        denominator = (y_pred_centered.pow(2).sum(dim=1) * y_true_centered.pow(2).sum(dim=1)).sqrt() + self.eps\n","        pearson_corr = numerator / denominator\n","        pearson_loss = 1 - pearson_corr\n","\n","        # Cosine Similarity (1 - similarity for minimization)\n","        cosine_loss = 1 - self.cosine_similarity(y_pred, y_true)\n","        loss = self.alpha * pearson_loss + (1 - self.alpha) * cosine_loss\n","        return loss.mean()\n","class HyperbolicModel(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, output_dim)\n","        self.tanh = nn.Tanh()\n","    def forward(self, x):\n","        x = self.tanh(self.fc1(x))\n","        x = self.tanh(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    corrs = [np.corrcoef(y_true[:,i], y_pred[:,i])[0,1] if np.std(y_true[:,i])>0 and np.std(y_pred[:,i])>0 else 0 for i in range(y_true.shape[1])]\n","    avg_pearson = np.mean(corrs)\n","    norms_true = np.linalg.norm(y_true, axis=1)\n","    norms_pred = np.linalg.norm(y_pred, axis=1)\n","    cos = np.sum(y_true * y_pred, axis=1) / (norms_true * norms_pred + 1e-8)\n","    avg_cosine = np.mean(cos)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine\n","    }\n","\n","# Training routine\n","def train_and_evaluate(X, y, test_ratio=0.2, epochs=100, lr=1e-3, batch_size=32, alpha=0.5):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # Split\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_ratio, random_state=42)\n","    X_train_t = torch.FloatTensor(X_train).to(device)\n","    y_train_t = torch.FloatTensor(y_train).to(device)\n","    X_val_t = torch.FloatTensor(X_val).to(device)\n","    y_val_t = torch.FloatTensor(y_val).to(device)\n","\n","    # Model\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    loss_fn = PearsonCosineLoss(alpha=alpha)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    n = X_train.shape[0]\n","    steps_per_epoch = int(np.ceil(n / batch_size))\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        idx = np.random.permutation(n)\n","        for i in range(steps_per_epoch):\n","            batch_idx = idx[i*batch_size:(i+1)*batch_size]\n","            xb = X_train_t[batch_idx]\n","            yb = y_train_t[batch_idx]\n","            optimizer.zero_grad()\n","            y_pred = model(xb)\n","            loss = loss_fn(y_pred, yb)\n","            loss.backward()\n","            optimizer.step()\n","        if (epoch+1) % 20 == 0:\n","            print(f\"Epoch {epoch+1}/{epochs}: Train Loss = {loss.item():.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        y_train_pred = model(X_train_t).cpu().numpy()\n","        y_val_pred = model(X_val_t).cpu().numpy()\n","\n","    # Print metrics on split data\n","    train_metrics = calculate_metrics(y_train, y_train_pred)\n","    val_metrics = calculate_metrics(y_val, y_val_pred)\n","    print(\"\\\\nTrain Metrics:\", train_metrics)\n","    print(\"Validation Metrics:\", val_metrics)\n","\n","    # Retrain on full data\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    X_full_t = torch.FloatTensor(X).to(device)\n","    y_full_t = torch.FloatTensor(y).to(device)\n","    for epoch in range(epochs):\n","        optimizer.zero_grad()\n","        y_pred = model(X_full_t)\n","        loss = loss_fn(y_pred, y_full_t)\n","        loss.backward()\n","        optimizer.step()\n","    model.eval()\n","    with torch.no_grad():\n","        y_full_pred = model(X_full_t).cpu().numpy()\n","    full_metrics = calculate_metrics(y, y_full_pred)\n","    print(\"\\\\nMetrics on Full Data:\", full_metrics)\n","    return model, device\n","# Run training and print metrics\n","model, device = train_and_evaluate(\n","    x_df_lasso.to_numpy(dtype=np.float32),\n","    y_df.to_numpy(dtype=np.float32),\n","    test_ratio=0.2,\n","    epochs=100,\n","    lr=1e-3,\n","    batch_size=32,\n","    alpha=0.5\n",")\n","\n","# Convert all columns to numeric (with NaNs where conversion failed)\n","X_test_numeric = X_test.apply(pd.to_numeric, errors='coerce')\n","\n","# Fill NaN values (e.g., with 0 or other imputation strategy)\n","X_test_filled = X_test_numeric.fillna(0)\n","\n","# Convert to numpy array of floats\n","X_test_arr = X_test_filled.to_numpy(dtype=np.float32)\n","with torch.no_grad():\n","    X_test_tensor = torch.FloatTensor(X_test_arr).to(device)\n","    test_preds = model(X_test_tensor).cpu().numpy()\n","\n","# Save submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","\n","test_submission.to_csv('hyperbolic_task1_selectKBest.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKn1rTrhN47u","executionInfo":{"status":"ok","timestamp":1754645742585,"user_tz":-330,"elapsed":11552,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"f567e963-caa2-472e-8959-400a5efb6442"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 20/100: Train Loss = 0.4527\n","Epoch 40/100: Train Loss = 0.5017\n","Epoch 60/100: Train Loss = 0.4439\n","Epoch 80/100: Train Loss = 0.4849\n","Epoch 100/100: Train Loss = 0.4251\n","\\nTrain Metrics: {'MSE': 0.11515966057777405, 'MAE': 0.24492044746875763, 'R2': -0.4235658049583435, 'Avg Pearson Correlation': np.float64(0.27536956949576225), 'Avg Cosine Similarity': np.float32(0.6566249)}\n","Validation Metrics: {'MSE': 0.11577176302671432, 'MAE': 0.24947431683540344, 'R2': -0.7897145748138428, 'Avg Pearson Correlation': np.float64(0.10494987412849391), 'Avg Cosine Similarity': np.float32(0.62958616)}\n","\\nMetrics on Full Data: {'MSE': 0.13216489553451538, 'MAE': 0.2778971195220947, 'R2': -0.7331598401069641, 'Avg Pearson Correlation': np.float64(0.24429130359248113), 'Avg Cosine Similarity': np.float32(0.64507717)}\n","Test predictions saved.\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Correlation Regressor**"],"metadata":{"id":"d6XCJgfl0g16"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","\n","\n","# Pearson correlation loss (maximize correlation by minimizing negative correlation)\n","def pearson_correlation_loss(y_true, y_pred):\n","    y_true_centered = y_true - tf.reduce_mean(y_true, axis=1, keepdims=True)\n","    y_pred_centered = y_pred - tf.reduce_mean(y_pred, axis=1, keepdims=True)\n","    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n","    denominator = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered), axis=1)) * tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered), axis=1))\n","    correlation = numerator / (denominator + 1e-8)\n","    return -tf.reduce_mean(correlation)\n","\n","\n","def create_olfactory_model(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(128, activation='relu', input_shape=(input_dim,)),\n","        Dense(64, activation='relu'),\n","        Dense(output_dim, activation='linear')\n","    ])\n","    model.compile(optimizer='adam', loss=pearson_correlation_loss, metrics=['mse'])\n","    return model\n","\n","\n","class CorrelationRegressor(BaseEstimator, RegressorMixin):\n","    def __init__(self, input_dim=None, output_dim=None, epochs=100, batch_size=32, verbose=0):\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.verbose = verbose\n","        self.model_ = None\n","\n","    def fit(self, X, y):\n","        if self.input_dim is None:\n","            self.input_dim = X.shape[1]\n","        if self.output_dim is None:\n","            self.output_dim = y.shape[1] if len(y.shape) > 1 else 1\n","        self.model_ = create_olfactory_model(self.input_dim, self.output_dim)\n","        self.model_.fit(\n","            X, y,\n","            epochs=self.epochs,\n","            batch_size=self.batch_size,\n","            verbose=self.verbose\n","        )\n","        return self\n","\n","    def predict(self, X):\n","        if self.model_ is None:\n","            raise ValueError(\"Model not fitted yet\")\n","        return self.model_.predict(X)\n","\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","\n","# Convert DataFrames to numpy arrays\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","\n","# 1. Split data 80% train, 20% validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","\n","# 2. Initialize regressor\n","regressor = CorrelationRegressor(\n","    input_dim=X_train_split.shape[1],\n","    output_dim=y_train_split.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","\n","# 3. Train on 80% split\n","regressor.fit(X_train_split, y_train_split)\n","\n","# 4. Evaluate on train split and validation split\n","y_train_pred = regressor.predict(X_train_split)\n","y_val_pred = regressor.predict(X_val)\n","\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","\n","# 5. Train on full dataset (train + val)\n","regressor_full = CorrelationRegressor(\n","    input_dim=X.shape[1],\n","    output_dim=y.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","regressor_full.fit(X, y)\n","\n","# 6. Evaluate on entire training dataset\n","y_full_pred = regressor_full.predict(X)\n","print(\"\\nFull training dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","\n","# 7. Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = regressor_full.predict(X_test_arr)\n","\n","# 8. Save submission file\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('corr_test_selectKBest.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2EGVulygyAxt","executionInfo":{"status":"ok","timestamp":1754645765920,"user_tz":-330,"elapsed":23339,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"6b64308b-06f7-472e-ff99-3fafbd9cf2aa"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - loss: -0.0653 - mse: 394162.5312\n","Epoch 2/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.1630 - mse: 384175.9062\n","Epoch 3/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2529 - mse: 410569.1562 \n","Epoch 4/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.2958 - mse: 390472.7812 \n","Epoch 5/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3326 - mse: 432994.6562 \n","Epoch 6/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3406 - mse: 471260.8125 \n","Epoch 7/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3680 - mse: 469193.8750 \n","Epoch 8/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3784 - mse: 524424.6250 \n","Epoch 9/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3851 - mse: 553726.0000 \n","Epoch 10/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4010 - mse: 518931.7188 \n","Epoch 11/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3796 - mse: 499021.8750 \n","Epoch 12/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3762 - mse: 471570.8750 \n","Epoch 13/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3789 - mse: 487089.1250 \n","Epoch 14/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3845 - mse: 450237.8750 \n","Epoch 15/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4033 - mse: 421083.7500 \n","Epoch 16/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3914 - mse: 411551.7812 \n","Epoch 17/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3817 - mse: 405149.0000 \n","Epoch 18/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3929 - mse: 399829.1562 \n","Epoch 19/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3923 - mse: 389498.5625  \n","Epoch 20/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3880 - mse: 357402.9375 \n","Epoch 21/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4087 - mse: 330833.8750 \n","Epoch 22/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3936 - mse: 329394.9375 \n","Epoch 23/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3993 - mse: 297567.6250 \n","Epoch 24/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4148 - mse: 279944.6875 \n","Epoch 25/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4085 - mse: 258980.6094 \n","Epoch 26/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4133 - mse: 257064.1094 \n","Epoch 27/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4150 - mse: 247103.8594 \n","Epoch 28/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.3973 - mse: 217471.4062 \n","Epoch 29/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4017 - mse: 205977.4219 \n","Epoch 30/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4214 - mse: 179355.0312 \n","Epoch 31/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4175 - mse: 182926.9219 \n","Epoch 32/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4081 - mse: 168769.0938 \n","Epoch 33/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4193 - mse: 169366.4531 \n","Epoch 34/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4016 - mse: 146392.4062 \n","Epoch 35/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3919 - mse: 128903.4766 \n","Epoch 36/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4214 - mse: 127152.0078 \n","Epoch 37/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4354 - mse: 117426.5781 \n","Epoch 38/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4260 - mse: 107708.6641\n","Epoch 39/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4147 - mse: 100252.2109\n","Epoch 40/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4377 - mse: 94335.3203 \n","Epoch 41/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4322 - mse: 94241.8438  \n","Epoch 42/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4292 - mse: 80497.8594 \n","Epoch 43/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4217 - mse: 64594.2266 \n","Epoch 44/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4326 - mse: 60313.4883 \n","Epoch 45/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4255 - mse: 52447.3164 \n","Epoch 46/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4539 - mse: 40158.6875 \n","Epoch 47/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4513 - mse: 30783.2695 \n","Epoch 48/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4476 - mse: 30576.3340 \n","Epoch 49/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4351 - mse: 27944.3652 \n","Epoch 50/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4592 - mse: 25185.7188 \n","Epoch 51/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.4554 - mse: 23781.3770 \n","Epoch 52/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4721 - mse: 21669.7539 \n","Epoch 53/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4697 - mse: 20749.3496 \n","Epoch 54/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4654 - mse: 17474.6680 \n","Epoch 55/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4648 - mse: 17378.2969 \n","Epoch 56/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4727 - mse: 16750.5566 \n","Epoch 57/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4761 - mse: 16980.3203 \n","Epoch 58/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4802 - mse: 16809.2324 \n","Epoch 59/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4758 - mse: 16553.9277 \n","Epoch 60/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4869 - mse: 15592.3330 \n","Epoch 61/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4742 - mse: 13810.6260 \n","Epoch 62/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4678 - mse: 15149.4189 \n","Epoch 63/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4851 - mse: 16672.4062 \n","Epoch 64/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4692 - mse: 14018.8125 \n","Epoch 65/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4693 - mse: 17321.7754 \n","Epoch 66/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4770 - mse: 17367.3887 \n","Epoch 67/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4901 - mse: 17980.1660 \n","Epoch 68/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4812 - mse: 15336.0527  \n","Epoch 69/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4958 - mse: 14830.4277 \n","Epoch 70/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4982 - mse: 14323.4463 \n","Epoch 71/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4986 - mse: 13864.8770 \n","Epoch 72/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4969 - mse: 16174.2568 \n","Epoch 73/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5030 - mse: 13629.0850 \n","Epoch 74/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5048 - mse: 12637.5293 \n","Epoch 75/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5058 - mse: 10320.7217\n","Epoch 76/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4930 - mse: 10523.8955\n","Epoch 77/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4988 - mse: 12852.5723 \n","Epoch 78/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5116 - mse: 11820.5293 \n","Epoch 79/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5169 - mse: 10930.0576\n","Epoch 80/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5009 - mse: 10497.8174\n","Epoch 81/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5143 - mse: 9558.3223 \n","Epoch 82/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5222 - mse: 9645.8926 \n","Epoch 83/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4888 - mse: 10056.7334\n","Epoch 84/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5273 - mse: 9943.9336  \n","Epoch 85/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5111 - mse: 9284.7900 \n","Epoch 86/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5096 - mse: 9317.2227 \n","Epoch 87/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5124 - mse: 9961.2041  \n","Epoch 88/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5146 - mse: 9955.1045 \n","Epoch 89/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5138 - mse: 9784.2148  \n","Epoch 90/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5074 - mse: 9030.5586 \n","Epoch 91/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5058 - mse: 10090.6426\n","Epoch 92/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5160 - mse: 9950.7803 \n","Epoch 93/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5102 - mse: 9306.3662 \n","Epoch 94/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5154 - mse: 8971.8174 \n","Epoch 95/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5266 - mse: 9227.2188  \n","Epoch 96/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5211 - mse: 7672.7969 \n","Epoch 97/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5222 - mse: 8449.6973 \n","Epoch 98/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5180 - mse: 7868.8428 \n","Epoch 99/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.5396 - mse: 7809.0693 \n","Epoch 100/100\n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5300 - mse: 7405.9136 \n","\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n","\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Training set metrics:\n","{'MSE': 7055.83984375, 'MAE': 60.08552169799805, 'R2': -147393.78125, 'Avg Pearson Correlation': np.float64(0.3014306244693009), 'Avg Cosine Similarity': np.float32(0.058271393)}\n","\n","Validation set metrics:\n","{'MSE': 6567.82958984375, 'MAE': 57.16671371459961, 'R2': -223857.84375, 'Avg Pearson Correlation': np.float64(0.25384191024506947), 'Avg Cosine Similarity': np.float32(0.010935228)}\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0485 - mse: 294410.4688\n","Epoch 2/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.1227 - mse: 409314.1250 \n","Epoch 3/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.2547 - mse: 494383.6562 \n","Epoch 4/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.3170 - mse: 553942.5625 \n","Epoch 5/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.3486 - mse: 622588.0625 \n","Epoch 6/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.3734 - mse: 679931.1875 \n","Epoch 7/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.3881 - mse: 694966.8750 \n","Epoch 8/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.3959 - mse: 667698.8125  \n","Epoch 9/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3899 - mse: 696041.1875 \n","Epoch 10/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3944 - mse: 647895.1875 \n","Epoch 11/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3858 - mse: 613809.9375 \n","Epoch 12/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3981 - mse: 616515.7500 \n","Epoch 13/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4008 - mse: 590115.1250 \n","Epoch 14/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4059 - mse: 586498.1875 \n","Epoch 15/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4031 - mse: 520144.0625 \n","Epoch 16/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4089 - mse: 485291.8438 \n","Epoch 17/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4094 - mse: 489905.7500 \n","Epoch 18/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4161 - mse: 467640.7500 \n","Epoch 19/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3988 - mse: 421011.0312 \n","Epoch 20/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4247 - mse: 384368.6875 \n","Epoch 21/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4085 - mse: 366303.4688 \n","Epoch 22/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4103 - mse: 353921.2500 \n","Epoch 23/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4115 - mse: 373979.0000 \n","Epoch 24/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4059 - mse: 286339.1250 \n","Epoch 25/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4159 - mse: 305622.8750 \n","Epoch 26/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4220 - mse: 289193.6562 \n","Epoch 27/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4123 - mse: 251976.3750 \n","Epoch 28/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4249 - mse: 261174.5469 \n","Epoch 29/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4508 - mse: 239438.3594 \n","Epoch 30/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4335 - mse: 230672.8438 \n","Epoch 31/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4415 - mse: 205649.9219 \n","Epoch 32/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4411 - mse: 196317.4219 \n","Epoch 33/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4522 - mse: 186687.2812 \n","Epoch 34/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4419 - mse: 174328.1094  \n","Epoch 35/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4454 - mse: 158492.3594  \n","Epoch 36/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4250 - mse: 164549.7344 \n","Epoch 37/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4329 - mse: 120451.7969  \n","Epoch 38/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4480 - mse: 123767.2734 \n","Epoch 39/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4547 - mse: 106136.8516\n","Epoch 40/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4299 - mse: 103978.7969 \n","Epoch 41/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4605 - mse: 102900.0781 \n","Epoch 42/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4626 - mse: 87484.7109 \n","Epoch 43/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4438 - mse: 82838.3828 \n","Epoch 44/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4576 - mse: 72259.6797 \n","Epoch 45/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4636 - mse: 65048.8945 \n","Epoch 46/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4596 - mse: 56268.3086 \n","Epoch 47/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4669 - mse: 49347.7227  \n","Epoch 48/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4691 - mse: 48015.9102 \n","Epoch 49/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4867 - mse: 38198.0273 \n","Epoch 50/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4756 - mse: 41322.2539 \n","Epoch 51/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4737 - mse: 36811.2695  \n","Epoch 52/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4595 - mse: 38413.1172  \n","Epoch 53/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4849 - mse: 34704.9570  \n","Epoch 54/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4789 - mse: 37674.0039  \n","Epoch 55/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4704 - mse: 34920.5938 \n","Epoch 56/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4800 - mse: 34229.1602 \n","Epoch 57/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4914 - mse: 29072.2324  \n","Epoch 58/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4839 - mse: 25323.8594 \n","Epoch 59/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4839 - mse: 23724.2812 \n","Epoch 60/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4709 - mse: 24880.0547 \n","Epoch 61/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4913 - mse: 25534.9082  \n","Epoch 62/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4967 - mse: 23307.4863  \n","Epoch 63/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5028 - mse: 25627.4863 \n","Epoch 64/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5113 - mse: 21758.6621 \n","Epoch 65/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5016 - mse: 23751.1328 \n","Epoch 66/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4973 - mse: 20530.8047 \n","Epoch 67/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4932 - mse: 22377.4395 \n","Epoch 68/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5181 - mse: 20702.6797 \n","Epoch 69/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5200 - mse: 19603.5938 \n","Epoch 70/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5026 - mse: 18193.4238 \n","Epoch 71/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5010 - mse: 20812.5391 \n","Epoch 72/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4868 - mse: 30835.7852 \n","Epoch 73/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5027 - mse: 27758.7559 \n","Epoch 74/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4831 - mse: 26007.8125 \n","Epoch 75/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4957 - mse: 33054.9297  \n","Epoch 76/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5007 - mse: 26573.8008  \n","Epoch 77/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5141 - mse: 25172.9277  \n","Epoch 78/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5171 - mse: 20605.2793 \n","Epoch 79/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5037 - mse: 19025.9785 \n","Epoch 80/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5249 - mse: 15813.4238 \n","Epoch 81/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5150 - mse: 17252.5117 \n","Epoch 82/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5002 - mse: 20205.4004 \n","Epoch 83/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5207 - mse: 16777.8926 \n","Epoch 84/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5281 - mse: 14838.7412 \n","Epoch 85/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5314 - mse: 15102.9570 \n","Epoch 86/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5163 - mse: 12499.1426 \n","Epoch 87/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.5136 - mse: 15536.1396 \n","Epoch 88/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5345 - mse: 18142.2559 \n","Epoch 89/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5114 - mse: 15522.4834  \n","Epoch 90/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5224 - mse: 12691.1406 \n","Epoch 91/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5168 - mse: 14403.6602  \n","Epoch 92/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5225 - mse: 13571.1230 \n","Epoch 93/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5332 - mse: 11752.4912 \n","Epoch 94/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5337 - mse: 11394.1133 \n","Epoch 95/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5334 - mse: 12703.6211  \n","Epoch 96/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5280 - mse: 11722.8184  \n","Epoch 97/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5494 - mse: 11098.6045  \n","Epoch 98/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5350 - mse: 10116.9531\n","Epoch 99/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5258 - mse: 11339.4395 \n","Epoch 100/100\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5330 - mse: 10416.5088\n","\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n","\n","Full training dataset metrics:\n","{'MSE': 12963.880859375, 'MAE': 80.05216979980469, 'R2': -264379.65625, 'Avg Pearson Correlation': np.float64(0.31544220936248923), 'Avg Cosine Similarity': np.float32(0.09296872)}\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n","Test predictions saved.\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Random Forest Regressor**"],"metadata":{"id":"Ami_LtwT2Z2D"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","import pandas as pd\n","\n","# Custom Pearson correlation scorer\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","# Evaluation metrics\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","# Prepare data\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","# Train-validation split\n","X_train_split, X_val, y_train_split, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train model\n","base_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","model = MultiOutputRegressor(base_model)\n","model.fit(X_train_split, y_train_split)\n","\n","# Predictions\n","y_train_pred = model.predict(X_train_split)\n","y_val_pred = model.predict(X_val)\n","\n","# Evaluation\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# Train on full data\n","final_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n","final_model.fit(X, y)\n","y_pred=final_model.predict(X)\n","print(calculate_metrics(y, y_pred))\n","# Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = final_model.predict(X_test_arr)\n","\n","# Prepare submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('rf_test_selectKBest.csv', index=False)\n","print(\"Test predictions saved to rf_test_lasso.csv\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OMa9sFH7jzy","executionInfo":{"status":"ok","timestamp":1754645825235,"user_tz":-330,"elapsed":59318,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"4c38e5f6-4181-44cb-96e9-ea39784e36dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","{'MSE': 0.014286317527684732, 'MAE': 0.06703255233486971, 'R2': 0.8049915145162558, 'Avg Pearson Correlation': np.float64(0.9070259234150403), 'Avg Cosine Similarity': np.float64(0.9313476869690103)}\n","\n","Validation set metrics:\n","{'MSE': 0.05492271958676827, 'MAE': 0.14163073932081774, 'R2': 0.13389708875115758, 'Avg Pearson Correlation': np.float64(0.502069741571494), 'Avg Cosine Similarity': np.float64(0.6942050930218855)}\n","{'MSE': 0.015776308608181983, 'MAE': 0.07068810109649583, 'R2': 0.7837036031319526, 'Avg Pearson Correlation': np.float64(0.8912451568896235), 'Avg Cosine Similarity': np.float64(0.9219920484647737)}\n","Test predictions saved to rf_test_lasso.csv\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Randomforest 2**"],"metadata":{"id":"6CgPuqOv5UWE"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# --- Custom metrics ---\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr): corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    similarities = []\n","    for i in range(y_true.shape[0]):\n","        y_true_norm = y_true[i] / (np.linalg.norm(y_true[i]) + 1e-8)\n","        y_pred_norm = y_pred[i] / (np.linalg.norm(y_pred[i]) + 1e-8)\n","        similarity = np.dot(y_true_norm, y_pred_norm)\n","        similarities.append(similarity)\n","    return np.mean(similarities)\n","\n","def calculate_metrics(y_true, y_pred):\n","    return {\n","        \"MSE\": mean_squared_error(y_true, y_pred),\n","        \"MAE\": mean_absolute_error(y_true, y_pred),\n","        \"R2\": r2_score(y_true, y_pred),\n","        \"Avg Pearson Correlation\": pearson_correlation_score(y_true, y_pred),\n","        \"Avg Cosine Similarity\": cosine_similarity_score(y_true, y_pred),\n","    }\n","\n","# --------- Example workflow ---------\n","# These need to be set before running:\n","# X_df: DataFrame of features, y_df: DataFrame of targets (n_samples, n_targets)\n","# X_test_df: DataFrame of test features\n","# test_form: DataFrame with 'stimulus' column, matches rows of X_test_df\n","# target_cols: list of 51 string column names\n","\n","# 1. Convert to numpy if needed\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","X_test = X_test.to_numpy(dtype=np.float32)\n","\n","# 2. 80/20 split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 3. Train MultiOutput RandomForest\n","rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf.fit(X_train, y_train)\n","\n","# 4. Print metrics on splits\n","y_train_pred = rf.predict(X_train)\n","y_val_pred = rf.predict(X_val)\n","print(\"Training metrics:\")\n","print(calculate_metrics(y_train, y_train_pred))\n","print(\"\\nValidation metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# 5. Retrain on entire dataset, print metrics\n","rf_full = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf_full.fit(X, y)\n","y_full_pred = rf_full.predict(X)\n","print(\"\\nFull dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","# 6. Predict on test set, save file\n","test_preds = rf_full.predict(X_test)\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","test_submission.to_csv('rf_corr_cosine_metrics_test_selectKBest.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dPwlXa2e5Otw","executionInfo":{"status":"ok","timestamp":1754645879218,"user_tz":-330,"elapsed":53992,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"990dd2d0-b44f-46d8-c667-abb8b6d68ca4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training metrics:\n","{'MSE': 0.014286317527684732, 'MAE': 0.06703255233486971, 'R2': 0.8049915145162558, 'Avg Pearson Correlation': np.float64(0.9070259234150403), 'Avg Cosine Similarity': np.float64(0.9403035427152384)}\n","\n","Validation metrics:\n","{'MSE': 0.05492271958676827, 'MAE': 0.14163073932081774, 'R2': 0.13389708875115758, 'Avg Pearson Correlation': np.float64(0.502069741571494), 'Avg Cosine Similarity': np.float64(0.7524523548628589)}\n","\n","Full dataset metrics:\n","{'MSE': 0.015776308608181983, 'MAE': 0.07068810109649583, 'R2': 0.7837036031319526, 'Avg Pearson Correlation': np.float64(0.8912451568896235), 'Avg Cosine Similarity': np.float64(0.9315689026042793)}\n","Test predictions saved.\n","Test submission shape: (31, 52)\n"]}]},{"cell_type":"markdown","source":["# **Xgboost**"],"metadata":{"id":"-hanjYk-62sN"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics import make_scorer\n","from sklearn.multioutput import MultiOutputRegressor\n","import xgboost as xgb\n","\n","# --------------- Metrics ---------------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    avg_pearson = pearson_correlation_score(y_true, y_pred)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson\n","    }\n","\n","# --------------- Custom Objectives for XGBoost ---------------\n","# They receive (preds, dtrain) and must return (grad, hess)\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative Pearson correlation loss.\n","    This is a rough approximation for demonstration only.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_mean = np.mean(preds)\n","    label_mean = np.mean(labels)\n","    pred_centered = preds - pred_mean\n","    label_centered = labels - label_mean\n","\n","    cov = np.sum(pred_centered * label_centered)\n","    pred_var = np.sum(pred_centered ** 2) + 1e-8\n","    label_var = np.sum(label_centered ** 2) + 1e-8\n","\n","    # Gradient (negative derivative of correlation)\n","    grad = - (label_centered / (np.sqrt(pred_var) * np.sqrt(label_var))) + \\\n","           (cov * pred_centered) / (pred_var ** 1.5 * np.sqrt(label_var))\n","\n","    # Hessian approximation with small constant\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative cosine similarity loss.\n","    Rough approximation for demonstration.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","\n","    cos_sim = np.dot(preds, labels) / (pred_norm * label_norm)\n","    grad = - (labels / (pred_norm * label_norm)) + \\\n","           (cos_sim * preds) / (pred_norm ** 2)\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","# --------------- Model Wrappers ---------------\n","\n","class XGBoostCorrelationRegressor:\n","    \"\"\"XGBoost regressor for single output with Pearson correlation loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=pearson_correlation_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        # y must be 1D for single output\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class XGBoostCosineSimilarityRegressor:\n","    \"\"\"XGBoost regressor for single output with Cosine similarity loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=cosine_similarity_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class MultiOutputXGBoostRegressor:\n","    \"\"\"Multi-output regressor as sklearn wrapper over XGBRegressor.\"\"\"\n","    def __init__(self, **kwargs):\n","        base_est = xgb.XGBRegressor(objective='reg:squarederror', **kwargs)\n","        self.model = MultiOutputRegressor(base_est)\n","\n","    def fit(self, X, y):\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","# --------------- Training & evaluation function ---------------\n","\n","def train_evaluate_save(model, X, y, X_test, test_form, target_cols, model_name=\"model\"):\n","    \"\"\"\n","    Train with 80/20 split, print evaluation, retrain on full data, print evaluation, predict on test, save CSV.\n","    \"\"\"\n","    print(f\"--- Training and evaluating {model_name} ---\")\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Train on split\n","    model.fit(X_train, y_train)\n","\n","    # Predict & evaluate on train and validation split\n","    y_train_pred = model.predict(X_train)\n","    y_val_pred = model.predict(X_val)\n","    print(\"Train Metrics:\", calculate_metrics(y_train, y_train_pred))\n","    print(\"Validation Metrics:\", calculate_metrics(y_val, y_val_pred))\n","\n","    # Retrain on full dataset\n","    model.fit(X, y)\n","    y_full_pred = model.predict(X)\n","    print(\"Full Data Metrics:\", calculate_metrics(y, y_full_pred))\n","\n","    # Predict on test data\n","    test_preds = model.predict(X_test)\n","\n","    # Save predictions file\n","    test_submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        test_submission[col] = test_preds[:, i] if test_preds.shape[1] > 1 else test_preds[:, 0]\n","\n","    output_file = f'{model_name}_test_selectKBest.csv'\n","    test_submission.to_csv(output_file, index=False)\n","    print(f\"Test predictions saved to {output_file}\")\n","    print(f\"Test submission shape: {test_submission.shape}\\n\")\n","\n","# --------------- Usage Notes ---------------\n","# Variables you must have prepared before calling:\n","\n","# X: numpy array of shape (n_samples, n_features)\n","# y: numpy array of shape (n_samples, 51) - targets\n","# X_test: numpy array for test features, shape (n_test_samples, n_features)\n","# test_form: pandas DataFrame with 'stimulus' column for test samples\n","# target_cols: list of 51 odor descriptor column names, matching y columns\n","\n","# Example calls (uncomment and set your datasets appropriately):\n","#\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","model_pearson = MultiOutputXGBoostRegressor()  # Multitarget with standard MSE\n","train_evaluate_save(model_pearson, X, y, X_test, test_form, target_cols, model_name=\"MultiOutputXGBoost_MSE\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1yk7lN9vDvT2","executionInfo":{"status":"ok","timestamp":1754645891003,"user_tz":-330,"elapsed":11910,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"011990dc-fb4a-46bd-96c5-8afb873956a7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Training and evaluating MultiOutputXGBoost_MSE ---\n","Train Metrics: {'MSE': 0.01017782837152481, 'MAE': 0.04136594012379646, 'R2': 0.8603753447532654, 'Avg Pearson Correlation': np.float64(0.9270551726511738)}\n","Validation Metrics: {'MSE': 0.06840384751558304, 'MAE': 0.15304400026798248, 'R2': -0.1640651524066925, 'Avg Pearson Correlation': np.float64(0.43931616510412225)}\n","Full Data Metrics: {'MSE': 0.01297532208263874, 'MAE': 0.05337845906615257, 'R2': 0.822258472442627, 'Avg Pearson Correlation': np.float64(0.9060029224073907)}\n","Test predictions saved to MultiOutputXGBoost_MSE_test_selectKBest.csv\n","Test submission shape: (31, 52)\n","\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# ------- Custom metrics -------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        corrs.append(0 if np.isnan(corr) else corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        if np.linalg.norm(y_true[:, i]) > 0 and np.linalg.norm(y_pred[:, i]) > 0:\n","            cs = cosine_similarity(y_true[:, i].reshape(1, -1), y_pred[:, i].reshape(1, -1))[0, 0]\n","        else:\n","            cs = 0\n","        cos_sims.append(cs)\n","    return np.mean(cos_sims)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    pearson = pearson_correlation_score(y_true, y_pred)\n","    cosine = cosine_similarity_score(y_true, y_pred)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': pearson,\n","        'Avg Cosine Similarity': cosine\n","    }\n","\n","# ------- Custom objectives for XGBoost -------\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    y_true_mean = np.mean(labels)\n","    y_pred_mean = np.mean(preds)\n","    y_true_centered = labels - y_true_mean\n","    y_pred_centered = preds - y_pred_mean\n","    numerator = np.sum(y_true_centered * y_pred_centered)\n","    y_true_std = np.sqrt(np.sum(y_true_centered**2)) + 1e-8\n","    y_pred_std = np.sqrt(np.sum(y_pred_centered**2)) + 1e-8\n","    denominator = y_true_std * y_pred_std\n","\n","    d_numerator = y_true_centered\n","    d_y_pred_std = y_pred_centered / y_pred_std\n","    d_denominator = y_true_std * d_y_pred_std\n","\n","    gradient = -(d_numerator * denominator - numerator * d_denominator) / (denominator ** 2)\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","    y_true_normalized = labels / label_norm\n","    y_pred_normalized = preds / pred_norm\n","\n","    gradient = - y_true_normalized / pred_norm\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","# ------- Training function per model -------\n","\n","def train_custom_xgb_model(X, y, X_val, y_val, X_test, test_form, target_cols, custom_obj, model_name):\n","    print(f\"Training {model_name} ...\")\n","\n","    val_preds = []\n","    val_trues = []\n","\n","    test_preds = np.zeros((X_test.shape[0], y.shape[1]))\n","\n","    for i, col in enumerate(target_cols):\n","        print(f\"Training target: {col}\")\n","        # create DMatrix for training\n","        dtrain = xgb.DMatrix(X, label=y[:, i])\n","        dval = xgb.DMatrix(X_val, label=y_val[:, i])\n","        params = {\n","            'objective': 'reg:squarederror',  # ignored because of custom obj\n","            'max_depth': 6,\n","            'learning_rate': 0.1,\n","            'verbosity': 0,\n","            'seed': 42,\n","        }\n","        # Train model with early stopping evaluated on val split\n","        model = xgb.train(\n","            params,\n","            dtrain,\n","            num_boost_round=100,\n","            obj=custom_obj,\n","            evals=[(dval, 'validation')],\n","            early_stopping_rounds=10,\n","            verbose_eval=False\n","        )\n","\n","        # Predict validation\n","        val_pred = model.predict(dval)\n","        val_preds.append(val_pred)\n","        val_trues.append(y_val[:, i])\n","\n","        # Refit on full data for test prediction\n","        dfull = xgb.DMatrix(X, label=y[:, i])\n","        model_full = xgb.train(params, dfull, num_boost_round=model.best_iteration or 100, obj=custom_obj, verbose_eval=False)\n","\n","        dtest = xgb.DMatrix(X_test)\n","        test_preds[:, i] = model_full.predict(dtest)\n","\n","    # Aggregate validation results\n","    val_preds_arr = np.column_stack(val_preds)\n","    val_trues_arr = np.column_stack(val_trues)\n","\n","    print(f\"{model_name} - Validation metrics (aggregated):\")\n","    print(calculate_metrics(val_trues_arr, val_preds_arr))\n","\n","    # Save test predictions\n","    submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        submission[col] = test_preds[:, i]\n","    submission_file = f\"{model_name}_test_selectKBest.csv\"\n","    submission.to_csv(submission_file, index=False)\n","    print(f\"Saved test predictions to {submission_file}\")\n","\n","# ------- Prepare data -------\n","\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","target_cols = target_cols  # list of 51 target column names\n","test_form_df = test_form  # contains 'stimulus'\n","\n","\n","# Split train data for validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# ------- Run models -------\n","\n","# 1. Pearson correlation objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    pearson_correlation_obj, \"XGBoost_PearsonCorrelation\"\n",")\n","\n","# 2. Cosine similarity objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    cosine_similarity_obj, \"XGBoost_CosineSimilarity\"\n",")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vccgUip_XjH_","executionInfo":{"status":"ok","timestamp":1754645903035,"user_tz":-330,"elapsed":12145,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"a964cd1f-6e0b-4662-9a4d-435eb7b2ae5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training XGBoost_PearsonCorrelation ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_PearsonCorrelation - Validation metrics (aggregated):\n","{'MSE': 10562833481728.0, 'MAE': 2500900.5, 'R2': -354135052386304.0, 'Avg Pearson Correlation': np.float64(0.3989619648259271), 'Avg Cosine Similarity': np.float32(0.26882064)}\n","Saved test predictions to XGBoost_PearsonCorrelation_test_selectKBest.csv\n","Training XGBoost_CosineSimilarity ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_CosineSimilarity - Validation metrics (aggregated):\n","{'MSE': 0.2171178162097931, 'MAE': 0.43322136998176575, 'R2': -8.160547256469727, 'Avg Pearson Correlation': np.float64(0.35713430615396186), 'Avg Cosine Similarity': np.float32(0.5737666)}\n","Saved test predictions to XGBoost_CosineSimilarity_test_selectKBest.csv\n"]}]}]}
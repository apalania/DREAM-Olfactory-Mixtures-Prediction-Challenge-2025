{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1zYs9sjZBKCSq6DtO4am7r9CgXrb-HUtD","timestamp":1754717185668},{"file_id":"1SXCxTIzx4NM6EQlcKqfbDB7SiaKIPCza","timestamp":1754664142029}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","x_df_lasso= pd.read_csv(\"X_train_pca_99.csv\")\n","X_test= pd.read_csv(\"X_test_pca_99.csv\")\n","y_df= pd.read_csv(\"y_train.csv\")\n","test_form= pd.read_csv(\"TASK2_Test_set_Submission_form.csv\")\n","# Remove unwanted columns\n","\n","# Ensure both have same columns in the same order\n","x_df_lasso =x_df_lasso.drop(columns=['stimulus'])\n","X_test = X_test.drop(columns=['stimulus'])\n","\n","target_cols = [\n","    'Green', 'Cucumber', 'Herbal', 'Mint', 'Woody', 'Pine', 'Floral',\n","    'Powdery', 'Fruity', 'Citrus', 'Tropical', 'Berry', 'Peach', 'Sweet',\n","    'Caramellic', 'Vanilla', 'BrownSpice', 'Smoky', 'Burnt', 'Roasted',\n","    'Grainy', 'Meaty', 'Nutty', 'Fatty', 'Coconut', 'Waxy', 'Dairy',\n","    'Buttery', 'Cheesy', 'Sour', 'Fermented', 'Sulfurous', 'Garlic.Onion',\n","    'Earthy', 'Mushroom', 'Musty', 'Ammonia', 'Fishy', 'Fecal',\n","    'Rotten.Decay', 'Rubber', 'Phenolic', 'Animal', 'Medicinal',\n","    'Cooling', 'Sharp', 'Chlorine', 'Alcoholic', 'Plastic', 'Ozone', 'Metallic'\n","]"],"metadata":{"id":"7SOmmemYi4is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_df_lasso.shape)\n","\n","print(X_test.shape)\n","print(y_df.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptPIplwOp4QQ","executionInfo":{"status":"ok","timestamp":1754666219731,"user_tz":-330,"elapsed":2,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"f1562967-0942-4734-fc77-42b8ada489dc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(393, 51)\n","(130, 51)\n","(393, 51)\n"]}]},{"cell_type":"markdown","source":["# **Hyperbolic model**"],"metadata":{"id":"XgdSwKLH6ym0"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class PearsonCosineLoss(nn.Module):\n","    def __init__(self, alpha=0.5, eps=1e-8):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.eps = eps\n","        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=eps)\n","\n","    def forward(self, y_pred, y_true):\n","        # Pearson Correlation (1 - correlation for minimization)\n","        y_pred_centered = y_pred - y_pred.mean(dim=1, keepdim=True)\n","        y_true_centered = y_true - y_true.mean(dim=1, keepdim=True)\n","        numerator = (y_pred_centered * y_true_centered).sum(dim=1)\n","        denominator = (y_pred_centered.pow(2).sum(dim=1) * y_true_centered.pow(2).sum(dim=1)).sqrt() + self.eps\n","        pearson_corr = numerator / denominator\n","        pearson_loss = 1 - pearson_corr\n","\n","        # Cosine Similarity (1 - similarity for minimization)\n","        cosine_loss = 1 - self.cosine_similarity(y_pred, y_true)\n","        loss = self.alpha * pearson_loss + (1 - self.alpha) * cosine_loss\n","        return loss.mean()\n","class HyperbolicModel(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, output_dim)\n","        self.tanh = nn.Tanh()\n","    def forward(self, x):\n","        x = self.tanh(self.fc1(x))\n","        x = self.tanh(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    corrs = [np.corrcoef(y_true[:,i], y_pred[:,i])[0,1] if np.std(y_true[:,i])>0 and np.std(y_pred[:,i])>0 else 0 for i in range(y_true.shape[1])]\n","    avg_pearson = np.mean(corrs)\n","    norms_true = np.linalg.norm(y_true, axis=1)\n","    norms_pred = np.linalg.norm(y_pred, axis=1)\n","    cos = np.sum(y_true * y_pred, axis=1) / (norms_true * norms_pred + 1e-8)\n","    avg_cosine = np.mean(cos)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine\n","    }\n","\n","# Training routine\n","def train_and_evaluate(X, y, test_ratio=0.2, epochs=100, lr=1e-3, batch_size=32, alpha=0.5):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # Split\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_ratio, random_state=42)\n","    X_train_t = torch.FloatTensor(X_train).to(device)\n","    y_train_t = torch.FloatTensor(y_train).to(device)\n","    X_val_t = torch.FloatTensor(X_val).to(device)\n","    y_val_t = torch.FloatTensor(y_val).to(device)\n","\n","    # Model\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    loss_fn = PearsonCosineLoss(alpha=alpha)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    n = X_train.shape[0]\n","    steps_per_epoch = int(np.ceil(n / batch_size))\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        idx = np.random.permutation(n)\n","        for i in range(steps_per_epoch):\n","            batch_idx = idx[i*batch_size:(i+1)*batch_size]\n","            xb = X_train_t[batch_idx]\n","            yb = y_train_t[batch_idx]\n","            optimizer.zero_grad()\n","            y_pred = model(xb)\n","            loss = loss_fn(y_pred, yb)\n","            loss.backward()\n","            optimizer.step()\n","        if (epoch+1) % 20 == 0:\n","            print(f\"Epoch {epoch+1}/{epochs}: Train Loss = {loss.item():.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        y_train_pred = model(X_train_t).cpu().numpy()\n","        y_val_pred = model(X_val_t).cpu().numpy()\n","\n","    # Print metrics on split data\n","    train_metrics = calculate_metrics(y_train, y_train_pred)\n","    val_metrics = calculate_metrics(y_val, y_val_pred)\n","    print(\"\\\\nTrain Metrics:\", train_metrics)\n","    print(\"Validation Metrics:\", val_metrics)\n","\n","    # Retrain on full data\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    X_full_t = torch.FloatTensor(X).to(device)\n","    y_full_t = torch.FloatTensor(y).to(device)\n","    for epoch in range(epochs):\n","        optimizer.zero_grad()\n","        y_pred = model(X_full_t)\n","        loss = loss_fn(y_pred, y_full_t)\n","        loss.backward()\n","        optimizer.step()\n","    model.eval()\n","    with torch.no_grad():\n","        y_full_pred = model(X_full_t).cpu().numpy()\n","    full_metrics = calculate_metrics(y, y_full_pred)\n","    print(\"\\\\nMetrics on Full Data:\", full_metrics)\n","    return model, device\n","# Run training and print metrics\n","model, device = train_and_evaluate(\n","    x_df_lasso.to_numpy(dtype=np.float32),\n","    y_df.to_numpy(dtype=np.float32),\n","    test_ratio=0.2,\n","    epochs=100,\n","    lr=1e-3,\n","    batch_size=32,\n","    alpha=0.5\n",")\n","\n","# Convert all columns to numeric (with NaNs where conversion failed)\n","X_test_numeric = X_test.apply(pd.to_numeric, errors='coerce')\n","\n","# Fill NaN values (e.g., with 0 or other imputation strategy)\n","X_test_filled = X_test_numeric.fillna(0)\n","\n","# Convert to numpy array of floats\n","X_test_arr = X_test_filled.to_numpy(dtype=np.float32)\n","with torch.no_grad():\n","    X_test_tensor = torch.FloatTensor(X_test_arr).to(device)\n","    test_preds = model(X_test_tensor).cpu().numpy()\n","\n","# Save submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","\n","test_submission.to_csv('hyperbolic_task2_pca.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKn1rTrhN47u","executionInfo":{"status":"ok","timestamp":1754666232464,"user_tz":-330,"elapsed":9571,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"4471eeb8-22a6-435b-8e31-6abf7fc2615d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 20/100: Train Loss = 0.1959\n","Epoch 40/100: Train Loss = 0.1501\n","Epoch 60/100: Train Loss = 0.1396\n","Epoch 80/100: Train Loss = 0.1077\n","Epoch 100/100: Train Loss = 0.1001\n","\\nTrain Metrics: {'MSE': 0.07890557497739792, 'MAE': 0.15479159355163574, 'R2': 0.26670101284980774, 'Avg Pearson Correlation': np.float64(0.7639274394204721), 'Avg Cosine Similarity': np.float32(0.9229938)}\n","Validation Metrics: {'MSE': 0.09945151954889297, 'MAE': 0.17800931632518768, 'R2': 0.03634636476635933, 'Avg Pearson Correlation': np.float64(0.4620689562810271), 'Avg Cosine Similarity': np.float32(0.729081)}\n","\\nMetrics on Full Data: {'MSE': 0.0799824595451355, 'MAE': 0.15950997173786163, 'R2': 0.22959144413471222, 'Avg Pearson Correlation': np.float64(0.5753046189834348), 'Avg Cosine Similarity': np.float32(0.85443944)}\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **Correlation regressor**"],"metadata":{"id":"pSjUqg9565EQ"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","\n","\n","# Pearson correlation loss (maximize correlation by minimizing negative correlation)\n","def pearson_correlation_loss(y_true, y_pred):\n","    y_true_centered = y_true - tf.reduce_mean(y_true, axis=1, keepdims=True)\n","    y_pred_centered = y_pred - tf.reduce_mean(y_pred, axis=1, keepdims=True)\n","    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n","    denominator = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered), axis=1)) * tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered), axis=1))\n","    correlation = numerator / (denominator + 1e-8)\n","    return -tf.reduce_mean(correlation)\n","\n","\n","def create_olfactory_model(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(128, activation='relu', input_shape=(input_dim,)),\n","        Dense(64, activation='relu'),\n","        Dense(output_dim, activation='linear')\n","    ])\n","    model.compile(optimizer='adam', loss=pearson_correlation_loss, metrics=['mse'])\n","    return model\n","\n","\n","class CorrelationRegressor(BaseEstimator, RegressorMixin):\n","    def __init__(self, input_dim=None, output_dim=None, epochs=100, batch_size=32, verbose=0):\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.verbose = verbose\n","        self.model_ = None\n","\n","    def fit(self, X, y):\n","        if self.input_dim is None:\n","            self.input_dim = X.shape[1]\n","        if self.output_dim is None:\n","            self.output_dim = y.shape[1] if len(y.shape) > 1 else 1\n","        self.model_ = create_olfactory_model(self.input_dim, self.output_dim)\n","        self.model_.fit(\n","            X, y,\n","            epochs=self.epochs,\n","            batch_size=self.batch_size,\n","            verbose=self.verbose\n","        )\n","        return self\n","\n","    def predict(self, X):\n","        if self.model_ is None:\n","            raise ValueError(\"Model not fitted yet\")\n","        return self.model_.predict(X)\n","\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","\n","# Convert DataFrames to numpy arrays\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","\n","# 1. Split data 80% train, 20% validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","\n","# 2. Initialize regressor\n","regressor = CorrelationRegressor(\n","    input_dim=X_train_split.shape[1],\n","    output_dim=y_train_split.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","\n","# 3. Train on 80% split\n","regressor.fit(X_train_split, y_train_split)\n","\n","# 4. Evaluate on train split and validation split\n","y_train_pred = regressor.predict(X_train_split)\n","y_val_pred = regressor.predict(X_val)\n","\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","\n","# 5. Train on full dataset (train + val)\n","regressor_full = CorrelationRegressor(\n","    input_dim=X.shape[1],\n","    output_dim=y.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","regressor_full.fit(X, y)\n","\n","# 6. Evaluate on entire training dataset\n","y_full_pred = regressor_full.predict(X)\n","print(\"\\nFull training dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","\n","# 7. Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = regressor_full.predict(X_test_arr)\n","\n","# 8. Save submission file\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('corr_test_task2_pca.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"collapsed":true,"id":"2EGVulygyAxt","executionInfo":{"status":"ok","timestamp":1754666301792,"user_tz":-330,"elapsed":62533,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d611f056-6a13-4f9c-bc5b-2abe49aa01c3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - loss: -0.0298 - mse: 0.9874\n","Epoch 2/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - loss: -0.2498 - mse: 1.1298\n","Epoch 3/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: -0.3574 - mse: 1.3602\n","Epoch 4/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: -0.4331 - mse: 1.4894 \n","Epoch 5/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: -0.4782 - mse: 1.5328\n","Epoch 6/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step - loss: -0.5386 - mse: 1.4448\n","Epoch 7/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - loss: -0.5609 - mse: 1.3866\n","Epoch 8/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: -0.5731 - mse: 1.2044\n","Epoch 9/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - loss: -0.6114 - mse: 1.1077\n","Epoch 10/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 36ms/step - loss: -0.6210 - mse: 0.9821\n","Epoch 11/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - loss: -0.6284 - mse: 0.8649\n","Epoch 12/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: -0.6554 - mse: 0.8248\n","Epoch 13/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: -0.6652 - mse: 0.7260\n","Epoch 14/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: -0.6800 - mse: 0.6870\n","Epoch 15/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: -0.6994 - mse: 0.6305\n","Epoch 16/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.7020 - mse: 0.5733\n","Epoch 17/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.7154 - mse: 0.5570\n","Epoch 18/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: -0.7173 - mse: 0.5326\n","Epoch 19/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7408 - mse: 0.4877\n","Epoch 20/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.7408 - mse: 0.4620\n","Epoch 21/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.7464 - mse: 0.4456\n","Epoch 22/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: -0.7530 - mse: 0.4107\n","Epoch 23/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: -0.7596 - mse: 0.4041\n","Epoch 24/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: -0.7611 - mse: 0.3883\n","Epoch 25/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: -0.7725 - mse: 0.3761\n","Epoch 26/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.7750 - mse: 0.3580\n","Epoch 27/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.7840 - mse: 0.3383\n","Epoch 28/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: -0.7908 - mse: 0.3323\n","Epoch 29/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: -0.7947 - mse: 0.3086\n","Epoch 30/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: -0.7995 - mse: 0.3014\n","Epoch 31/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: -0.7961 - mse: 0.2965\n","Epoch 32/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7961 - mse: 0.3030 \n","Epoch 33/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: -0.8007 - mse: 0.2825\n","Epoch 34/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: -0.7954 - mse: 0.2936\n","Epoch 35/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: -0.8014 - mse: 0.2868\n","Epoch 36/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - loss: -0.8125 - mse: 0.2736\n","Epoch 37/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.8033 - mse: 0.2743\n","Epoch 38/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.8156 - mse: 0.2723\n","Epoch 39/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.8187 - mse: 0.2669\n","Epoch 40/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: -0.8217 - mse: 0.2654\n","Epoch 41/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: -0.8276 - mse: 0.2411\n","Epoch 42/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: -0.8163 - mse: 0.2500\n","Epoch 43/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.8275 - mse: 0.2368\n","Epoch 44/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: -0.8250 - mse: 0.2496\n","Epoch 45/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: -0.8173 - mse: 0.2412\n","Epoch 46/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.8263 - mse: 0.2513\n","Epoch 47/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: -0.8371 - mse: 0.2323\n","Epoch 48/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - loss: -0.8361 - mse: 0.2338\n","Epoch 49/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: -0.8413 - mse: 0.2173\n","Epoch 50/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: -0.8456 - mse: 0.2125\n","Epoch 51/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: -0.8392 - mse: 0.2131\n","Epoch 52/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 41ms/step - loss: -0.8455 - mse: 0.2177\n","Epoch 53/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: -0.8527 - mse: 0.2111\n","Epoch 54/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8447 - mse: 0.2078  \n","Epoch 55/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8539 - mse: 0.2137 \n","Epoch 56/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8479 - mse: 0.2101 \n","Epoch 57/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8532 - mse: 0.2002 \n","Epoch 58/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.8573 - mse: 0.2015\n","Epoch 59/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8560 - mse: 0.1884 \n","Epoch 60/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8501 - mse: 0.2017 \n","Epoch 61/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8560 - mse: 0.2027 \n","Epoch 62/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.8663 - mse: 0.1919 \n","Epoch 63/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8641 - mse: 0.2047 \n","Epoch 64/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8619 - mse: 0.1981 \n","Epoch 65/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8563 - mse: 0.1932 \n","Epoch 66/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: -0.8690 - mse: 0.1995\n","Epoch 67/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.8670 - mse: 0.1895\n","Epoch 68/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.8604 - mse: 0.2061\n","Epoch 69/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.8617 - mse: 0.1860 \n","Epoch 70/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8540 - mse: 0.1987 \n","Epoch 71/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8657 - mse: 0.1903 \n","Epoch 72/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8677 - mse: 0.1935 \n","Epoch 73/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8695 - mse: 0.1782 \n","Epoch 74/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8786 - mse: 0.1878 \n","Epoch 75/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8781 - mse: 0.1763 \n","Epoch 76/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8697 - mse: 0.1816 \n","Epoch 77/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8660 - mse: 0.1790 \n","Epoch 78/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8704 - mse: 0.1754 \n","Epoch 79/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8745 - mse: 0.1780 \n","Epoch 80/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8724 - mse: 0.1789 \n","Epoch 81/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8738 - mse: 0.1766 \n","Epoch 82/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8774 - mse: 0.1757 \n","Epoch 83/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8761 - mse: 0.1803 \n","Epoch 84/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8770 - mse: 0.1759 \n","Epoch 85/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8744 - mse: 0.1746 \n","Epoch 86/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.8842 - mse: 0.1811 \n","Epoch 87/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8821 - mse: 0.1803 \n","Epoch 88/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8802 - mse: 0.1799 \n","Epoch 89/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8784 - mse: 0.1706 \n","Epoch 90/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8816 - mse: 0.1719 \n","Epoch 91/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8819 - mse: 0.1726 \n","Epoch 92/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8842 - mse: 0.1668 \n","Epoch 93/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8857 - mse: 0.1641 \n","Epoch 94/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8863 - mse: 0.1684 \n","Epoch 95/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8881 - mse: 0.1722 \n","Epoch 96/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8891 - mse: 0.1691 \n","Epoch 97/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8817 - mse: 0.1676 \n","Epoch 98/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8917 - mse: 0.1640 \n","Epoch 99/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8873 - mse: 0.1679 \n","Epoch 100/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8964 - mse: 0.1658 \n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Training set metrics:\n","{'MSE': 0.16494151949882507, 'MAE': 0.3468341827392578, 'R2': -1.8298076391220093, 'Avg Pearson Correlation': np.float64(0.7064104678982102), 'Avg Cosine Similarity': np.float32(0.3310507)}\n","\n","Validation set metrics:\n","{'MSE': 0.21217326819896698, 'MAE': 0.3623180091381073, 'R2': -2.6756510734558105, 'Avg Pearson Correlation': np.float64(0.43425052988104695), 'Avg Cosine Similarity': np.float32(0.14567815)}\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - loss: -0.1056 - mse: 0.7436\n","Epoch 2/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.3306 - mse: 0.9855 \n","Epoch 3/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4297 - mse: 1.2271 \n","Epoch 4/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.5080 - mse: 1.1800\n","Epoch 5/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.5250 - mse: 1.1885\n","Epoch 6/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: -0.5561 - mse: 1.1145\n","Epoch 7/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - loss: -0.5741 - mse: 0.9756\n","Epoch 8/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - loss: -0.5877 - mse: 0.8637\n","Epoch 9/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: -0.6071 - mse: 0.7129\n","Epoch 10/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - loss: -0.6238 - mse: 0.6633\n","Epoch 11/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - loss: -0.6479 - mse: 0.5556\n","Epoch 12/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: -0.6526 - mse: 0.5156\n","Epoch 13/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - loss: -0.6710 - mse: 0.4554\n","Epoch 14/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6723 - mse: 0.4227\n","Epoch 15/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6884 - mse: 0.3989 \n","Epoch 16/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6944 - mse: 0.3878 \n","Epoch 17/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7075 - mse: 0.3384 \n","Epoch 18/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7206 - mse: 0.3141 \n","Epoch 19/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7288 - mse: 0.2917 \n","Epoch 20/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7323 - mse: 0.3017 \n","Epoch 21/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7361 - mse: 0.2731 \n","Epoch 22/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7449 - mse: 0.2624 \n","Epoch 23/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7477 - mse: 0.2394 \n","Epoch 24/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7575 - mse: 0.2403 \n","Epoch 25/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7592 - mse: 0.2390 \n","Epoch 26/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7642 - mse: 0.2443 \n","Epoch 27/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7628 - mse: 0.2163 \n","Epoch 28/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7776 - mse: 0.2070 \n","Epoch 29/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7672 - mse: 0.2170 \n","Epoch 30/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7745 - mse: 0.2027 \n","Epoch 31/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7935 - mse: 0.1856 \n","Epoch 32/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7811 - mse: 0.1930 \n","Epoch 33/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7847 - mse: 0.1857 \n","Epoch 34/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7848 - mse: 0.1801 \n","Epoch 35/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7901 - mse: 0.1800 \n","Epoch 36/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7933 - mse: 0.1793 \n","Epoch 37/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7911 - mse: 0.1732 \n","Epoch 38/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7926 - mse: 0.1678\n","Epoch 39/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.8099 - mse: 0.1689 \n","Epoch 40/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7962 - mse: 0.1535 \n","Epoch 41/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7919 - mse: 0.1743 \n","Epoch 42/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.8042 - mse: 0.1666 \n","Epoch 43/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.8079 - mse: 0.1606 \n","Epoch 44/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.8118 - mse: 0.1530 \n","Epoch 45/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8196 - mse: 0.1534 \n","Epoch 46/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8217 - mse: 0.1443 \n","Epoch 47/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8138 - mse: 0.1566 \n","Epoch 48/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8222 - mse: 0.1531 \n","Epoch 49/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8178 - mse: 0.1463 \n","Epoch 50/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8299 - mse: 0.1496 \n","Epoch 51/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8206 - mse: 0.1405 \n","Epoch 52/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8295 - mse: 0.1433 \n","Epoch 53/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8134 - mse: 0.1475 \n","Epoch 54/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8219 - mse: 0.1369 \n","Epoch 55/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8366 - mse: 0.1431 \n","Epoch 56/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8285 - mse: 0.1341 \n","Epoch 57/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8252 - mse: 0.1407 \n","Epoch 58/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8196 - mse: 0.1490 \n","Epoch 59/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8328 - mse: 0.1364 \n","Epoch 60/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8352 - mse: 0.1353 \n","Epoch 61/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8299 - mse: 0.1345 \n","Epoch 62/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8440 - mse: 0.1309 \n","Epoch 63/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8337 - mse: 0.1357 \n","Epoch 64/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8320 - mse: 0.1379 \n","Epoch 65/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8302 - mse: 0.1369 \n","Epoch 66/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8422 - mse: 0.1270 \n","Epoch 67/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8436 - mse: 0.1307 \n","Epoch 68/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8301 - mse: 0.1272 \n","Epoch 69/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8463 - mse: 0.1238 \n","Epoch 70/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8485 - mse: 0.1264 \n","Epoch 71/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8412 - mse: 0.1239 \n","Epoch 72/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8511 - mse: 0.1209\n","Epoch 73/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8499 - mse: 0.1283 \n","Epoch 74/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8480 - mse: 0.1172 \n","Epoch 75/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8543 - mse: 0.1255 \n","Epoch 76/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8566 - mse: 0.1209 \n","Epoch 77/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8558 - mse: 0.1170 \n","Epoch 78/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8538 - mse: 0.1183 \n","Epoch 79/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8487 - mse: 0.1193 \n","Epoch 80/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8566 - mse: 0.1202 \n","Epoch 81/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8497 - mse: 0.1259 \n","Epoch 82/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8638 - mse: 0.1164 \n","Epoch 83/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8561 - mse: 0.1228 \n","Epoch 84/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8642 - mse: 0.1183 \n","Epoch 85/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8634 - mse: 0.1115 \n","Epoch 86/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8598 - mse: 0.1172 \n","Epoch 87/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8589 - mse: 0.1176 \n","Epoch 88/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8479 - mse: 0.1173 \n","Epoch 89/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8604 - mse: 0.1182 \n","Epoch 90/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8640 - mse: 0.1210 \n","Epoch 91/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8589 - mse: 0.1115 \n","Epoch 92/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8543 - mse: 0.1127 \n","Epoch 93/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.8644 - mse: 0.1149 \n","Epoch 94/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.8611 - mse: 0.1109\n","Epoch 95/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8626 - mse: 0.1078\n","Epoch 96/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: -0.8723 - mse: 0.1060\n","Epoch 97/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8669 - mse: 0.1152\n","Epoch 98/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8639 - mse: 0.1130\n","Epoch 99/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.8674 - mse: 0.1155\n","Epoch 100/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8649 - mse: 0.1068\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n","\n","Full training dataset metrics:\n","{'MSE': 0.11070224642753601, 'MAE': 0.2537687122821808, 'R2': -0.5835215449333191, 'Avg Pearson Correlation': np.float64(0.7180693930506601), 'Avg Cosine Similarity': np.float32(0.53306645)}\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **RF1**"],"metadata":{"id":"F8MeTU0Q7LHa"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","import pandas as pd\n","\n","# Custom Pearson correlation scorer\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","# Evaluation metrics\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","# Prepare data\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","# Train-validation split\n","X_train_split, X_val, y_train_split, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train model\n","base_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","model = MultiOutputRegressor(base_model)\n","model.fit(X_train_split, y_train_split)\n","\n","# Predictions\n","y_train_pred = model.predict(X_train_split)\n","y_val_pred = model.predict(X_val)\n","\n","# Evaluation\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# Train on full data\n","final_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n","final_model.fit(X, y)\n","y_pred=final_model.predict(X)\n","print(calculate_metrics(y, y_pred))\n","# Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = final_model.predict(X_test_arr)\n","\n","# Prepare submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('rf_test_task2_pca.csv', index=False)\n","print(\"Test predictions saved to rf_test_lasso.csv\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OMa9sFH7jzy","outputId":"9b625ee8-c8fb-4ec5-e831-107c8b51a7d2","executionInfo":{"status":"ok","timestamp":1754666507550,"user_tz":-330,"elapsed":204510,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","{'MSE': 0.01313139781601718, 'MAE': 0.0709743845826857, 'R2': 0.8747026756433595, 'Avg Pearson Correlation': np.float64(0.9625448788081996), 'Avg Cosine Similarity': np.float64(0.965920844590546)}\n","\n","Validation set metrics:\n","{'MSE': 0.09164473132372848, 'MAE': 0.18490114800982815, 'R2': 0.10700704492725212, 'Avg Pearson Correlation': np.float64(0.4275643043414627), 'Avg Cosine Similarity': np.float64(0.6812443606186288)}\n","{'MSE': 0.01286998229863919, 'MAE': 0.06971111780719794, 'R2': 0.8762721923389426, 'Avg Pearson Correlation': np.float64(0.9606161718681298), 'Avg Cosine Similarity': np.float64(0.9656829242223746)}\n","Test predictions saved to rf_test_lasso.csv\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **RF2**"],"metadata":{"id":"pPbQnT8r_oow"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# --- Custom metrics ---\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr): corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    similarities = []\n","    for i in range(y_true.shape[0]):\n","        y_true_norm = y_true[i] / (np.linalg.norm(y_true[i]) + 1e-8)\n","        y_pred_norm = y_pred[i] / (np.linalg.norm(y_pred[i]) + 1e-8)\n","        similarity = np.dot(y_true_norm, y_pred_norm)\n","        similarities.append(similarity)\n","    return np.mean(similarities)\n","\n","def calculate_metrics(y_true, y_pred):\n","    return {\n","        \"MSE\": mean_squared_error(y_true, y_pred),\n","        \"MAE\": mean_absolute_error(y_true, y_pred),\n","        \"R2\": r2_score(y_true, y_pred),\n","        \"Avg Pearson Correlation\": pearson_correlation_score(y_true, y_pred),\n","        \"Avg Cosine Similarity\": cosine_similarity_score(y_true, y_pred),\n","    }\n","\n","# --------- Example workflow ---------\n","# These need to be set before running:\n","# X_df: DataFrame of features, y_df: DataFrame of targets (n_samples, n_targets)\n","# X_test_df: DataFrame of test features\n","# test_form: DataFrame with 'stimulus' column, matches rows of X_test_df\n","# target_cols: list of 51 string column names\n","\n","# 1. Convert to numpy if needed\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","X_test = X_test.to_numpy(dtype=np.float32)\n","\n","# 2. 80/20 split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 3. Train MultiOutput RandomForest\n","rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf.fit(X_train, y_train)\n","\n","# 4. Print metrics on splits\n","y_train_pred = rf.predict(X_train)\n","y_val_pred = rf.predict(X_val)\n","print(\"Training metrics:\")\n","print(calculate_metrics(y_train, y_train_pred))\n","print(\"\\nValidation metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# 5. Retrain on entire dataset, print metrics\n","rf_full = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf_full.fit(X, y)\n","y_full_pred = rf_full.predict(X)\n","print(\"\\nFull dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","# 6. Predict on test set, save file\n","test_preds = rf_full.predict(X_test)\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","test_submission.to_csv('rf_corr_cosine_metrics_test_task2_pca.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"id":"dPwlXa2e5Otw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754666667352,"user_tz":-330,"elapsed":159813,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"56f8188f-acc2-4579-fd48-acba314d88ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training metrics:\n","{'MSE': 0.01313139781601718, 'MAE': 0.0709743845826857, 'R2': 0.8747026756433595, 'Avg Pearson Correlation': np.float64(0.9625448788081996), 'Avg Cosine Similarity': np.float64(0.9707439892846974)}\n","\n","Validation metrics:\n","{'MSE': 0.09164473132372848, 'MAE': 0.18490114800982815, 'R2': 0.10700704492725212, 'Avg Pearson Correlation': np.float64(0.4275643043414627), 'Avg Cosine Similarity': np.float64(0.7359867374235066)}\n","\n","Full dataset metrics:\n","{'MSE': 0.01286998229863919, 'MAE': 0.06971111780719794, 'R2': 0.8762721923389426, 'Avg Pearson Correlation': np.float64(0.9606161718681298), 'Avg Cosine Similarity': np.float64(0.9712158923090263)}\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **XG1**"],"metadata":{"id":"Mlg703nF_u0C"}},{"cell_type":"code","source":[],"metadata":{"id":"Nk-WTU5f_4lJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics import make_scorer\n","from sklearn.multioutput import MultiOutputRegressor\n","import xgboost as xgb\n","\n","# --------------- Metrics ---------------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    avg_pearson = pearson_correlation_score(y_true, y_pred)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson\n","    }\n","\n","# --------------- Custom Objectives for XGBoost ---------------\n","# They receive (preds, dtrain) and must return (grad, hess)\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative Pearson correlation loss.\n","    This is a rough approximation for demonstration only.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_mean = np.mean(preds)\n","    label_mean = np.mean(labels)\n","    pred_centered = preds - pred_mean\n","    label_centered = labels - label_mean\n","\n","    cov = np.sum(pred_centered * label_centered)\n","    pred_var = np.sum(pred_centered ** 2) + 1e-8\n","    label_var = np.sum(label_centered ** 2) + 1e-8\n","\n","    # Gradient (negative derivative of correlation)\n","    grad = - (label_centered / (np.sqrt(pred_var) * np.sqrt(label_var))) + \\\n","           (cov * pred_centered) / (pred_var ** 1.5 * np.sqrt(label_var))\n","\n","    # Hessian approximation with small constant\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative cosine similarity loss.\n","    Rough approximation for demonstration.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","\n","    cos_sim = np.dot(preds, labels) / (pred_norm * label_norm)\n","    grad = - (labels / (pred_norm * label_norm)) + \\\n","           (cos_sim * preds) / (pred_norm ** 2)\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","# --------------- Model Wrappers ---------------\n","\n","class XGBoostCorrelationRegressor:\n","    \"\"\"XGBoost regressor for single output with Pearson correlation loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=pearson_correlation_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        # y must be 1D for single output\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class XGBoostCosineSimilarityRegressor:\n","    \"\"\"XGBoost regressor for single output with Cosine similarity loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=cosine_similarity_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class MultiOutputXGBoostRegressor:\n","    \"\"\"Multi-output regressor as sklearn wrapper over XGBRegressor.\"\"\"\n","    def __init__(self, **kwargs):\n","        base_est = xgb.XGBRegressor(objective='reg:squarederror', **kwargs)\n","        self.model = MultiOutputRegressor(base_est)\n","\n","    def fit(self, X, y):\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","# --------------- Training & evaluation function ---------------\n","\n","def train_evaluate_save(model, X, y, X_test, test_form, target_cols, model_name=\"model\"):\n","    \"\"\"\n","    Train with 80/20 split, print evaluation, retrain on full data, print evaluation, predict on test, save CSV.\n","    \"\"\"\n","    print(f\"--- Training and evaluating {model_name} ---\")\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Train on split\n","    model.fit(X_train, y_train)\n","\n","    # Predict & evaluate on train and validation split\n","    y_train_pred = model.predict(X_train)\n","    y_val_pred = model.predict(X_val)\n","    print(\"Train Metrics:\", calculate_metrics(y_train, y_train_pred))\n","    print(\"Validation Metrics:\", calculate_metrics(y_val, y_val_pred))\n","\n","    # Retrain on full dataset\n","    model.fit(X, y)\n","    y_full_pred = model.predict(X)\n","    print(\"Full Data Metrics:\", calculate_metrics(y, y_full_pred))\n","\n","    # Predict on test data\n","    test_preds = model.predict(X_test)\n","\n","    # Save predictions file\n","    test_submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        test_submission[col] = test_preds[:, i] if test_preds.shape[1] > 1 else test_preds[:, 0]\n","\n","    output_file = f'{model_name}_test_task2_pca.csv'\n","    test_submission.to_csv(output_file, index=False)\n","    print(f\"Test predictions saved to {output_file}\")\n","    print(f\"Test submission shape: {test_submission.shape}\\n\")\n","\n","# --------------- Usage Notes ---------------\n","# Variables you must have prepared before calling:\n","\n","# X: numpy array of shape (n_samples, n_features)\n","# y: numpy array of shape (n_samples, 51) - targets\n","# X_test: numpy array for test features, shape (n_test_samples, n_features)\n","# test_form: pandas DataFrame with 'stimulus' column for test samples\n","# target_cols: list of 51 odor descriptor column names, matching y columns\n","\n","# Example calls (uncomment and set your datasets appropriately):\n","#\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","model_pearson = MultiOutputXGBoostRegressor()  # Multitarget with standard MSE\n","train_evaluate_save(model_pearson, X, y, X_test, test_form, target_cols, model_name=\"MultiOutputXGBoost_MSE\")\n","\n"],"metadata":{"id":"1yk7lN9vDvT2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754666762483,"user_tz":-330,"elapsed":95145,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"991ab381-0e9e-4d2f-f814-b8c14185a018"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Training and evaluating MultiOutputXGBoost_MSE ---\n","Train Metrics: {'MSE': 0.0005327683174982667, 'MAE': 0.0024941451847553253, 'R2': 0.9956803321838379, 'Avg Pearson Correlation': np.float64(0.9978357096941781)}\n","Validation Metrics: {'MSE': 0.10268654674291611, 'MAE': 0.18777428567409515, 'R2': 0.002518061315640807, 'Avg Pearson Correlation': np.float64(0.3981909506071373)}\n","Full Data Metrics: {'MSE': 0.00069020054070279, 'MAE': 0.0034672098699957132, 'R2': 0.9933817386627197, 'Avg Pearson Correlation': np.float64(0.9966809283725399)}\n","Test predictions saved to MultiOutputXGBoost_MSE_test_task2_pca.csv\n","Test submission shape: (130, 52)\n","\n"]}]},{"cell_type":"markdown","source":["# **XG2**"],"metadata":{"id":"G2iIxM1Y_3dS"}},{"cell_type":"code","source":[],"metadata":{"id":"4a167-MYAHry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# ------- Custom metrics -------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        corrs.append(0 if np.isnan(corr) else corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        if np.linalg.norm(y_true[:, i]) > 0 and np.linalg.norm(y_pred[:, i]) > 0:\n","            cs = cosine_similarity(y_true[:, i].reshape(1, -1), y_pred[:, i].reshape(1, -1))[0, 0]\n","        else:\n","            cs = 0\n","        cos_sims.append(cs)\n","    return np.mean(cos_sims)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    pearson = pearson_correlation_score(y_true, y_pred)\n","    cosine = cosine_similarity_score(y_true, y_pred)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': pearson,\n","        'Avg Cosine Similarity': cosine\n","    }\n","\n","# ------- Custom objectives for XGBoost -------\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    y_true_mean = np.mean(labels)\n","    y_pred_mean = np.mean(preds)\n","    y_true_centered = labels - y_true_mean\n","    y_pred_centered = preds - y_pred_mean\n","    numerator = np.sum(y_true_centered * y_pred_centered)\n","    y_true_std = np.sqrt(np.sum(y_true_centered**2)) + 1e-8\n","    y_pred_std = np.sqrt(np.sum(y_pred_centered**2)) + 1e-8\n","    denominator = y_true_std * y_pred_std\n","\n","    d_numerator = y_true_centered\n","    d_y_pred_std = y_pred_centered / y_pred_std\n","    d_denominator = y_true_std * d_y_pred_std\n","\n","    gradient = -(d_numerator * denominator - numerator * d_denominator) / (denominator ** 2)\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","    y_true_normalized = labels / label_norm\n","    y_pred_normalized = preds / pred_norm\n","\n","    gradient = - y_true_normalized / pred_norm\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","# ------- Training function per model -------\n","\n","def train_custom_xgb_model(X, y, X_val, y_val, X_test, test_form, target_cols, custom_obj, model_name):\n","    print(f\"Training {model_name} ...\")\n","\n","    val_preds = []\n","    val_trues = []\n","\n","    test_preds = np.zeros((X_test.shape[0], y.shape[1]))\n","\n","    for i, col in enumerate(target_cols):\n","        print(f\"Training target: {col}\")\n","        # create DMatrix for training\n","        dtrain = xgb.DMatrix(X, label=y[:, i])\n","        dval = xgb.DMatrix(X_val, label=y_val[:, i])\n","        params = {\n","            'objective': 'reg:squarederror',  # ignored because of custom obj\n","            'max_depth': 6,\n","            'learning_rate': 0.1,\n","            'verbosity': 0,\n","            'seed': 42,\n","        }\n","        # Train model with early stopping evaluated on val split\n","        model = xgb.train(\n","            params,\n","            dtrain,\n","            num_boost_round=100,\n","            obj=custom_obj,\n","            evals=[(dval, 'validation')],\n","            early_stopping_rounds=10,\n","            verbose_eval=False\n","        )\n","\n","        # Predict validation\n","        val_pred = model.predict(dval)\n","        val_preds.append(val_pred)\n","        val_trues.append(y_val[:, i])\n","\n","        # Refit on full data for test prediction\n","        dfull = xgb.DMatrix(X, label=y[:, i])\n","        model_full = xgb.train(params, dfull, num_boost_round=model.best_iteration or 100, obj=custom_obj, verbose_eval=False)\n","\n","        dtest = xgb.DMatrix(X_test)\n","        test_preds[:, i] = model_full.predict(dtest)\n","\n","    # Aggregate validation results\n","    val_preds_arr = np.column_stack(val_preds)\n","    val_trues_arr = np.column_stack(val_trues)\n","\n","    print(f\"{model_name} - Validation metrics (aggregated):\")\n","    print(calculate_metrics(val_trues_arr, val_preds_arr))\n","\n","    # Save test predictions\n","    submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        submission[col] = test_preds[:, i]\n","    submission_file = f\"{model_name}_test_task2_pca.csv\"\n","    submission.to_csv(submission_file, index=False)\n","    print(f\"Saved test predictions to {submission_file}\")\n","\n","# ------- Prepare data -------\n","\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","target_cols = target_cols  # list of 51 target column names\n","test_form_df = test_form  # contains 'stimulus'\n","\n","\n","# Split train data for validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# ------- Run models -------\n","\n","# 1. Pearson correlation objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    pearson_correlation_obj, \"XGBoost_PearsonCorrelation\"\n",")\n","\n","# 2. Cosine similarity objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    cosine_similarity_obj, \"XGBoost_CosineSimilarity\"\n",")\n"],"metadata":{"id":"vccgUip_XjH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754666812052,"user_tz":-330,"elapsed":49578,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"58e527e2-8940-4e61-9c8f-b0dc638f403f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training XGBoost_PearsonCorrelation ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_PearsonCorrelation - Validation metrics (aggregated):\n","{'MSE': 6845686611968.0, 'MAE': 2032848.5, 'R2': -151139681042432.0, 'Avg Pearson Correlation': np.float64(0.3053868908752571), 'Avg Cosine Similarity': np.float32(0.18349199)}\n","Saved test predictions to XGBoost_PearsonCorrelation_test_task2_pca.csv\n","Training XGBoost_CosineSimilarity ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_CosineSimilarity - Validation metrics (aggregated):\n","{'MSE': 0.20699888467788696, 'MAE': 0.40242958068847656, 'R2': -3.7163145542144775, 'Avg Pearson Correlation': np.float64(0.29286005100613965), 'Avg Cosine Similarity': np.float32(0.60436964)}\n","Saved test predictions to XGBoost_CosineSimilarity_test_task2_pca.csv\n"]}]}]}
{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1SXCxTIzx4NM6EQlcKqfbDB7SiaKIPCza","timestamp":1754717245218}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"wRKsoWqyBcy0"},"outputs":[],"source":["import pandas as pd\n","\n","# Load all data files\n","comp_def = pd.read_csv(\"TASK2_Component_definition.csv\")\n","stim_def = pd.read_csv(\"TASK2_Stimulus_definition.csv\")\n","cid_map = pd.read_csv(\"CID.csv\")\n","mol_features = pd.read_csv(\"concatenated_fingerprints.csv\")  # Provided separately\n","train_targets = pd.read_csv(\"TASK2_Train_mixture_Dataset.csv\")\n","test_stimuli = pd.read_csv(\"TASK2_Test_set_Submission_form.csv\")\n","\n","# Merge component → molecule → molecule features\n","comp_full = comp_def.merge(cid_map, left_on=\"CID\", right_on=\"molecule\", how=\"left\") \\\n","                    .merge(mol_features, on=\"molecule\", how=\"left\")\n","\n","# Expand stimulus → components\n","stim_expanded = stim_def.assign(component_id=stim_def['components'].str.split(';')).explode('component_id')\n","stim_expanded['component_id'] = stim_expanded['component_id'].astype(int)\n","\n","# Merge in component details + features\n","stim_with_feats = stim_expanded.merge(comp_full, left_on=\"component_id\", right_on=\"id\", how=\"left\")\n","\n","# Aggregate features for each stimulus (weighted avg by dilution)\n","feature_cols = [c for c in mol_features.columns if c not in ['molecule','SMILES']]\n","agg_funcs = {f: (lambda x, w=stim_with_feats['dilution']: (x*w).sum() / w.sum()) for f in feature_cols}\n","\n","X_stim = stim_with_feats.groupby('id_x').apply(\n","    lambda g: pd.Series({feat: (g[feat]*g['dilution']).sum() / g['dilution'].sum() for feat in feature_cols})\n",").reset_index().rename(columns={'id_x':'stimulus'})\n","\n","# Merge with targets for TRAIN\n","train_df = train_targets.merge(X_stim, on=\"stimulus\", how=\"left\")\n","y_train = train_df[[c for c in train_targets.columns if c not in ['stimulus', 'Intensity', 'Pleasantness']]]\n","X_train = train_df.drop(columns=y_train.columns)\n","\n","# Prepare TEST set the same way\n","X_test = test_stimuli.merge(X_stim, on=\"stimulus\", how=\"left\")\n","# List of descriptor target columns\n","target_cols = [\n","    'Green', 'Cucumber', 'Herbal', 'Mint', 'Woody', 'Pine', 'Floral',\n","    'Powdery', 'Fruity', 'Citrus', 'Tropical', 'Berry', 'Peach', 'Sweet',\n","    'Caramellic', 'Vanilla', 'BrownSpice', 'Smoky', 'Burnt', 'Roasted',\n","    'Grainy', 'Meaty', 'Nutty', 'Fatty', 'Coconut', 'Waxy', 'Dairy',\n","    'Buttery', 'Cheesy', 'Sour', 'Fermented', 'Sulfurous', 'Garlic.Onion',\n","    'Earthy', 'Mushroom', 'Musty', 'Ammonia', 'Fishy', 'Fecal',\n","    'Rotten.Decay', 'Rubber', 'Phenolic', 'Animal', 'Medicinal',\n","    'Cooling', 'Sharp', 'Chlorine', 'Alcoholic', 'Plastic', 'Ozone', 'Metallic'\n","]\n","\n","# Drop targets from X_test if they exist\n","X_test = X_test.drop(columns=[c for c in target_cols if c in X_test.columns])\n"]},{"cell_type":"code","source":["print(X_train.head())\n","print(X_test.shape)\n","print(y_train.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FhMocKbWPdxU","executionInfo":{"status":"ok","timestamp":1754661608322,"user_tz":-330,"elapsed":471,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"1b18d4ff-a979-446c-90d9-898f02a7be44"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["  stimulus  MACCS_0  MACCS_1  MACCS_2  MACCS_3  MACCS_4  MACCS_5  MACCS_6  \\\n","0    AA007      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n","1    AA085      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n","2    AA088      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n","3    AA097      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n","4    AA142      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n","\n","   MACCS_7  MACCS_8  ...      SRW10     TSRW10          MW       AMW  \\\n","0      0.0      0.0  ...  10.340125  68.368312  256.453367  5.732591   \n","1      0.0      0.0  ...   9.597926  42.265087  155.762211  5.383940   \n","2      0.0      0.0  ...   9.029562  42.739382  173.717179  6.538335   \n","3      0.0      0.0  ...   7.537016  35.746383  138.928406  5.525270   \n","4      0.0      0.0  ...  10.379972  68.822549  258.086302  5.740114   \n","\n","        WPath       WPol     Zagreb1     Zagreb2  mZagreb1  mZagreb2  \n","0  588.645320  38.527094  110.847291  139.389163  7.981938  3.817323  \n","1  133.415842  16.891089   57.702970   66.603960  5.967547  2.249175  \n","2  245.333333  16.333333   56.190476   62.761905  5.013228  3.197090  \n","3  160.187500   7.125000   34.375000   32.687500  3.967014  2.710069  \n","4  594.489510  38.966034  111.914086  140.883117  8.037130  3.831752  \n","\n","[5 rows x 3713 columns]\n","(130, 3713)\n","(393, 51)\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","X_train= pd.read_csv(\"X_train_cleaned.csv\")\n","X_test= pd.read_csv(\"X_test_cleaned.csv\")\n","y_train= pd.read_csv(\"y_train.csv\")\n","# Remove unwanted columns\n","X_train = X_train.drop(columns=[\"Intensity\", \"Pleasantness\"], errors='ignore')\n","X_test = X_test.drop(columns=[\"Intensity\", \"Pleasantness\"], errors='ignore')\n","\n","# Ensure both have same columns in the same order\n","X_test = X_test[X_train.columns]\n","\n"],"metadata":{"id":"7SOmmemYi4is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.feature_selection import SelectKBest, f_regression\n","# Drop 'stimulus' column before PCA\n","stimulus_train = X_train['stimulus']\n","stimulus_test = X_test['stimulus']\n","X_train = X_train.drop(columns=['stimulus'])\n","X_test = X_test.drop(columns=['stimulus'])\n","def select_k_best_features(x_df, y_df, k=50):\n","    \"\"\"\n","    Select top k features with SelectKBest for multi-output regression by\n","    averaging F-scores across all target columns.\n","\n","    Parameters:\n","        x_df (pd.DataFrame): Feature dataframe\n","        y_df (pd.DataFrame): Multi-output target dataframe\n","        k (int): Number of top features to select\n","\n","    Returns:\n","        X_selected_df (pd.DataFrame): DataFrame with top k features selected (train data)\n","    \"\"\"\n","\n","    # Convert to numpy\n","    X = x_df.values\n","    y = y_df.values\n","\n","    # We'll collect scores for each target\n","    all_scores = []\n","    for i in range(y.shape[1]):\n","        # Compute f_regression univariate scores for this target\n","        scores, _ = f_regression(X, y[:, i])\n","        all_scores.append(scores)\n","\n","    # Average scores across all targets\n","    avg_scores = np.mean(np.array(all_scores), axis=0)\n","\n","    # Select indices of top k scores\n","    top_k_indices = np.argsort(avg_scores)[::-1][:k]\n","\n","    # Subset dataframe to these columns\n","    selected_columns = x_df.columns[top_k_indices]\n","    X_selected_df = x_df.loc[:, selected_columns]\n","\n","    return X_selected_df\n","\n","# Example usage:\n","x_df_lasso = select_k_best_features(X_train, y_train, k=50)\n","\n","selected_features_lasso = x_df_lasso.columns.tolist()\n","\n","# Filter X_df to contain only the selected features\n","X_test = X_test[selected_features_lasso]"],"metadata":{"id":"pEpC_eIAolR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save X_df_lasso to CSV\n","x_df_lasso.to_csv('X_selectkbest.csv', index=False)\n","\n","# Save X_train to CSV\n","X_test.to_csv('X_test_selectkbest.csv', index=False)\n"],"metadata":{"id":"30iJbrcKEk3L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(X_train.shape)\n","print(X_test.shape)\n","print(y_train.shape)\n","print(x_df_lasso.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptPIplwOp4QQ","executionInfo":{"status":"ok","timestamp":1754661652673,"user_tz":-330,"elapsed":5,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"e0510017-0b48-41fd-fd72-e710bd7c385d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(393, 3712)\n","(130, 50)\n","(393, 51)\n","(393, 50)\n"]}]},{"cell_type":"code","source":["\n","test_form=test_stimuli\n","y_df=y_train"],"metadata":{"id":"ofVXmp_c6dDA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Hyperbolic model**"],"metadata":{"id":"XgdSwKLH6ym0"}},{"cell_type":"code","source":[],"metadata":{"id":"45RBiqq7614x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class PearsonCosineLoss(nn.Module):\n","    def __init__(self, alpha=0.5, eps=1e-8):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.eps = eps\n","        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=eps)\n","\n","    def forward(self, y_pred, y_true):\n","        # Pearson Correlation (1 - correlation for minimization)\n","        y_pred_centered = y_pred - y_pred.mean(dim=1, keepdim=True)\n","        y_true_centered = y_true - y_true.mean(dim=1, keepdim=True)\n","        numerator = (y_pred_centered * y_true_centered).sum(dim=1)\n","        denominator = (y_pred_centered.pow(2).sum(dim=1) * y_true_centered.pow(2).sum(dim=1)).sqrt() + self.eps\n","        pearson_corr = numerator / denominator\n","        pearson_loss = 1 - pearson_corr\n","\n","        # Cosine Similarity (1 - similarity for minimization)\n","        cosine_loss = 1 - self.cosine_similarity(y_pred, y_true)\n","        loss = self.alpha * pearson_loss + (1 - self.alpha) * cosine_loss\n","        return loss.mean()\n","class HyperbolicModel(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, output_dim)\n","        self.tanh = nn.Tanh()\n","    def forward(self, x):\n","        x = self.tanh(self.fc1(x))\n","        x = self.tanh(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    corrs = [np.corrcoef(y_true[:,i], y_pred[:,i])[0,1] if np.std(y_true[:,i])>0 and np.std(y_pred[:,i])>0 else 0 for i in range(y_true.shape[1])]\n","    avg_pearson = np.mean(corrs)\n","    norms_true = np.linalg.norm(y_true, axis=1)\n","    norms_pred = np.linalg.norm(y_pred, axis=1)\n","    cos = np.sum(y_true * y_pred, axis=1) / (norms_true * norms_pred + 1e-8)\n","    avg_cosine = np.mean(cos)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine\n","    }\n","\n","# Training routine\n","def train_and_evaluate(X, y, test_ratio=0.2, epochs=100, lr=1e-3, batch_size=32, alpha=0.5):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # Split\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_ratio, random_state=42)\n","    X_train_t = torch.FloatTensor(X_train).to(device)\n","    y_train_t = torch.FloatTensor(y_train).to(device)\n","    X_val_t = torch.FloatTensor(X_val).to(device)\n","    y_val_t = torch.FloatTensor(y_val).to(device)\n","\n","    # Model\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    loss_fn = PearsonCosineLoss(alpha=alpha)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    n = X_train.shape[0]\n","    steps_per_epoch = int(np.ceil(n / batch_size))\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        idx = np.random.permutation(n)\n","        for i in range(steps_per_epoch):\n","            batch_idx = idx[i*batch_size:(i+1)*batch_size]\n","            xb = X_train_t[batch_idx]\n","            yb = y_train_t[batch_idx]\n","            optimizer.zero_grad()\n","            y_pred = model(xb)\n","            loss = loss_fn(y_pred, yb)\n","            loss.backward()\n","            optimizer.step()\n","        if (epoch+1) % 20 == 0:\n","            print(f\"Epoch {epoch+1}/{epochs}: Train Loss = {loss.item():.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        y_train_pred = model(X_train_t).cpu().numpy()\n","        y_val_pred = model(X_val_t).cpu().numpy()\n","\n","    # Print metrics on split data\n","    train_metrics = calculate_metrics(y_train, y_train_pred)\n","    val_metrics = calculate_metrics(y_val, y_val_pred)\n","    print(\"\\\\nTrain Metrics:\", train_metrics)\n","    print(\"Validation Metrics:\", val_metrics)\n","\n","    # Retrain on full data\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    X_full_t = torch.FloatTensor(X).to(device)\n","    y_full_t = torch.FloatTensor(y).to(device)\n","    for epoch in range(epochs):\n","        optimizer.zero_grad()\n","        y_pred = model(X_full_t)\n","        loss = loss_fn(y_pred, y_full_t)\n","        loss.backward()\n","        optimizer.step()\n","    model.eval()\n","    with torch.no_grad():\n","        y_full_pred = model(X_full_t).cpu().numpy()\n","    full_metrics = calculate_metrics(y, y_full_pred)\n","    print(\"\\\\nMetrics on Full Data:\", full_metrics)\n","    return model, device\n","# Run training and print metrics\n","model, device = train_and_evaluate(\n","    x_df_lasso.to_numpy(dtype=np.float32),\n","    y_df.to_numpy(dtype=np.float32),\n","    test_ratio=0.2,\n","    epochs=100,\n","    lr=1e-3,\n","    batch_size=32,\n","    alpha=0.5\n",")\n","\n","# Convert all columns to numeric (with NaNs where conversion failed)\n","X_test_numeric = X_test.apply(pd.to_numeric, errors='coerce')\n","\n","# Fill NaN values (e.g., with 0 or other imputation strategy)\n","X_test_filled = X_test_numeric.fillna(0)\n","\n","# Convert to numpy array of floats\n","X_test_arr = X_test_filled.to_numpy(dtype=np.float32)\n","with torch.no_grad():\n","    X_test_tensor = torch.FloatTensor(X_test_arr).to(device)\n","    test_preds = model(X_test_tensor).cpu().numpy()\n","\n","# Save submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","\n","test_submission.to_csv('hyperbolic_task1_selectKBest.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKn1rTrhN47u","executionInfo":{"status":"ok","timestamp":1754661690002,"user_tz":-330,"elapsed":2290,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"ca23ef0f-a905-4ffb-9a3a-cbc40e2f63ba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 20/100: Train Loss = 0.3821\n","Epoch 40/100: Train Loss = 0.3378\n","Epoch 60/100: Train Loss = 0.2628\n","Epoch 80/100: Train Loss = 0.2234\n","Epoch 100/100: Train Loss = 0.2858\n","\\nTrain Metrics: {'MSE': 0.07160959392786026, 'MAE': 0.1663902848958969, 'R2': 0.2997744381427765, 'Avg Pearson Correlation': np.float64(0.5690874771957686), 'Avg Cosine Similarity': np.float32(0.81192607)}\n","Validation Metrics: {'MSE': 0.08727452158927917, 'MAE': 0.1889084130525589, 'R2': 0.11720053106546402, 'Avg Pearson Correlation': np.float64(0.43495913906400185), 'Avg Cosine Similarity': np.float32(0.73271805)}\n","\\nMetrics on Full Data: {'MSE': 0.10184694826602936, 'MAE': 0.21781644225120544, 'R2': 0.030575264245271683, 'Avg Pearson Correlation': np.float64(0.3097160872774384), 'Avg Cosine Similarity': np.float32(0.7215691)}\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **Correlation regressor**"],"metadata":{"id":"pSjUqg9565EQ"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","\n","\n","# Pearson correlation loss (maximize correlation by minimizing negative correlation)\n","def pearson_correlation_loss(y_true, y_pred):\n","    y_true_centered = y_true - tf.reduce_mean(y_true, axis=1, keepdims=True)\n","    y_pred_centered = y_pred - tf.reduce_mean(y_pred, axis=1, keepdims=True)\n","    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n","    denominator = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered), axis=1)) * tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered), axis=1))\n","    correlation = numerator / (denominator + 1e-8)\n","    return -tf.reduce_mean(correlation)\n","\n","\n","def create_olfactory_model(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(128, activation='relu', input_shape=(input_dim,)),\n","        Dense(64, activation='relu'),\n","        Dense(output_dim, activation='linear')\n","    ])\n","    model.compile(optimizer='adam', loss=pearson_correlation_loss, metrics=['mse'])\n","    return model\n","\n","\n","class CorrelationRegressor(BaseEstimator, RegressorMixin):\n","    def __init__(self, input_dim=None, output_dim=None, epochs=100, batch_size=32, verbose=0):\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.verbose = verbose\n","        self.model_ = None\n","\n","    def fit(self, X, y):\n","        if self.input_dim is None:\n","            self.input_dim = X.shape[1]\n","        if self.output_dim is None:\n","            self.output_dim = y.shape[1] if len(y.shape) > 1 else 1\n","        self.model_ = create_olfactory_model(self.input_dim, self.output_dim)\n","        self.model_.fit(\n","            X, y,\n","            epochs=self.epochs,\n","            batch_size=self.batch_size,\n","            verbose=self.verbose\n","        )\n","        return self\n","\n","    def predict(self, X):\n","        if self.model_ is None:\n","            raise ValueError(\"Model not fitted yet\")\n","        return self.model_.predict(X)\n","\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","\n","# Convert DataFrames to numpy arrays\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","\n","# 1. Split data 80% train, 20% validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","\n","# 2. Initialize regressor\n","regressor = CorrelationRegressor(\n","    input_dim=X_train_split.shape[1],\n","    output_dim=y_train_split.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","\n","# 3. Train on 80% split\n","regressor.fit(X_train_split, y_train_split)\n","\n","# 4. Evaluate on train split and validation split\n","y_train_pred = regressor.predict(X_train_split)\n","y_val_pred = regressor.predict(X_val)\n","\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","\n","# 5. Train on full dataset (train + val)\n","regressor_full = CorrelationRegressor(\n","    input_dim=X.shape[1],\n","    output_dim=y.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","regressor_full.fit(X, y)\n","\n","# 6. Evaluate on entire training dataset\n","y_full_pred = regressor_full.predict(X)\n","print(\"\\nFull training dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","\n","# 7. Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = regressor_full.predict(X_test_arr)\n","\n","# 8. Save submission file\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('corr_test_selectKBest.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"2EGVulygyAxt","executionInfo":{"status":"ok","timestamp":1754661719231,"user_tz":-330,"elapsed":21150,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"16a0a5ba-a174-4eb2-8c87-04a578f0aa0f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: -0.1659 - mse: 24.2250\n","Epoch 2/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.3566 - mse: 34.3307 \n","Epoch 3/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4257 - mse: 39.8883 \n","Epoch 4/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.4462 - mse: 46.1744 \n","Epoch 5/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4586 - mse: 49.2815 \n","Epoch 6/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4589 - mse: 51.3423 \n","Epoch 7/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4716 - mse: 49.0795 \n","Epoch 8/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4448 - mse: 48.9267 \n","Epoch 9/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4712 - mse: 47.6118 \n","Epoch 10/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4774 - mse: 43.2231  \n","Epoch 11/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4833 - mse: 39.5732 \n","Epoch 12/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4684 - mse: 36.1843 \n","Epoch 13/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4787 - mse: 31.8628 \n","Epoch 14/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5046 - mse: 26.3036 \n","Epoch 15/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4989 - mse: 23.1548 \n","Epoch 16/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5035 - mse: 18.7192 \n","Epoch 17/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4982 - mse: 16.9159 \n","Epoch 18/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5113 - mse: 14.9800 \n","Epoch 19/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5133 - mse: 13.0473 \n","Epoch 20/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5197 - mse: 11.7754 \n","Epoch 21/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5202 - mse: 10.2327 \n","Epoch 22/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5316 - mse: 9.2611 \n","Epoch 23/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5430 - mse: 8.4796 \n","Epoch 24/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5321 - mse: 7.9298 \n","Epoch 25/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5332 - mse: 7.3632 \n","Epoch 26/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5383 - mse: 7.2512 \n","Epoch 27/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5343 - mse: 7.0673 \n","Epoch 28/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5381 - mse: 6.4582 \n","Epoch 29/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5421 - mse: 6.2932 \n","Epoch 30/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5522 - mse: 5.7075 \n","Epoch 31/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5535 - mse: 5.6478 \n","Epoch 32/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5443 - mse: 5.4741 \n","Epoch 33/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5593 - mse: 4.9431 \n","Epoch 34/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5577 - mse: 4.8270 \n","Epoch 35/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5629 - mse: 5.5156 \n","Epoch 36/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5740 - mse: 5.0784 \n","Epoch 37/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5738 - mse: 4.5942 \n","Epoch 38/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5842 - mse: 4.3987 \n","Epoch 39/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5707 - mse: 4.5113 \n","Epoch 40/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.5643 - mse: 4.5034\n","Epoch 41/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5657 - mse: 4.2768  \n","Epoch 42/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5759 - mse: 3.6658 \n","Epoch 43/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5728 - mse: 3.7693 \n","Epoch 44/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5762 - mse: 3.7336 \n","Epoch 45/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5763 - mse: 3.5518 \n","Epoch 46/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5810 - mse: 3.6675 \n","Epoch 47/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5748 - mse: 3.3003 \n","Epoch 48/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5836 - mse: 3.2427 \n","Epoch 49/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5909 - mse: 3.0916 \n","Epoch 50/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5739 - mse: 3.0958 \n","Epoch 51/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6010 - mse: 3.0138 \n","Epoch 52/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5827 - mse: 2.9998 \n","Epoch 53/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5736 - mse: 2.8158 \n","Epoch 54/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5927 - mse: 2.8172 \n","Epoch 55/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5946 - mse: 2.6532 \n","Epoch 56/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6019 - mse: 2.3337 \n","Epoch 57/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5945 - mse: 2.4825 \n","Epoch 58/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6000 - mse: 2.5214 \n","Epoch 59/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6034 - mse: 2.4001 \n","Epoch 60/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6011 - mse: 2.3741 \n","Epoch 61/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6170 - mse: 2.2923 \n","Epoch 62/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5982 - mse: 2.2269 \n","Epoch 63/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6150 - mse: 2.2589 \n","Epoch 64/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6028 - mse: 2.1801 \n","Epoch 65/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5993 - mse: 2.4254 \n","Epoch 66/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6104 - mse: 2.3598 \n","Epoch 67/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6078 - mse: 2.1475 \n","Epoch 68/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5958 - mse: 2.0664 \n","Epoch 69/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6094 - mse: 2.1721 \n","Epoch 70/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6084 - mse: 1.9631 \n","Epoch 71/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6054 - mse: 1.8704 \n","Epoch 72/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6057 - mse: 1.7569 \n","Epoch 73/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6210 - mse: 1.6532 \n","Epoch 74/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6130 - mse: 2.0958 \n","Epoch 75/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6238 - mse: 1.7450 \n","Epoch 76/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6225 - mse: 1.6587 \n","Epoch 77/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6193 - mse: 1.7221 \n","Epoch 78/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6213 - mse: 1.7979 \n","Epoch 79/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6219 - mse: 1.5038 \n","Epoch 80/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6294 - mse: 1.8654 \n","Epoch 81/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6150 - mse: 1.9850 \n","Epoch 82/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6308 - mse: 1.6313 \n","Epoch 83/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6398 - mse: 1.5067 \n","Epoch 84/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6352 - mse: 1.5004 \n","Epoch 85/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6347 - mse: 1.5834 \n","Epoch 86/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6356 - mse: 1.4795 \n","Epoch 87/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6460 - mse: 1.6414 \n","Epoch 88/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6393 - mse: 1.8975 \n","Epoch 89/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6268 - mse: 1.7907 \n","Epoch 90/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6219 - mse: 1.5703 \n","Epoch 91/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6396 - mse: 1.6615 \n","Epoch 92/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6269 - mse: 1.3946 \n","Epoch 93/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6514 - mse: 1.5932 \n","Epoch 94/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6392 - mse: 1.5267 \n","Epoch 95/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6421 - mse: 1.5288 \n","Epoch 96/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6458 - mse: 1.5464 \n","Epoch 97/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6593 - mse: 1.3378 \n","Epoch 98/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6410 - mse: 1.3622 \n","Epoch 99/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6470 - mse: 1.2980 \n","Epoch 100/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6256 - mse: 1.4405 \n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n","Training set metrics:\n","{'MSE': 1.5262385606765747, 'MAE': 0.9110705256462097, 'R2': -24.99949073791504, 'Avg Pearson Correlation': np.float64(0.43532624408535003), 'Avg Cosine Similarity': np.float32(0.1306542)}\n","\n","Validation set metrics:\n","{'MSE': 1.824042558670044, 'MAE': 0.963718593120575, 'R2': -35.57246780395508, 'Avg Pearson Correlation': np.float64(0.351811700652305), 'Avg Cosine Similarity': np.float32(0.09230334)}\n","Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: -0.1472 - mse: 46.5588   \n","Epoch 2/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.3558 - mse: 74.1892 \n","Epoch 3/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4154 - mse: 90.9855  \n","Epoch 4/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4416 - mse: 107.2750 \n","Epoch 5/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4517 - mse: 111.8941  \n","Epoch 6/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4621 - mse: 107.1603  \n","Epoch 7/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4696 - mse: 99.3328  \n","Epoch 8/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4753 - mse: 86.7735 \n","Epoch 9/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4694 - mse: 80.9822 \n","Epoch 10/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4864 - mse: 73.3630 \n","Epoch 11/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4799 - mse: 63.8421 \n","Epoch 12/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4733 - mse: 54.6697 \n","Epoch 13/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4955 - mse: 47.7161 \n","Epoch 14/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5001 - mse: 38.8632 \n","Epoch 15/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.4939 - mse: 37.1413 \n","Epoch 16/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5074 - mse: 30.6447\n","Epoch 17/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5027 - mse: 25.0912 \n","Epoch 18/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4997 - mse: 22.1483 \n","Epoch 19/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5120 - mse: 18.9417 \n","Epoch 20/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5026 - mse: 16.4490 \n","Epoch 21/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5142 - mse: 14.8712 \n","Epoch 22/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5132 - mse: 14.0910  \n","Epoch 23/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.5342 - mse: 12.2045\n","Epoch 24/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5321 - mse: 11.0556 \n","Epoch 25/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5408 - mse: 10.7633 \n","Epoch 26/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5110 - mse: 9.2899  \n","Epoch 27/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5280 - mse: 9.2054 \n","Epoch 28/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5395 - mse: 8.9684 \n","Epoch 29/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5518 - mse: 8.6417 \n","Epoch 30/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5303 - mse: 7.4409 \n","Epoch 31/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5603 - mse: 7.5140 \n","Epoch 32/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5390 - mse: 7.0638 \n","Epoch 33/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5476 - mse: 7.4109 \n","Epoch 34/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5411 - mse: 5.9368 \n","Epoch 35/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.5611 - mse: 5.9661 \n","Epoch 36/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5622 - mse: 5.6356 \n","Epoch 37/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5642 - mse: 5.0807 \n","Epoch 38/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5793 - mse: 6.0499 \n","Epoch 39/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5634 - mse: 5.0868 \n","Epoch 40/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5778 - mse: 4.5499 \n","Epoch 41/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5762 - mse: 4.6576 \n","Epoch 42/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5669 - mse: 4.1232 \n","Epoch 43/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5725 - mse: 3.9989 \n","Epoch 44/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5646 - mse: 4.0685 \n","Epoch 45/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6013 - mse: 4.3974 \n","Epoch 46/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5843 - mse: 4.7727  \n","Epoch 47/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5671 - mse: 4.3227  \n","Epoch 48/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5748 - mse: 3.9990 \n","Epoch 49/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5809 - mse: 3.9838 \n","Epoch 50/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5944 - mse: 4.0277 \n","Epoch 51/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5936 - mse: 4.2904 \n","Epoch 52/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5899 - mse: 3.7247 \n","Epoch 53/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6060 - mse: 3.4855 \n","Epoch 54/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5932 - mse: 3.3397 \n","Epoch 55/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5936 - mse: 3.5642  \n","Epoch 56/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5923 - mse: 2.9280 \n","Epoch 57/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6020 - mse: 3.2054 \n","Epoch 58/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6032 - mse: 3.4278  \n","Epoch 59/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6062 - mse: 2.9722  \n","Epoch 60/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6053 - mse: 3.1411 \n","Epoch 61/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6173 - mse: 2.9715 \n","Epoch 62/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6107 - mse: 3.2276 \n","Epoch 63/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.5868 - mse: 2.8503 \n","Epoch 64/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6091 - mse: 3.6207  \n","Epoch 65/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6141 - mse: 2.7760 \n","Epoch 66/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6195 - mse: 2.8381 \n","Epoch 67/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6064 - mse: 3.1083 \n","Epoch 68/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6134 - mse: 2.9139 \n","Epoch 69/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6255 - mse: 3.1230 \n","Epoch 70/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6118 - mse: 3.0497 \n","Epoch 71/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6275 - mse: 2.4694 \n","Epoch 72/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6277 - mse: 2.6344 \n","Epoch 73/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6173 - mse: 2.6420 \n","Epoch 74/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6158 - mse: 3.0224 \n","Epoch 75/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6174 - mse: 2.6112 \n","Epoch 76/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6267 - mse: 2.3906 \n","Epoch 77/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6321 - mse: 2.2100 \n","Epoch 78/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6262 - mse: 2.5823\n","Epoch 79/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6273 - mse: 2.6756 \n","Epoch 80/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6169 - mse: 2.8735 \n","Epoch 81/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6228 - mse: 2.3843 \n","Epoch 82/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6283 - mse: 2.4956 \n","Epoch 83/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6301 - mse: 2.1375 \n","Epoch 84/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6481 - mse: 2.4271 \n","Epoch 85/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6388 - mse: 2.3882 \n","Epoch 86/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6412 - mse: 1.9704 \n","Epoch 87/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6317 - mse: 1.8659 \n","Epoch 88/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6419 - mse: 2.1414 \n","Epoch 89/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6275 - mse: 2.2958 \n","Epoch 90/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6153 - mse: 2.5639  \n","Epoch 91/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6448 - mse: 2.2447 \n","Epoch 92/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6412 - mse: 2.3943 \n","Epoch 93/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6505 - mse: 2.2044 \n","Epoch 94/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6434 - mse: 2.3945  \n","Epoch 95/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6464 - mse: 2.3181 \n","Epoch 96/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: -0.6427 - mse: 2.0110 \n","Epoch 97/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6530 - mse: 2.1180 \n","Epoch 98/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6556 - mse: 1.8668 \n","Epoch 99/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6639 - mse: 1.8724 \n","Epoch 100/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: -0.6596 - mse: 2.1521 \n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n","\n","Full training dataset metrics:\n","{'MSE': 2.128830909729004, 'MAE': 1.059783697128296, 'R2': -35.480716705322266, 'Avg Pearson Correlation': np.float64(0.42019520858741055), 'Avg Cosine Similarity': np.float32(0.067468464)}\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **RF1**"],"metadata":{"id":"F8MeTU0Q7LHa"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","import pandas as pd\n","\n","# Custom Pearson correlation scorer\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","# Evaluation metrics\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","# Prepare data\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","# Train-validation split\n","X_train_split, X_val, y_train_split, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train model\n","base_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","model = MultiOutputRegressor(base_model)\n","model.fit(X_train_split, y_train_split)\n","\n","# Predictions\n","y_train_pred = model.predict(X_train_split)\n","y_val_pred = model.predict(X_val)\n","\n","# Evaluation\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# Train on full data\n","final_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n","final_model.fit(X, y)\n","y_pred=final_model.predict(X)\n","print(calculate_metrics(y, y_pred))\n","# Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = final_model.predict(X_test_arr)\n","\n","# Prepare submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('rf_test_selectKBest.csv', index=False)\n","print(\"Test predictions saved to rf_test_lasso.csv\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OMa9sFH7jzy","outputId":"8d6cb22f-6496-408d-c2cb-267f7ad4b6f9","executionInfo":{"status":"ok","timestamp":1754661777989,"user_tz":-330,"elapsed":52908,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","{'MSE': 0.010918709461753523, 'MAE': 0.06442748469633679, 'R2': 0.8907187723489061, 'Avg Pearson Correlation': np.float64(0.9656632529097907), 'Avg Cosine Similarity': np.float64(0.9711460832356168)}\n","\n","Validation set metrics:\n","{'MSE': 0.06893838867940788, 'MAE': 0.16309510295158589, 'R2': 0.24438091898193057, 'Avg Pearson Correlation': np.float64(0.5333490135900242), 'Avg Cosine Similarity': np.float64(0.7394322048297546)}\n","{'MSE': 0.010740672063946542, 'MAE': 0.06314851420547937, 'R2': 0.8924325744780174, 'Avg Pearson Correlation': np.float64(0.964614143601126), 'Avg Cosine Similarity': np.float64(0.9714790123233945)}\n","Test predictions saved to rf_test_lasso.csv\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **RF2**"],"metadata":{"id":"pPbQnT8r_oow"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# --- Custom metrics ---\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr): corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    similarities = []\n","    for i in range(y_true.shape[0]):\n","        y_true_norm = y_true[i] / (np.linalg.norm(y_true[i]) + 1e-8)\n","        y_pred_norm = y_pred[i] / (np.linalg.norm(y_pred[i]) + 1e-8)\n","        similarity = np.dot(y_true_norm, y_pred_norm)\n","        similarities.append(similarity)\n","    return np.mean(similarities)\n","\n","def calculate_metrics(y_true, y_pred):\n","    return {\n","        \"MSE\": mean_squared_error(y_true, y_pred),\n","        \"MAE\": mean_absolute_error(y_true, y_pred),\n","        \"R2\": r2_score(y_true, y_pred),\n","        \"Avg Pearson Correlation\": pearson_correlation_score(y_true, y_pred),\n","        \"Avg Cosine Similarity\": cosine_similarity_score(y_true, y_pred),\n","    }\n","\n","# --------- Example workflow ---------\n","# These need to be set before running:\n","# X_df: DataFrame of features, y_df: DataFrame of targets (n_samples, n_targets)\n","# X_test_df: DataFrame of test features\n","# test_form: DataFrame with 'stimulus' column, matches rows of X_test_df\n","# target_cols: list of 51 string column names\n","\n","# 1. Convert to numpy if needed\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","X_test = X_test.to_numpy(dtype=np.float32)\n","\n","# 2. 80/20 split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 3. Train MultiOutput RandomForest\n","rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf.fit(X_train, y_train)\n","\n","# 4. Print metrics on splits\n","y_train_pred = rf.predict(X_train)\n","y_val_pred = rf.predict(X_val)\n","print(\"Training metrics:\")\n","print(calculate_metrics(y_train, y_train_pred))\n","print(\"\\nValidation metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# 5. Retrain on entire dataset, print metrics\n","rf_full = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf_full.fit(X, y)\n","y_full_pred = rf_full.predict(X)\n","print(\"\\nFull dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","# 6. Predict on test set, save file\n","test_preds = rf_full.predict(X_test)\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","test_submission.to_csv('rf_corr_cosine_metrics_test_selectKBest.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"id":"dPwlXa2e5Otw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754661885235,"user_tz":-330,"elapsed":53030,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"6bea4833-ad3b-478a-b3bc-e6e140e7a7f0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training metrics:\n","{'MSE': 0.010918709461753523, 'MAE': 0.06442748469633679, 'R2': 0.8907187723489061, 'Avg Pearson Correlation': np.float64(0.9656632529097907), 'Avg Cosine Similarity': np.float64(0.9758667063231214)}\n","\n","Validation metrics:\n","{'MSE': 0.06893838867940788, 'MAE': 0.16309510295158589, 'R2': 0.24438091898193057, 'Avg Pearson Correlation': np.float64(0.5333490135900242), 'Avg Cosine Similarity': np.float64(0.793832736757829)}\n","\n","Full dataset metrics:\n","{'MSE': 0.010740672063946542, 'MAE': 0.06314851420547937, 'R2': 0.8924325744780174, 'Avg Pearson Correlation': np.float64(0.964614143601126), 'Avg Cosine Similarity': np.float64(0.9758430703429521)}\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **XG1**"],"metadata":{"id":"Mlg703nF_u0C"}},{"cell_type":"code","source":[],"metadata":{"id":"Nk-WTU5f_4lJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics import make_scorer\n","from sklearn.multioutput import MultiOutputRegressor\n","import xgboost as xgb\n","\n","# --------------- Metrics ---------------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    avg_pearson = pearson_correlation_score(y_true, y_pred)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson\n","    }\n","\n","# --------------- Custom Objectives for XGBoost ---------------\n","# They receive (preds, dtrain) and must return (grad, hess)\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative Pearson correlation loss.\n","    This is a rough approximation for demonstration only.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_mean = np.mean(preds)\n","    label_mean = np.mean(labels)\n","    pred_centered = preds - pred_mean\n","    label_centered = labels - label_mean\n","\n","    cov = np.sum(pred_centered * label_centered)\n","    pred_var = np.sum(pred_centered ** 2) + 1e-8\n","    label_var = np.sum(label_centered ** 2) + 1e-8\n","\n","    # Gradient (negative derivative of correlation)\n","    grad = - (label_centered / (np.sqrt(pred_var) * np.sqrt(label_var))) + \\\n","           (cov * pred_centered) / (pred_var ** 1.5 * np.sqrt(label_var))\n","\n","    # Hessian approximation with small constant\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative cosine similarity loss.\n","    Rough approximation for demonstration.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","\n","    cos_sim = np.dot(preds, labels) / (pred_norm * label_norm)\n","    grad = - (labels / (pred_norm * label_norm)) + \\\n","           (cos_sim * preds) / (pred_norm ** 2)\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","# --------------- Model Wrappers ---------------\n","\n","class XGBoostCorrelationRegressor:\n","    \"\"\"XGBoost regressor for single output with Pearson correlation loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=pearson_correlation_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        # y must be 1D for single output\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class XGBoostCosineSimilarityRegressor:\n","    \"\"\"XGBoost regressor for single output with Cosine similarity loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=cosine_similarity_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class MultiOutputXGBoostRegressor:\n","    \"\"\"Multi-output regressor as sklearn wrapper over XGBRegressor.\"\"\"\n","    def __init__(self, **kwargs):\n","        base_est = xgb.XGBRegressor(objective='reg:squarederror', **kwargs)\n","        self.model = MultiOutputRegressor(base_est)\n","\n","    def fit(self, X, y):\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","# --------------- Training & evaluation function ---------------\n","\n","def train_evaluate_save(model, X, y, X_test, test_form, target_cols, model_name=\"model\"):\n","    \"\"\"\n","    Train with 80/20 split, print evaluation, retrain on full data, print evaluation, predict on test, save CSV.\n","    \"\"\"\n","    print(f\"--- Training and evaluating {model_name} ---\")\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Train on split\n","    model.fit(X_train, y_train)\n","\n","    # Predict & evaluate on train and validation split\n","    y_train_pred = model.predict(X_train)\n","    y_val_pred = model.predict(X_val)\n","    print(\"Train Metrics:\", calculate_metrics(y_train, y_train_pred))\n","    print(\"Validation Metrics:\", calculate_metrics(y_val, y_val_pred))\n","\n","    # Retrain on full dataset\n","    model.fit(X, y)\n","    y_full_pred = model.predict(X)\n","    print(\"Full Data Metrics:\", calculate_metrics(y, y_full_pred))\n","\n","    # Predict on test data\n","    test_preds = model.predict(X_test)\n","\n","    # Save predictions file\n","    test_submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        test_submission[col] = test_preds[:, i] if test_preds.shape[1] > 1 else test_preds[:, 0]\n","\n","    output_file = f'{model_name}_test_selectKBest.csv'\n","    test_submission.to_csv(output_file, index=False)\n","    print(f\"Test predictions saved to {output_file}\")\n","    print(f\"Test submission shape: {test_submission.shape}\\n\")\n","\n","# --------------- Usage Notes ---------------\n","# Variables you must have prepared before calling:\n","\n","# X: numpy array of shape (n_samples, n_features)\n","# y: numpy array of shape (n_samples, 51) - targets\n","# X_test: numpy array for test features, shape (n_test_samples, n_features)\n","# test_form: pandas DataFrame with 'stimulus' column for test samples\n","# target_cols: list of 51 odor descriptor column names, matching y columns\n","\n","# Example calls (uncomment and set your datasets appropriately):\n","#\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","model_pearson = MultiOutputXGBoostRegressor()  # Multitarget with standard MSE\n","train_evaluate_save(model_pearson, X, y, X_test, test_form, target_cols, model_name=\"MultiOutputXGBoost_MSE\")\n","\n"],"metadata":{"id":"1yk7lN9vDvT2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754661954715,"user_tz":-330,"elapsed":32750,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"6e70219b-ab79-4a4b-b271-5f4cf350eb6c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Training and evaluating MultiOutputXGBoost_MSE ---\n","Train Metrics: {'MSE': 0.0005333579028956592, 'MAE': 0.0027056317776441574, 'R2': 0.9956709742546082, 'Avg Pearson Correlation': np.float64(0.9978314898155451)}\n","Validation Metrics: {'MSE': 0.0752163678407669, 'MAE': 0.16625799238681793, 'R2': 0.158661887049675, 'Avg Pearson Correlation': np.float64(0.5268714147463488)}\n","Full Data Metrics: {'MSE': 0.0006937040016055107, 'MAE': 0.004218182060867548, 'R2': 0.9933404922485352, 'Avg Pearson Correlation': np.float64(0.9966628373336213)}\n","Test predictions saved to MultiOutputXGBoost_MSE_test_selectKBest.csv\n","Test submission shape: (130, 52)\n","\n"]}]},{"cell_type":"markdown","source":["# **XG2**"],"metadata":{"id":"G2iIxM1Y_3dS"}},{"cell_type":"code","source":[],"metadata":{"id":"4a167-MYAHry"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# ------- Custom metrics -------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        corrs.append(0 if np.isnan(corr) else corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        if np.linalg.norm(y_true[:, i]) > 0 and np.linalg.norm(y_pred[:, i]) > 0:\n","            cs = cosine_similarity(y_true[:, i].reshape(1, -1), y_pred[:, i].reshape(1, -1))[0, 0]\n","        else:\n","            cs = 0\n","        cos_sims.append(cs)\n","    return np.mean(cos_sims)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    pearson = pearson_correlation_score(y_true, y_pred)\n","    cosine = cosine_similarity_score(y_true, y_pred)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': pearson,\n","        'Avg Cosine Similarity': cosine\n","    }\n","\n","# ------- Custom objectives for XGBoost -------\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    y_true_mean = np.mean(labels)\n","    y_pred_mean = np.mean(preds)\n","    y_true_centered = labels - y_true_mean\n","    y_pred_centered = preds - y_pred_mean\n","    numerator = np.sum(y_true_centered * y_pred_centered)\n","    y_true_std = np.sqrt(np.sum(y_true_centered**2)) + 1e-8\n","    y_pred_std = np.sqrt(np.sum(y_pred_centered**2)) + 1e-8\n","    denominator = y_true_std * y_pred_std\n","\n","    d_numerator = y_true_centered\n","    d_y_pred_std = y_pred_centered / y_pred_std\n","    d_denominator = y_true_std * d_y_pred_std\n","\n","    gradient = -(d_numerator * denominator - numerator * d_denominator) / (denominator ** 2)\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","    y_true_normalized = labels / label_norm\n","    y_pred_normalized = preds / pred_norm\n","\n","    gradient = - y_true_normalized / pred_norm\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","# ------- Training function per model -------\n","\n","def train_custom_xgb_model(X, y, X_val, y_val, X_test, test_form, target_cols, custom_obj, model_name):\n","    print(f\"Training {model_name} ...\")\n","\n","    val_preds = []\n","    val_trues = []\n","\n","    test_preds = np.zeros((X_test.shape[0], y.shape[1]))\n","\n","    for i, col in enumerate(target_cols):\n","        print(f\"Training target: {col}\")\n","        # create DMatrix for training\n","        dtrain = xgb.DMatrix(X, label=y[:, i])\n","        dval = xgb.DMatrix(X_val, label=y_val[:, i])\n","        params = {\n","            'objective': 'reg:squarederror',  # ignored because of custom obj\n","            'max_depth': 6,\n","            'learning_rate': 0.1,\n","            'verbosity': 0,\n","            'seed': 42,\n","        }\n","        # Train model with early stopping evaluated on val split\n","        model = xgb.train(\n","            params,\n","            dtrain,\n","            num_boost_round=100,\n","            obj=custom_obj,\n","            evals=[(dval, 'validation')],\n","            early_stopping_rounds=10,\n","            verbose_eval=False\n","        )\n","\n","        # Predict validation\n","        val_pred = model.predict(dval)\n","        val_preds.append(val_pred)\n","        val_trues.append(y_val[:, i])\n","\n","        # Refit on full data for test prediction\n","        dfull = xgb.DMatrix(X, label=y[:, i])\n","        model_full = xgb.train(params, dfull, num_boost_round=model.best_iteration or 100, obj=custom_obj, verbose_eval=False)\n","\n","        dtest = xgb.DMatrix(X_test)\n","        test_preds[:, i] = model_full.predict(dtest)\n","\n","    # Aggregate validation results\n","    val_preds_arr = np.column_stack(val_preds)\n","    val_trues_arr = np.column_stack(val_trues)\n","\n","    print(f\"{model_name} - Validation metrics (aggregated):\")\n","    print(calculate_metrics(val_trues_arr, val_preds_arr))\n","\n","    # Save test predictions\n","    submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        submission[col] = test_preds[:, i]\n","    submission_file = f\"{model_name}_test_selectKBest.csv\"\n","    submission.to_csv(submission_file, index=False)\n","    print(f\"Saved test predictions to {submission_file}\")\n","\n","# ------- Prepare data -------\n","\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","target_cols = target_cols  # list of 51 target column names\n","test_form_df = test_form  # contains 'stimulus'\n","\n","\n","# Split train data for validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# ------- Run models -------\n","\n","# 1. Pearson correlation objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    pearson_correlation_obj, \"XGBoost_PearsonCorrelation\"\n",")\n","\n","# 2. Cosine similarity objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    cosine_similarity_obj, \"XGBoost_CosineSimilarity\"\n",")\n"],"metadata":{"id":"vccgUip_XjH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754661985322,"user_tz":-330,"elapsed":12962,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"23ad2b8f-b04f-4efa-df95-f884d8a072c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training XGBoost_PearsonCorrelation ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_PearsonCorrelation - Validation metrics (aggregated):\n","{'MSE': 7284886339584.0, 'MAE': 2093940.375, 'R2': -149010149015552.0, 'Avg Pearson Correlation': np.float64(0.4263632827799081), 'Avg Cosine Similarity': np.float32(0.2631468)}\n","Saved test predictions to XGBoost_PearsonCorrelation_test_selectKBest.csv\n","Training XGBoost_CosineSimilarity ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_CosineSimilarity - Validation metrics (aggregated):\n","{'MSE': 0.20174747705459595, 'MAE': 0.4044457972049713, 'R2': -3.712563991546631, 'Avg Pearson Correlation': np.float64(0.38724653867752834), 'Avg Cosine Similarity': np.float32(0.61929756)}\n","Saved test predictions to XGBoost_CosineSimilarity_test_selectKBest.csv\n"]}]}]}
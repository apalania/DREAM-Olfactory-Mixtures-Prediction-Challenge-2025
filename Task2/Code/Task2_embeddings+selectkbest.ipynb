{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1mABQHSBohEaOjMnNCnlH5yALCGPGyBCh","timestamp":1754717247287},{"file_id":"1zYs9sjZBKCSq6DtO4am7r9CgXrb-HUtD","timestamp":1754666832432},{"file_id":"1SXCxTIzx4NM6EQlcKqfbDB7SiaKIPCza","timestamp":1754664142029}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import pandas as pd\n","x_df_lasso= pd.read_csv(\"x_train_concat_task2.csv\")\n","X_test= pd.read_csv(\"x_test_concat_task2.csv\")\n","y_df= pd.read_csv(\"y_train.csv\")\n","test_form= pd.read_csv(\"TASK2_Test_set_Submission_form.csv\")\n","# Remove unwanted columns\n","\n","\n","\n","target_cols = [\n","    'Green', 'Cucumber', 'Herbal', 'Mint', 'Woody', 'Pine', 'Floral',\n","    'Powdery', 'Fruity', 'Citrus', 'Tropical', 'Berry', 'Peach', 'Sweet',\n","    'Caramellic', 'Vanilla', 'BrownSpice', 'Smoky', 'Burnt', 'Roasted',\n","    'Grainy', 'Meaty', 'Nutty', 'Fatty', 'Coconut', 'Waxy', 'Dairy',\n","    'Buttery', 'Cheesy', 'Sour', 'Fermented', 'Sulfurous', 'Garlic.Onion',\n","    'Earthy', 'Mushroom', 'Musty', 'Ammonia', 'Fishy', 'Fecal',\n","    'Rotten.Decay', 'Rubber', 'Phenolic', 'Animal', 'Medicinal',\n","    'Cooling', 'Sharp', 'Chlorine', 'Alcoholic', 'Plastic', 'Ozone', 'Metallic'\n","]"],"metadata":{"id":"7SOmmemYi4is"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(x_df_lasso.shape)\n","\n","print(X_test.shape)\n","print(y_df.shape)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ptPIplwOp4QQ","executionInfo":{"status":"ok","timestamp":1754667100347,"user_tz":-330,"elapsed":468,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"ff53c0c5-4f09-4ac9-9204-1c1328a80644"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(393, 101)\n","(130, 101)\n","(393, 51)\n"]}]},{"cell_type":"markdown","source":["# **Hyperbolic model**"],"metadata":{"id":"XgdSwKLH6ym0"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class PearsonCosineLoss(nn.Module):\n","    def __init__(self, alpha=0.5, eps=1e-8):\n","        super().__init__()\n","        self.alpha = alpha\n","        self.eps = eps\n","        self.cosine_similarity = nn.CosineSimilarity(dim=1, eps=eps)\n","\n","    def forward(self, y_pred, y_true):\n","        # Pearson Correlation (1 - correlation for minimization)\n","        y_pred_centered = y_pred - y_pred.mean(dim=1, keepdim=True)\n","        y_true_centered = y_true - y_true.mean(dim=1, keepdim=True)\n","        numerator = (y_pred_centered * y_true_centered).sum(dim=1)\n","        denominator = (y_pred_centered.pow(2).sum(dim=1) * y_true_centered.pow(2).sum(dim=1)).sqrt() + self.eps\n","        pearson_corr = numerator / denominator\n","        pearson_loss = 1 - pearson_corr\n","\n","        # Cosine Similarity (1 - similarity for minimization)\n","        cosine_loss = 1 - self.cosine_similarity(y_pred, y_true)\n","        loss = self.alpha * pearson_loss + (1 - self.alpha) * cosine_loss\n","        return loss.mean()\n","class HyperbolicModel(nn.Module):\n","    def __init__(self, input_dim, output_dim):\n","        super().__init__()\n","        self.fc1 = nn.Linear(input_dim, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, output_dim)\n","        self.tanh = nn.Tanh()\n","    def forward(self, x):\n","        x = self.tanh(self.fc1(x))\n","        x = self.tanh(self.fc2(x))\n","        x = self.fc3(x)\n","        return x\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    corrs = [np.corrcoef(y_true[:,i], y_pred[:,i])[0,1] if np.std(y_true[:,i])>0 and np.std(y_pred[:,i])>0 else 0 for i in range(y_true.shape[1])]\n","    avg_pearson = np.mean(corrs)\n","    norms_true = np.linalg.norm(y_true, axis=1)\n","    norms_pred = np.linalg.norm(y_pred, axis=1)\n","    cos = np.sum(y_true * y_pred, axis=1) / (norms_true * norms_pred + 1e-8)\n","    avg_cosine = np.mean(cos)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine\n","    }\n","\n","# Training routine\n","def train_and_evaluate(X, y, test_ratio=0.2, epochs=100, lr=1e-3, batch_size=32, alpha=0.5):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    # Split\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_ratio, random_state=42)\n","    X_train_t = torch.FloatTensor(X_train).to(device)\n","    y_train_t = torch.FloatTensor(y_train).to(device)\n","    X_val_t = torch.FloatTensor(X_val).to(device)\n","    y_val_t = torch.FloatTensor(y_val).to(device)\n","\n","    # Model\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    loss_fn = PearsonCosineLoss(alpha=alpha)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","\n","    n = X_train.shape[0]\n","    steps_per_epoch = int(np.ceil(n / batch_size))\n","\n","    # Training loop\n","    for epoch in range(epochs):\n","        model.train()\n","        idx = np.random.permutation(n)\n","        for i in range(steps_per_epoch):\n","            batch_idx = idx[i*batch_size:(i+1)*batch_size]\n","            xb = X_train_t[batch_idx]\n","            yb = y_train_t[batch_idx]\n","            optimizer.zero_grad()\n","            y_pred = model(xb)\n","            loss = loss_fn(y_pred, yb)\n","            loss.backward()\n","            optimizer.step()\n","        if (epoch+1) % 20 == 0:\n","            print(f\"Epoch {epoch+1}/{epochs}: Train Loss = {loss.item():.4f}\")\n","\n","    model.eval()\n","    with torch.no_grad():\n","        y_train_pred = model(X_train_t).cpu().numpy()\n","        y_val_pred = model(X_val_t).cpu().numpy()\n","\n","    # Print metrics on split data\n","    train_metrics = calculate_metrics(y_train, y_train_pred)\n","    val_metrics = calculate_metrics(y_val, y_val_pred)\n","    print(\"\\\\nTrain Metrics:\", train_metrics)\n","    print(\"Validation Metrics:\", val_metrics)\n","\n","    # Retrain on full data\n","    model = HyperbolicModel(X.shape[1], y.shape[1]).to(device)\n","    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n","    X_full_t = torch.FloatTensor(X).to(device)\n","    y_full_t = torch.FloatTensor(y).to(device)\n","    for epoch in range(epochs):\n","        optimizer.zero_grad()\n","        y_pred = model(X_full_t)\n","        loss = loss_fn(y_pred, y_full_t)\n","        loss.backward()\n","        optimizer.step()\n","    model.eval()\n","    with torch.no_grad():\n","        y_full_pred = model(X_full_t).cpu().numpy()\n","    full_metrics = calculate_metrics(y, y_full_pred)\n","    print(\"\\\\nMetrics on Full Data:\", full_metrics)\n","    return model, device\n","# Run training and print metrics\n","model, device = train_and_evaluate(\n","    x_df_lasso.to_numpy(dtype=np.float32),\n","    y_df.to_numpy(dtype=np.float32),\n","    test_ratio=0.2,\n","    epochs=100,\n","    lr=1e-3,\n","    batch_size=32,\n","    alpha=0.5\n",")\n","\n","# Convert all columns to numeric (with NaNs where conversion failed)\n","X_test_numeric = X_test.apply(pd.to_numeric, errors='coerce')\n","\n","# Fill NaN values (e.g., with 0 or other imputation strategy)\n","X_test_filled = X_test_numeric.fillna(0)\n","\n","# Convert to numpy array of floats\n","X_test_arr = X_test_filled.to_numpy(dtype=np.float32)\n","with torch.no_grad():\n","    X_test_tensor = torch.FloatTensor(X_test_arr).to(device)\n","    test_preds = model(X_test_tensor).cpu().numpy()\n","\n","# Save submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","\n","test_submission.to_csv('hyperbolic_task2_pca.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OKn1rTrhN47u","executionInfo":{"status":"ok","timestamp":1754667124006,"user_tz":-330,"elapsed":17151,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"c2614a5c-d851-48a3-e373-986bc687b372"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 20/100: Train Loss = 0.2170\n","Epoch 40/100: Train Loss = 0.2034\n","Epoch 60/100: Train Loss = 0.1382\n","Epoch 80/100: Train Loss = 0.1228\n","Epoch 100/100: Train Loss = 0.1107\n","\\nTrain Metrics: {'MSE': 0.0583437941968441, 'MAE': 0.13845588266849518, 'R2': 0.428681880235672, 'Avg Pearson Correlation': np.float64(0.7757019969660994), 'Avg Cosine Similarity': np.float32(0.91562706)}\n","Validation Metrics: {'MSE': 0.08716513216495514, 'MAE': 0.1750948280096054, 'R2': 0.14064952731132507, 'Avg Pearson Correlation': np.float64(0.49657111434224094), 'Avg Cosine Similarity': np.float32(0.7389037)}\n","\\nMetrics on Full Data: {'MSE': 0.07775706797838211, 'MAE': 0.16313889622688293, 'R2': 0.2487296462059021, 'Avg Pearson Correlation': np.float64(0.5662829883781576), 'Avg Cosine Similarity': np.float32(0.82520145)}\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **Correlation regressor**"],"metadata":{"id":"pSjUqg9565EQ"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras import backend as K\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.model_selection import train_test_split\n","import numpy as np\n","import pandas as pd\n","\n","\n","# Pearson correlation loss (maximize correlation by minimizing negative correlation)\n","def pearson_correlation_loss(y_true, y_pred):\n","    y_true_centered = y_true - tf.reduce_mean(y_true, axis=1, keepdims=True)\n","    y_pred_centered = y_pred - tf.reduce_mean(y_pred, axis=1, keepdims=True)\n","    numerator = tf.reduce_sum(y_true_centered * y_pred_centered, axis=1)\n","    denominator = tf.sqrt(tf.reduce_sum(tf.square(y_true_centered), axis=1)) * tf.sqrt(tf.reduce_sum(tf.square(y_pred_centered), axis=1))\n","    correlation = numerator / (denominator + 1e-8)\n","    return -tf.reduce_mean(correlation)\n","\n","\n","def create_olfactory_model(input_dim, output_dim):\n","    model = Sequential([\n","        Dense(128, activation='relu', input_shape=(input_dim,)),\n","        Dense(64, activation='relu'),\n","        Dense(output_dim, activation='linear')\n","    ])\n","    model.compile(optimizer='adam', loss=pearson_correlation_loss, metrics=['mse'])\n","    return model\n","\n","\n","class CorrelationRegressor(BaseEstimator, RegressorMixin):\n","    def __init__(self, input_dim=None, output_dim=None, epochs=100, batch_size=32, verbose=0):\n","        self.input_dim = input_dim\n","        self.output_dim = output_dim\n","        self.epochs = epochs\n","        self.batch_size = batch_size\n","        self.verbose = verbose\n","        self.model_ = None\n","\n","    def fit(self, X, y):\n","        if self.input_dim is None:\n","            self.input_dim = X.shape[1]\n","        if self.output_dim is None:\n","            self.output_dim = y.shape[1] if len(y.shape) > 1 else 1\n","        self.model_ = create_olfactory_model(self.input_dim, self.output_dim)\n","        self.model_.fit(\n","            X, y,\n","            epochs=self.epochs,\n","            batch_size=self.batch_size,\n","            verbose=self.verbose\n","        )\n","        return self\n","\n","    def predict(self, X):\n","        if self.model_ is None:\n","            raise ValueError(\"Model not fitted yet\")\n","        return self.model_.predict(X)\n","\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","\n","# Convert DataFrames to numpy arrays\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","\n","# 1. Split data 80% train, 20% validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42)\n","\n","# 2. Initialize regressor\n","regressor = CorrelationRegressor(\n","    input_dim=X_train_split.shape[1],\n","    output_dim=y_train_split.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","\n","# 3. Train on 80% split\n","regressor.fit(X_train_split, y_train_split)\n","\n","# 4. Evaluate on train split and validation split\n","y_train_pred = regressor.predict(X_train_split)\n","y_val_pred = regressor.predict(X_val)\n","\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","\n","# 5. Train on full dataset (train + val)\n","regressor_full = CorrelationRegressor(\n","    input_dim=X.shape[1],\n","    output_dim=y.shape[1],\n","    epochs=100,\n","    batch_size=32,\n","    verbose=1\n",")\n","regressor_full.fit(X, y)\n","\n","# 6. Evaluate on entire training dataset\n","y_full_pred = regressor_full.predict(X)\n","print(\"\\nFull training dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","\n","# 7. Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = regressor_full.predict(X_test_arr)\n","\n","# 8. Save submission file\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('corr_test_task2_combined.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"collapsed":true,"id":"2EGVulygyAxt","executionInfo":{"status":"ok","timestamp":1754667304025,"user_tz":-330,"elapsed":46190,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca9a7c07-5715-46ea-9b97-58bf56411c9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 55ms/step - loss: -0.0712 - mse: 29.1187\n","Epoch 2/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - loss: -0.3211 - mse: 44.4138\n","Epoch 3/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - loss: -0.3735 - mse: 63.5932\n","Epoch 4/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.4284 - mse: 70.6566 \n","Epoch 5/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4387 - mse: 67.9878 \n","Epoch 6/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.4683 - mse: 64.0970 \n","Epoch 7/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4949 - mse: 52.4813 \n","Epoch 8/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.4823 - mse: 47.0436 \n","Epoch 9/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.4978 - mse: 39.2894 \n","Epoch 10/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5060 - mse: 31.4320 \n","Epoch 11/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5237 - mse: 24.2616 \n","Epoch 12/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5297 - mse: 16.7371 \n","Epoch 13/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5553 - mse: 12.3964 \n","Epoch 14/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5729 - mse: 9.0923 \n","Epoch 15/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5809 - mse: 7.0899 \n","Epoch 16/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6087 - mse: 6.2506 \n","Epoch 17/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.6067 - mse: 5.4070 \n","Epoch 18/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6283 - mse: 5.0343 \n","Epoch 19/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6409 - mse: 4.6388 \n","Epoch 20/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6567 - mse: 3.9241 \n","Epoch 21/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.6547 - mse: 4.0658 \n","Epoch 22/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6560 - mse: 3.4629 \n","Epoch 23/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6685 - mse: 3.3524 \n","Epoch 24/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6772 - mse: 3.0365 \n","Epoch 25/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6752 - mse: 2.8906 \n","Epoch 26/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6878 - mse: 2.9977 \n","Epoch 27/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6920 - mse: 2.7022 \n","Epoch 28/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.6919 - mse: 2.7974 \n","Epoch 29/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7023 - mse: 2.5655 \n","Epoch 30/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7063 - mse: 2.5808 \n","Epoch 31/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7142 - mse: 2.3922 \n","Epoch 32/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7136 - mse: 2.2751 \n","Epoch 33/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7223 - mse: 2.4440 \n","Epoch 34/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7148 - mse: 2.1068 \n","Epoch 35/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7196 - mse: 1.9909 \n","Epoch 36/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7308 - mse: 2.1567 \n","Epoch 37/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7282 - mse: 2.1294 \n","Epoch 38/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7468 - mse: 2.0164 \n","Epoch 39/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7383 - mse: 1.8611 \n","Epoch 40/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7423 - mse: 2.0089 \n","Epoch 41/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7471 - mse: 1.8906 \n","Epoch 42/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7430 - mse: 1.7667 \n","Epoch 43/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7413 - mse: 1.8139 \n","Epoch 44/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.7561 - mse: 1.7282\n","Epoch 45/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.7458 - mse: 1.7429\n","Epoch 46/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7420 - mse: 1.8857 \n","Epoch 47/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7585 - mse: 1.7608 \n","Epoch 48/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7629 - mse: 1.8631 \n","Epoch 49/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7664 - mse: 1.6676 \n","Epoch 50/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7473 - mse: 1.6505 \n","Epoch 51/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7633 - mse: 1.7124 \n","Epoch 52/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7734 - mse: 1.5388 \n","Epoch 53/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7703 - mse: 1.6121 \n","Epoch 54/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7587 - mse: 1.5896 \n","Epoch 55/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7686 - mse: 1.6371 \n","Epoch 56/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7693 - mse: 1.6037 \n","Epoch 57/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7609 - mse: 1.5345 \n","Epoch 58/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7762 - mse: 1.6066 \n","Epoch 59/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7661 - mse: 1.4548 \n","Epoch 60/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7694 - mse: 1.5326 \n","Epoch 61/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7857 - mse: 1.5150 \n","Epoch 62/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7629 - mse: 1.5346 \n","Epoch 63/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7756 - mse: 1.5218 \n","Epoch 64/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7958 - mse: 1.5316 \n","Epoch 65/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7752 - mse: 1.4225 \n","Epoch 66/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7845 - mse: 1.4651 \n","Epoch 67/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7781 - mse: 1.3820 \n","Epoch 68/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7823 - mse: 1.4833 \n","Epoch 69/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7897 - mse: 1.4763 \n","Epoch 70/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7943 - mse: 1.3382 \n","Epoch 71/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7799 - mse: 1.2509 \n","Epoch 72/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7956 - mse: 1.4047 \n","Epoch 73/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7840 - mse: 1.3843 \n","Epoch 74/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8036 - mse: 1.3716 \n","Epoch 75/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7891 - mse: 1.3203 \n","Epoch 76/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7843 - mse: 1.4397 \n","Epoch 77/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7935 - mse: 1.3930 \n","Epoch 78/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.7994 - mse: 1.3464\n","Epoch 79/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: -0.7898 - mse: 1.3089\n","Epoch 80/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7983 - mse: 1.3671  \n","Epoch 81/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7852 - mse: 1.3264 \n","Epoch 82/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7966 - mse: 1.2122 \n","Epoch 83/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8020 - mse: 1.2921 \n","Epoch 84/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8060 - mse: 1.3512 \n","Epoch 85/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8111 - mse: 1.3739 \n","Epoch 86/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8040 - mse: 1.2533 \n","Epoch 87/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7963 - mse: 1.3141 \n","Epoch 88/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.8108 - mse: 1.2608 \n","Epoch 89/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.8118 - mse: 1.2943 \n","Epoch 90/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.8137 - mse: 1.2876 \n","Epoch 91/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.8098 - mse: 1.2010 \n","Epoch 92/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8001 - mse: 1.2666 \n","Epoch 93/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8170 - mse: 1.3288 \n","Epoch 94/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.8132 - mse: 1.2355\n","Epoch 95/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.8166 - mse: 1.2425  \n","Epoch 96/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - loss: -0.8159 - mse: 1.3270\n","Epoch 97/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - loss: -0.8148 - mse: 1.2057\n","Epoch 98/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: -0.8092 - mse: 1.1077\n","Epoch 99/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: -0.8263 - mse: 1.2073\n","Epoch 100/100\n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - loss: -0.8187 - mse: 1.1419 \n","\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n","\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n","Training set metrics:\n","{'MSE': 1.2277177572250366, 'MAE': 0.896125316619873, 'R2': -21.648422241210938, 'Avg Pearson Correlation': np.float64(0.6470092715532638), 'Avg Cosine Similarity': np.float32(0.21888177)}\n","\n","Validation set metrics:\n","{'MSE': 1.2863013744354248, 'MAE': 0.9070459008216858, 'R2': -26.737295150756836, 'Avg Pearson Correlation': np.float64(0.4644676774087276), 'Avg Cosine Similarity': np.float32(0.12716053)}\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - loss: -0.0131 - mse: 40.2363\n","Epoch 2/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.2895 - mse: 67.7059 \n","Epoch 3/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.3774 - mse: 91.5868 \n","Epoch 4/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4427 - mse: 92.4694 \n","Epoch 5/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4641 - mse: 86.1756 \n","Epoch 6/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.4649 - mse: 78.7181 \n","Epoch 7/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4894 - mse: 63.3202 \n","Epoch 8/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.4834 - mse: 49.9786 \n","Epoch 9/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5083 - mse: 34.3903 \n","Epoch 10/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.5240 - mse: 22.6231 \n","Epoch 11/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.5603 - mse: 13.7579 \n","Epoch 12/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5732 - mse: 10.3883 \n","Epoch 13/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.5949 - mse: 8.0111 \n","Epoch 14/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6168 - mse: 6.6477 \n","Epoch 15/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6034 - mse: 6.2592 \n","Epoch 16/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6396 - mse: 5.7283 \n","Epoch 17/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6384 - mse: 5.2998 \n","Epoch 18/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6442 - mse: 5.4829 \n","Epoch 19/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6529 - mse: 4.8887 \n","Epoch 20/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6551 - mse: 4.6593 \n","Epoch 21/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6583 - mse: 4.4077 \n","Epoch 22/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6578 - mse: 4.0859 \n","Epoch 23/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6814 - mse: 4.2019 \n","Epoch 24/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.6800 - mse: 3.7840 \n","Epoch 25/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6829 - mse: 3.4828 \n","Epoch 26/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6858 - mse: 3.8817 \n","Epoch 27/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.6890 - mse: 3.4351 \n","Epoch 28/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7098 - mse: 3.8477 \n","Epoch 29/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7029 - mse: 3.6118 \n","Epoch 30/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7139 - mse: 3.5016 \n","Epoch 31/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7124 - mse: 3.1487 \n","Epoch 32/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7193 - mse: 3.1562 \n","Epoch 33/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7142 - mse: 3.1119 \n","Epoch 34/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7178 - mse: 2.9813 \n","Epoch 35/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7103 - mse: 3.5471 \n","Epoch 36/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7216 - mse: 3.2714 \n","Epoch 37/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7221 - mse: 2.8111 \n","Epoch 38/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7357 - mse: 2.8588 \n","Epoch 39/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7369 - mse: 2.7866 \n","Epoch 40/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7323 - mse: 2.6990 \n","Epoch 41/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7389 - mse: 2.8418 \n","Epoch 42/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7324 - mse: 2.7295 \n","Epoch 43/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7305 - mse: 2.5616 \n","Epoch 44/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7495 - mse: 2.6196 \n","Epoch 45/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7412 - mse: 2.7240\n","Epoch 46/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7450 - mse: 2.6506 \n","Epoch 47/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7448 - mse: 2.7965 \n","Epoch 48/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7495 - mse: 2.4292 \n","Epoch 49/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7544 - mse: 2.5261 \n","Epoch 50/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7531 - mse: 2.3129 \n","Epoch 51/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7425 - mse: 2.2743 \n","Epoch 52/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7489 - mse: 2.4079 \n","Epoch 53/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7455 - mse: 2.5015 \n","Epoch 54/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7499 - mse: 2.7810 \n","Epoch 55/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7453 - mse: 2.6000 \n","Epoch 56/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7512 - mse: 2.4001 \n","Epoch 57/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7476 - mse: 2.2976 \n","Epoch 58/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7648 - mse: 2.3724 \n","Epoch 59/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7566 - mse: 2.3707\n","Epoch 60/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7561 - mse: 2.0484\n","Epoch 61/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7594 - mse: 2.2693\n","Epoch 62/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7611 - mse: 2.3700\n","Epoch 63/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7594 - mse: 2.4099 \n","Epoch 64/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7671 - mse: 2.1755 \n","Epoch 65/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7593 - mse: 2.1474 \n","Epoch 66/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7710 - mse: 2.1081 \n","Epoch 67/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7853 - mse: 2.1863\n","Epoch 68/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7644 - mse: 2.0401\n","Epoch 69/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7611 - mse: 2.2105\n","Epoch 70/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7633 - mse: 2.2122\n","Epoch 71/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: -0.7788 - mse: 2.1222  \n","Epoch 72/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7770 - mse: 2.0651 \n","Epoch 73/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7715 - mse: 2.1392 \n","Epoch 74/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7661 - mse: 1.9359 \n","Epoch 75/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7777 - mse: 2.0824 \n","Epoch 76/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7795 - mse: 2.0839 \n","Epoch 77/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7858 - mse: 2.1756 \n","Epoch 78/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7644 - mse: 2.0696 \n","Epoch 79/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7753 - mse: 1.9802 \n","Epoch 80/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7785 - mse: 2.1868 \n","Epoch 81/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7854 - mse: 1.9442 \n","Epoch 82/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7908 - mse: 1.9246 \n","Epoch 83/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7812 - mse: 1.9843 \n","Epoch 84/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7813 - mse: 1.9889 \n","Epoch 85/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7911 - mse: 1.9004 \n","Epoch 86/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7922 - mse: 1.8292 \n","Epoch 87/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7857 - mse: 1.9972 \n","Epoch 88/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7778 - mse: 1.8317 \n","Epoch 89/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7845 - mse: 1.9800 \n","Epoch 90/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7847 - mse: 2.0215 \n","Epoch 91/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: -0.7861 - mse: 1.9475 \n","Epoch 92/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: -0.7788 - mse: 1.7394 \n","Epoch 93/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7917 - mse: 1.8358\n","Epoch 94/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: -0.7880 - mse: 1.8119\n","Epoch 95/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7813 - mse: 1.8981 \n","Epoch 96/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: -0.7913 - mse: 1.9636 \n","Epoch 97/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: -0.7896 - mse: 1.7563\n","Epoch 98/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7967 - mse: 1.7331\n","Epoch 99/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: -0.7951 - mse: 1.9202\n","Epoch 100/100\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: -0.7915 - mse: 2.0522\n","\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n","\n","Full training dataset metrics:\n","{'MSE': 1.9374088048934937, 'MAE': 0.9783313274383545, 'R2': -25.559276580810547, 'Avg Pearson Correlation': np.float64(0.6424088290430936), 'Avg Cosine Similarity': np.float32(0.374554)}\n","\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **RF1**"],"metadata":{"id":"F8MeTU0Q7LHa"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n","import numpy as np\n","import pandas as pd\n","\n","# Custom Pearson correlation scorer\n","def pearson_correlation_score(y_true, y_pred):\n","    correlations = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        correlations.append(corr)\n","    return np.mean(correlations)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","# Evaluation metrics\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","import numpy as np\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    corrs = []\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        y_true_col = y_true[:, i]\n","        y_pred_col = y_pred[:, i]\n","\n","        # Pearson correlation\n","        if np.std(y_true_col) > 0 and np.std(y_pred_col) > 0:\n","            corr = np.corrcoef(y_true_col, y_pred_col)[0, 1]\n","        else:\n","            corr = 0\n","        corrs.append(corr)\n","\n","        # Cosine similarity\n","        if np.linalg.norm(y_true_col) > 0 and np.linalg.norm(y_pred_col) > 0:\n","            cos_sim = cosine_similarity(\n","                y_true_col.reshape(1, -1), y_pred_col.reshape(1, -1))[0, 0]\n","        else:\n","            cos_sim = 0\n","        cos_sims.append(cos_sim)\n","\n","    avg_pearson = np.mean(corrs)\n","    avg_cosine_similarity = np.mean(cos_sims)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson,\n","        'Avg Cosine Similarity': avg_cosine_similarity\n","    }\n","\n","\n","# Prepare data\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","# Train-validation split\n","X_train_split, X_val, y_train_split, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Initialize and train model\n","base_model = RandomForestRegressor(n_estimators=100, random_state=42)\n","model = MultiOutputRegressor(base_model)\n","model.fit(X_train_split, y_train_split)\n","\n","# Predictions\n","y_train_pred = model.predict(X_train_split)\n","y_val_pred = model.predict(X_val)\n","\n","# Evaluation\n","print(\"Training set metrics:\")\n","print(calculate_metrics(y_train_split, y_train_pred))\n","\n","print(\"\\nValidation set metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# Train on full data\n","final_model = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=42))\n","final_model.fit(X, y)\n","y_pred=final_model.predict(X)\n","print(calculate_metrics(y, y_pred))\n","# Predict on test set\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","predictions = final_model.predict(X_test_arr)\n","\n","# Prepare submission\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = predictions[:, i]\n","\n","test_submission.to_csv('rf_test_task2_combined.csv', index=False)\n","print(\"Test predictions saved to rf_test_lasso.csv\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4OMa9sFH7jzy","outputId":"43f29527-cfbc-4f6b-bf08-bb7e073e5ba0","executionInfo":{"status":"ok","timestamp":1754667578828,"user_tz":-330,"elapsed":274808,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training set metrics:\n","{'MSE': 0.010518383492117523, 'MAE': 0.06420235958896899, 'R2': 0.8921443693959343, 'Avg Pearson Correlation': np.float64(0.9673701840709672), 'Avg Cosine Similarity': np.float64(0.9712884166031108)}\n","\n","Validation set metrics:\n","{'MSE': 0.06542474246573686, 'MAE': 0.16211139329666316, 'R2': 0.2592146740249138, 'Avg Pearson Correlation': np.float64(0.5446494684539364), 'Avg Cosine Similarity': np.float64(0.7452429569882943)}\n","{'MSE': 0.010049656856470149, 'MAE': 0.06250374935680934, 'R2': 0.8954517864510795, 'Avg Pearson Correlation': np.float64(0.9659844905167095), 'Avg Cosine Similarity': np.float64(0.9717169381991124)}\n","Test predictions saved to rf_test_lasso.csv\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **RF2**"],"metadata":{"id":"pPbQnT8r_oow"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.multioutput import MultiOutputRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","\n","# --- Custom metrics ---\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr): corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    similarities = []\n","    for i in range(y_true.shape[0]):\n","        y_true_norm = y_true[i] / (np.linalg.norm(y_true[i]) + 1e-8)\n","        y_pred_norm = y_pred[i] / (np.linalg.norm(y_pred[i]) + 1e-8)\n","        similarity = np.dot(y_true_norm, y_pred_norm)\n","        similarities.append(similarity)\n","    return np.mean(similarities)\n","\n","def calculate_metrics(y_true, y_pred):\n","    return {\n","        \"MSE\": mean_squared_error(y_true, y_pred),\n","        \"MAE\": mean_absolute_error(y_true, y_pred),\n","        \"R2\": r2_score(y_true, y_pred),\n","        \"Avg Pearson Correlation\": pearson_correlation_score(y_true, y_pred),\n","        \"Avg Cosine Similarity\": cosine_similarity_score(y_true, y_pred),\n","    }\n","\n","# --------- Example workflow ---------\n","# These need to be set before running:\n","# X_df: DataFrame of features, y_df: DataFrame of targets (n_samples, n_targets)\n","# X_test_df: DataFrame of test features\n","# test_form: DataFrame with 'stimulus' column, matches rows of X_test_df\n","# target_cols: list of 51 string column names\n","\n","# 1. Convert to numpy if needed\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","X_test = X_test.to_numpy(dtype=np.float32)\n","\n","# 2. 80/20 split\n","X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# 3. Train MultiOutput RandomForest\n","rf = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf.fit(X_train, y_train)\n","\n","# 4. Print metrics on splits\n","y_train_pred = rf.predict(X_train)\n","y_val_pred = rf.predict(X_val)\n","print(\"Training metrics:\")\n","print(calculate_metrics(y_train, y_train_pred))\n","print(\"\\nValidation metrics:\")\n","print(calculate_metrics(y_val, y_val_pred))\n","\n","# 5. Retrain on entire dataset, print metrics\n","rf_full = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, max_depth=None, random_state=42, n_jobs=-1))\n","rf_full.fit(X, y)\n","y_full_pred = rf_full.predict(X)\n","print(\"\\nFull dataset metrics:\")\n","print(calculate_metrics(y, y_full_pred))\n","\n","# 6. Predict on test set, save file\n","test_preds = rf_full.predict(X_test)\n","test_submission = test_form[['stimulus']].copy()\n","for i, col in enumerate(target_cols):\n","    test_submission[col] = test_preds[:, i]\n","test_submission.to_csv('rf_corr_cosine_metrics_test_task2_combined.csv', index=False)\n","print(\"Test predictions saved.\")\n","print(f\"Test submission shape: {test_submission.shape}\")\n"],"metadata":{"id":"dPwlXa2e5Otw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754667785741,"user_tz":-330,"elapsed":206943,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"fd2d59f1-42bf-4e75-aea3-b5bd521bbc8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training metrics:\n","{'MSE': 0.010518383492117523, 'MAE': 0.06420235958896899, 'R2': 0.8921443693959343, 'Avg Pearson Correlation': np.float64(0.9673701840709672), 'Avg Cosine Similarity': np.float64(0.9756392310670461)}\n","\n","Validation metrics:\n","{'MSE': 0.06542474246573686, 'MAE': 0.16211139329666316, 'R2': 0.2592146740249138, 'Avg Pearson Correlation': np.float64(0.5446494684539364), 'Avg Cosine Similarity': np.float64(0.8035231979903125)}\n","\n","Full dataset metrics:\n","{'MSE': 0.010049656856470149, 'MAE': 0.06250374935680934, 'R2': 0.8954517864510795, 'Avg Pearson Correlation': np.float64(0.9659844905167095), 'Avg Cosine Similarity': np.float64(0.9765042337977773)}\n","Test predictions saved.\n","Test submission shape: (130, 52)\n"]}]},{"cell_type":"markdown","source":["# **XG1**"],"metadata":{"id":"Mlg703nF_u0C"}},{"cell_type":"code","source":[],"metadata":{"id":"Nk-WTU5f_4lJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics import make_scorer\n","from sklearn.multioutput import MultiOutputRegressor\n","import xgboost as xgb\n","\n","# --------------- Metrics ---------------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        if np.isnan(corr):\n","            corr = 0\n","        corrs.append(corr)\n","    return np.mean(corrs)\n","\n","correlation_scorer = make_scorer(pearson_correlation_score, greater_is_better=True)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","\n","    avg_pearson = pearson_correlation_score(y_true, y_pred)\n","\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': avg_pearson\n","    }\n","\n","# --------------- Custom Objectives for XGBoost ---------------\n","# They receive (preds, dtrain) and must return (grad, hess)\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative Pearson correlation loss.\n","    This is a rough approximation for demonstration only.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_mean = np.mean(preds)\n","    label_mean = np.mean(labels)\n","    pred_centered = preds - pred_mean\n","    label_centered = labels - label_mean\n","\n","    cov = np.sum(pred_centered * label_centered)\n","    pred_var = np.sum(pred_centered ** 2) + 1e-8\n","    label_var = np.sum(label_centered ** 2) + 1e-8\n","\n","    # Gradient (negative derivative of correlation)\n","    grad = - (label_centered / (np.sqrt(pred_var) * np.sqrt(label_var))) + \\\n","           (cov * pred_centered) / (pred_var ** 1.5 * np.sqrt(label_var))\n","\n","    # Hessian approximation with small constant\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    \"\"\"\n","    Approximate gradient and hessian for negative cosine similarity loss.\n","    Rough approximation for demonstration.\n","    \"\"\"\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","\n","    cos_sim = np.dot(preds, labels) / (pred_norm * label_norm)\n","    grad = - (labels / (pred_norm * label_norm)) + \\\n","           (cos_sim * preds) / (pred_norm ** 2)\n","    hess = np.ones_like(grad) * 1e-4\n","\n","    return grad, hess\n","\n","# --------------- Model Wrappers ---------------\n","\n","class XGBoostCorrelationRegressor:\n","    \"\"\"XGBoost regressor for single output with Pearson correlation loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=pearson_correlation_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        # y must be 1D for single output\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class XGBoostCosineSimilarityRegressor:\n","    \"\"\"XGBoost regressor for single output with Cosine similarity loss.\"\"\"\n","    def __init__(self, **kwargs):\n","        self.model = xgb.XGBRegressor(objective=cosine_similarity_obj, **kwargs)\n","\n","    def fit(self, X, y):\n","        y = y.reshape(-1)\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X).reshape(-1, 1)\n","\n","class MultiOutputXGBoostRegressor:\n","    \"\"\"Multi-output regressor as sklearn wrapper over XGBRegressor.\"\"\"\n","    def __init__(self, **kwargs):\n","        base_est = xgb.XGBRegressor(objective='reg:squarederror', **kwargs)\n","        self.model = MultiOutputRegressor(base_est)\n","\n","    def fit(self, X, y):\n","        self.model.fit(X, y)\n","        return self\n","\n","    def predict(self, X):\n","        return self.model.predict(X)\n","\n","# --------------- Training & evaluation function ---------------\n","\n","def train_evaluate_save(model, X, y, X_test, test_form, target_cols, model_name=\"model\"):\n","    \"\"\"\n","    Train with 80/20 split, print evaluation, retrain on full data, print evaluation, predict on test, save CSV.\n","    \"\"\"\n","    print(f\"--- Training and evaluating {model_name} ---\")\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Train on split\n","    model.fit(X_train, y_train)\n","\n","    # Predict & evaluate on train and validation split\n","    y_train_pred = model.predict(X_train)\n","    y_val_pred = model.predict(X_val)\n","    print(\"Train Metrics:\", calculate_metrics(y_train, y_train_pred))\n","    print(\"Validation Metrics:\", calculate_metrics(y_val, y_val_pred))\n","\n","    # Retrain on full dataset\n","    model.fit(X, y)\n","    y_full_pred = model.predict(X)\n","    print(\"Full Data Metrics:\", calculate_metrics(y, y_full_pred))\n","\n","    # Predict on test data\n","    test_preds = model.predict(X_test)\n","\n","    # Save predictions file\n","    test_submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        test_submission[col] = test_preds[:, i] if test_preds.shape[1] > 1 else test_preds[:, 0]\n","\n","    output_file = f'{model_name}_test_task2_combined.csv'\n","    test_submission.to_csv(output_file, index=False)\n","    print(f\"Test predictions saved to {output_file}\")\n","    print(f\"Test submission shape: {test_submission.shape}\\n\")\n","\n","# --------------- Usage Notes ---------------\n","# Variables you must have prepared before calling:\n","\n","# X: numpy array of shape (n_samples, n_features)\n","# y: numpy array of shape (n_samples, 51) - targets\n","# X_test: numpy array for test features, shape (n_test_samples, n_features)\n","# test_form: pandas DataFrame with 'stimulus' column for test samples\n","# target_cols: list of 51 odor descriptor column names, matching y columns\n","\n","# Example calls (uncomment and set your datasets appropriately):\n","#\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","\n","model_pearson = MultiOutputXGBoostRegressor()  # Multitarget with standard MSE\n","train_evaluate_save(model_pearson, X, y, X_test, test_form, target_cols, model_name=\"MultiOutputXGBoost_MSE\")\n","\n"],"metadata":{"id":"1yk7lN9vDvT2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754667907317,"user_tz":-330,"elapsed":121612,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"746a2fbc-792e-4e4b-80de-47483a6fb5a3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--- Training and evaluating MultiOutputXGBoost_MSE ---\n","Train Metrics: {'MSE': 0.0005327186081558466, 'MAE': 0.0024665924720466137, 'R2': 0.9956809878349304, 'Avg Pearson Correlation': np.float64(0.9978358783317698)}\n","Validation Metrics: {'MSE': 0.07560475170612335, 'MAE': 0.1649562120437622, 'R2': 0.17050018906593323, 'Avg Pearson Correlation': np.float64(0.5156266204771057)}\n","Full Data Metrics: {'MSE': 0.0006901447777636349, 'MAE': 0.003441475797444582, 'R2': 0.9933826923370361, 'Avg Pearson Correlation': np.float64(0.9966812609679261)}\n","Test predictions saved to MultiOutputXGBoost_MSE_test_task2_combined.csv\n","Test submission shape: (130, 52)\n","\n"]}]},{"cell_type":"markdown","source":["# **XG2**"],"metadata":{"id":"G2iIxM1Y_3dS"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import xgboost as xgb\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","from sklearn.metrics.pairwise import cosine_similarity\n","\n","# ------- Custom metrics -------\n","\n","def pearson_correlation_score(y_true, y_pred):\n","    corrs = []\n","    for i in range(y_true.shape[1]):\n","        corr = np.corrcoef(y_true[:, i], y_pred[:, i])[0, 1]\n","        corrs.append(0 if np.isnan(corr) else corr)\n","    return np.mean(corrs)\n","\n","def cosine_similarity_score(y_true, y_pred):\n","    cos_sims = []\n","    for i in range(y_true.shape[1]):\n","        if np.linalg.norm(y_true[:, i]) > 0 and np.linalg.norm(y_pred[:, i]) > 0:\n","            cs = cosine_similarity(y_true[:, i].reshape(1, -1), y_pred[:, i].reshape(1, -1))[0, 0]\n","        else:\n","            cs = 0\n","        cos_sims.append(cs)\n","    return np.mean(cos_sims)\n","\n","def calculate_metrics(y_true, y_pred):\n","    mse = mean_squared_error(y_true, y_pred)\n","    mae = mean_absolute_error(y_true, y_pred)\n","    r2 = r2_score(y_true, y_pred)\n","    pearson = pearson_correlation_score(y_true, y_pred)\n","    cosine = cosine_similarity_score(y_true, y_pred)\n","    return {\n","        'MSE': mse,\n","        'MAE': mae,\n","        'R2': r2,\n","        'Avg Pearson Correlation': pearson,\n","        'Avg Cosine Similarity': cosine\n","    }\n","\n","# ------- Custom objectives for XGBoost -------\n","\n","def pearson_correlation_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    y_true_mean = np.mean(labels)\n","    y_pred_mean = np.mean(preds)\n","    y_true_centered = labels - y_true_mean\n","    y_pred_centered = preds - y_pred_mean\n","    numerator = np.sum(y_true_centered * y_pred_centered)\n","    y_true_std = np.sqrt(np.sum(y_true_centered**2)) + 1e-8\n","    y_pred_std = np.sqrt(np.sum(y_pred_centered**2)) + 1e-8\n","    denominator = y_true_std * y_pred_std\n","\n","    d_numerator = y_true_centered\n","    d_y_pred_std = y_pred_centered / y_pred_std\n","    d_denominator = y_true_std * d_y_pred_std\n","\n","    gradient = -(d_numerator * denominator - numerator * d_denominator) / (denominator ** 2)\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","def cosine_similarity_obj(preds, dtrain):\n","    labels = dtrain.get_label()\n","    preds = preds.reshape(labels.shape)\n","    pred_norm = np.linalg.norm(preds) + 1e-8\n","    label_norm = np.linalg.norm(labels) + 1e-8\n","    y_true_normalized = labels / label_norm\n","    y_pred_normalized = preds / pred_norm\n","\n","    gradient = - y_true_normalized / pred_norm\n","    hessian = np.ones_like(gradient) * 0.1\n","    return gradient, hessian\n","\n","# ------- Training function per model -------\n","\n","def train_custom_xgb_model(X, y, X_val, y_val, X_test, test_form, target_cols, custom_obj, model_name):\n","    print(f\"Training {model_name} ...\")\n","\n","    val_preds = []\n","    val_trues = []\n","\n","    test_preds = np.zeros((X_test.shape[0], y.shape[1]))\n","\n","    for i, col in enumerate(target_cols):\n","        print(f\"Training target: {col}\")\n","        # create DMatrix for training\n","        dtrain = xgb.DMatrix(X, label=y[:, i])\n","        dval = xgb.DMatrix(X_val, label=y_val[:, i])\n","        params = {\n","            'objective': 'reg:squarederror',  # ignored because of custom obj\n","            'max_depth': 6,\n","            'learning_rate': 0.1,\n","            'verbosity': 0,\n","            'seed': 42,\n","        }\n","        # Train model with early stopping evaluated on val split\n","        model = xgb.train(\n","            params,\n","            dtrain,\n","            num_boost_round=100,\n","            obj=custom_obj,\n","            evals=[(dval, 'validation')],\n","            early_stopping_rounds=10,\n","            verbose_eval=False\n","        )\n","\n","        # Predict validation\n","        val_pred = model.predict(dval)\n","        val_preds.append(val_pred)\n","        val_trues.append(y_val[:, i])\n","\n","        # Refit on full data for test prediction\n","        dfull = xgb.DMatrix(X, label=y[:, i])\n","        model_full = xgb.train(params, dfull, num_boost_round=model.best_iteration or 100, obj=custom_obj, verbose_eval=False)\n","\n","        dtest = xgb.DMatrix(X_test)\n","        test_preds[:, i] = model_full.predict(dtest)\n","\n","    # Aggregate validation results\n","    val_preds_arr = np.column_stack(val_preds)\n","    val_trues_arr = np.column_stack(val_trues)\n","\n","    print(f\"{model_name} - Validation metrics (aggregated):\")\n","    print(calculate_metrics(val_trues_arr, val_preds_arr))\n","\n","    # Save test predictions\n","    submission = test_form[['stimulus']].copy()\n","    for i, col in enumerate(target_cols):\n","        submission[col] = test_preds[:, i]\n","    submission_file = f\"{model_name}_test_task2_combined.csv\"\n","    submission.to_csv(submission_file, index=False)\n","    print(f\"Saved test predictions to {submission_file}\")\n","\n","# ------- Prepare data -------\n","\n","X = x_df_lasso.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","y = y_df.apply(pd.to_numeric, errors='coerce').fillna(0).to_numpy(dtype=np.float32)\n","X_test_arr = X_test.to_numpy() if isinstance(X_test, pd.DataFrame) else X_test\n","target_cols = target_cols  # list of 51 target column names\n","test_form_df = test_form  # contains 'stimulus'\n","\n","\n","# Split train data for validation\n","X_train_split, X_val, y_train_split, y_val = train_test_split(\n","    X, y, test_size=0.2, random_state=42\n",")\n","\n","# ------- Run models -------\n","\n","# 1. Pearson correlation objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    pearson_correlation_obj, \"XGBoost_PearsonCorrelation\"\n",")\n","\n","# 2. Cosine similarity objective model\n","train_custom_xgb_model(\n","    X_train_split, y_train_split, X_val, y_val, X_test_arr, test_form_df, target_cols,\n","    cosine_similarity_obj, \"XGBoost_CosineSimilarity\"\n",")\n"],"metadata":{"id":"vccgUip_XjH_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1754667966506,"user_tz":-330,"elapsed":59203,"user":{"displayName":"Sheerin Irfaanaa M","userId":"08172659908996108299"}},"outputId":"a16ab444-138c-473a-9faf-4638b862c243"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Training XGBoost_PearsonCorrelation ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_PearsonCorrelation - Validation metrics (aggregated):\n","{'MSE': 7755841142784.0, 'MAE': 2150216.75, 'R2': -164700117532672.0, 'Avg Pearson Correlation': np.float64(0.4473015827524477), 'Avg Cosine Similarity': np.float32(0.25353655)}\n","Saved test predictions to XGBoost_PearsonCorrelation_test_task2_combined.csv\n","Training XGBoost_CosineSimilarity ...\n","Training target: Green\n","Training target: Cucumber\n","Training target: Herbal\n","Training target: Mint\n","Training target: Woody\n","Training target: Pine\n","Training target: Floral\n","Training target: Powdery\n","Training target: Fruity\n","Training target: Citrus\n","Training target: Tropical\n","Training target: Berry\n","Training target: Peach\n","Training target: Sweet\n","Training target: Caramellic\n","Training target: Vanilla\n","Training target: BrownSpice\n","Training target: Smoky\n","Training target: Burnt\n","Training target: Roasted\n","Training target: Grainy\n","Training target: Meaty\n","Training target: Nutty\n","Training target: Fatty\n","Training target: Coconut\n","Training target: Waxy\n","Training target: Dairy\n","Training target: Buttery\n","Training target: Cheesy\n","Training target: Sour\n","Training target: Fermented\n","Training target: Sulfurous\n","Training target: Garlic.Onion\n","Training target: Earthy\n","Training target: Mushroom\n","Training target: Musty\n","Training target: Ammonia\n","Training target: Fishy\n","Training target: Fecal\n","Training target: Rotten.Decay\n","Training target: Rubber\n","Training target: Phenolic\n","Training target: Animal\n","Training target: Medicinal\n","Training target: Cooling\n","Training target: Sharp\n","Training target: Chlorine\n","Training target: Alcoholic\n","Training target: Plastic\n","Training target: Ozone\n","Training target: Metallic\n","XGBoost_CosineSimilarity - Validation metrics (aggregated):\n","{'MSE': 0.1984511762857437, 'MAE': 0.401027113199234, 'R2': -3.6672425270080566, 'Avg Pearson Correlation': np.float64(0.3972599506381215), 'Avg Cosine Similarity': np.float32(0.62131786)}\n","Saved test predictions to XGBoost_CosineSimilarity_test_task2_combined.csv\n"]}]}]}